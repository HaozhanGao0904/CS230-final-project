{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5015a53-f2b9-46a1-aefb-1f34448f2a18",
   "metadata": {},
   "source": [
    "# Head Weight Estimation\n",
    "\n",
    "This notebook esimates weights for four heads in the recommender system's value model. A value model uses these four heads as targets and learns to predict the probability of each head for every user–video pair. At serving time, the system can combine the predicted head probabilities into a single value score using a weighted sum and then rank candidate videos by this value score:\n",
    "$$\n",
    "\\text{score} \\;=\\; w_1 \\,\\hat y_{\\text{complete}}\n",
    "               \\;+\\; w_2 \\,\\hat y_{\\text{long}}\n",
    "               \\;+\\; w_3 \\,\\hat y_{\\text{rewatch}}\n",
    "               \\;-\\; w_4 \\,\\hat y_{\\text{neg}},\n",
    "$$\n",
    "\n",
    "Head predictions can be done using GNN, which parameters have been stored."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6920f891-e4ea-4f24-8c0d-b851344ac66b",
   "metadata": {},
   "source": [
    "### 1. Extract (level 1) categorical distribution for each user session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae317e13-665a-48b0-990e-bafc6540d237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>video_id</th>\n",
       "      <th>play_duration</th>\n",
       "      <th>time</th>\n",
       "      <th>date</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>watch_ratio</th>\n",
       "      <th>burst_id</th>\n",
       "      <th>session</th>\n",
       "      <th>sess_rank</th>\n",
       "      <th>...</th>\n",
       "      <th>hist_ema_y_rewatch</th>\n",
       "      <th>hist_ema_y_neg</th>\n",
       "      <th>hist_ema_watchratio</th>\n",
       "      <th>hist_cat_ema_complete</th>\n",
       "      <th>hist_cat_entropy_l2</th>\n",
       "      <th>hist_author_recency_days</th>\n",
       "      <th>hist_last_complete_author</th>\n",
       "      <th>hist_has_author_history</th>\n",
       "      <th>hist_prev_sess_len</th>\n",
       "      <th>hist_intersess_gap_h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3649</td>\n",
       "      <td>13838</td>\n",
       "      <td>2020-07-05 00:08:23.438</td>\n",
       "      <td>20200705</td>\n",
       "      <td>1.593879e+09</td>\n",
       "      <td>1.273397</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>9598</td>\n",
       "      <td>13665</td>\n",
       "      <td>2020-07-05 00:13:41.297</td>\n",
       "      <td>20200705</td>\n",
       "      <td>1.593879e+09</td>\n",
       "      <td>1.244082</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.273396</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>5262</td>\n",
       "      <td>851</td>\n",
       "      <td>2020-07-05 00:16:06.687</td>\n",
       "      <td>20200705</td>\n",
       "      <td>1.593879e+09</td>\n",
       "      <td>0.107613</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.270465</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1963</td>\n",
       "      <td>862</td>\n",
       "      <td>2020-07-05 00:20:26.792</td>\n",
       "      <td>20200705</td>\n",
       "      <td>1.593880e+09</td>\n",
       "      <td>0.089885</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.154180</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.636514</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>8234</td>\n",
       "      <td>858</td>\n",
       "      <td>2020-07-05 00:43:05.128</td>\n",
       "      <td>20200705</td>\n",
       "      <td>1.593881e+09</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.047750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.562335</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  video_id  play_duration                    time      date  \\\n",
       "0        0      3649          13838 2020-07-05 00:08:23.438  20200705   \n",
       "1        0      9598          13665 2020-07-05 00:13:41.297  20200705   \n",
       "2        0      5262            851 2020-07-05 00:16:06.687  20200705   \n",
       "3        0      1963            862 2020-07-05 00:20:26.792  20200705   \n",
       "4        0      8234            858 2020-07-05 00:43:05.128  20200705   \n",
       "\n",
       "      timestamp  watch_ratio  burst_id  session  sess_rank  ...  \\\n",
       "0  1.593879e+09     1.273397         1        1          1  ...   \n",
       "1  1.593879e+09     1.244082         1        1          2  ...   \n",
       "2  1.593879e+09     0.107613         1        1          3  ...   \n",
       "3  1.593880e+09     0.089885         1        1          4  ...   \n",
       "4  1.593881e+09     0.078000         1        1          5  ...   \n",
       "\n",
       "   hist_ema_y_rewatch  hist_ema_y_neg  hist_ema_watchratio  \\\n",
       "0                 NaN             NaN                  NaN   \n",
       "1                 0.0            0.00             1.273396   \n",
       "2                 0.0            0.00             1.270465   \n",
       "3                 0.0            0.10             1.154180   \n",
       "4                 0.0            0.19             1.047750   \n",
       "\n",
       "   hist_cat_ema_complete  hist_cat_entropy_l2 hist_author_recency_days  \\\n",
       "0                    NaN             0.000000                      NaN   \n",
       "1                    1.0            -0.000000                      NaN   \n",
       "2                    NaN            -0.000000                      NaN   \n",
       "3                    1.0             0.636514                      NaN   \n",
       "4                    NaN             0.562335                      NaN   \n",
       "\n",
       "   hist_last_complete_author  hist_has_author_history  hist_prev_sess_len  \\\n",
       "0                        NaN                        0                 0.0   \n",
       "1                        NaN                        0                 0.0   \n",
       "2                        NaN                        0                 0.0   \n",
       "3                        NaN                        0                 0.0   \n",
       "4                        NaN                        0                 0.0   \n",
       "\n",
       "   hist_intersess_gap_h  \n",
       "0                   0.0  \n",
       "1                   0.0  \n",
       "2                   0.0  \n",
       "3                   0.0  \n",
       "4                   0.0  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from time import time\n",
    "\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "\n",
    "BASE = Path(\"/Users/haozhangao/Desktop/RecSys Research/KuaiRec 2.0/data/processed\")\n",
    "DATA_PATH = BASE / \"processed_data.parquet\"\n",
    "\n",
    "df = pd.read_parquet(DATA_PATH)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e74d3d14-90bd-472d-b0a9-f05ac93ca8e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 12527912\n"
     ]
    }
   ],
   "source": [
    "# There are some number of rows with missing L1 category\n",
    "n_nan = df[\"i_cat_level1_id\"].isna().sum()\n",
    "n_total = len(df)\n",
    "\n",
    "print(n_nan, n_total)\n",
    "\n",
    "df[\"i_cat_level1_id\"] = df[\"i_cat_level1_id\"].fillna(-124) # replace it with -124 (UNKNOWN)\n",
    "df[\"i_cat_level1_name\"] = (\n",
    "    df[\"i_cat_level1_name\"]\n",
    "    .replace({None: \"UNKNOWN\"})\n",
    "    .fillna(\"UNKNOWN\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f7d3021-7467-454c-874f-f4baeca87518",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i_cat_level1_id</th>\n",
       "      <th>i_cat_level1_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>-124.0</td>\n",
       "      <td>UNKNOWN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>舞蹈</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>2.0</td>\n",
       "      <td>音乐</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>3.0</td>\n",
       "      <td>游戏</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4.0</td>\n",
       "      <td>美妆</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>时尚</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.0</td>\n",
       "      <td>明星娱乐</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>7.0</td>\n",
       "      <td>运动</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>8.0</td>\n",
       "      <td>颜值</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>9.0</td>\n",
       "      <td>喜剧</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>10.0</td>\n",
       "      <td>旅游</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>11.0</td>\n",
       "      <td>生活</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>12.0</td>\n",
       "      <td>美食</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>13.0</td>\n",
       "      <td>三农</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>14.0</td>\n",
       "      <td>教育</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>15.0</td>\n",
       "      <td>艺术</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>16.0</td>\n",
       "      <td>健康</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>17.0</td>\n",
       "      <td>宠物</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>18.0</td>\n",
       "      <td>汽车</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>19.0</td>\n",
       "      <td>情感</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>20.0</td>\n",
       "      <td>二次元</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>21.0</td>\n",
       "      <td>人文</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>22.0</td>\n",
       "      <td>财经</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>23.0</td>\n",
       "      <td>时政资讯</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>24.0</td>\n",
       "      <td>星座命理</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>25.0</td>\n",
       "      <td>亲子</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>26.0</td>\n",
       "      <td>摄影</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>27.0</td>\n",
       "      <td>高新数码</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.0</td>\n",
       "      <td>民生资讯</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>29.0</td>\n",
       "      <td>科学与法律</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>31.0</td>\n",
       "      <td>健身</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>32.0</td>\n",
       "      <td>短剧</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>33.0</td>\n",
       "      <td>自拍</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>34.0</td>\n",
       "      <td>其他</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>35.0</td>\n",
       "      <td>军事</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>36.0</td>\n",
       "      <td>房产家居</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>37.0</td>\n",
       "      <td>奇人异象</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>38.0</td>\n",
       "      <td>读书</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>39.0</td>\n",
       "      <td>影视综</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      i_cat_level1_id i_cat_level1_name\n",
       "331            -124.0           UNKNOWN\n",
       "6                 1.0                舞蹈\n",
       "118               2.0                音乐\n",
       "611               3.0                游戏\n",
       "20                4.0                美妆\n",
       "2                 5.0                时尚\n",
       "4                 6.0              明星娱乐\n",
       "127               7.0                运动\n",
       "64                8.0                颜值\n",
       "11                9.0                喜剧\n",
       "35               10.0                旅游\n",
       "44               11.0                生活\n",
       "21               12.0                美食\n",
       "162              13.0                三农\n",
       "62               14.0                教育\n",
       "50               15.0                艺术\n",
       "57               16.0                健康\n",
       "24               17.0                宠物\n",
       "54               18.0                汽车\n",
       "25               19.0                情感\n",
       "47               20.0               二次元\n",
       "347              21.0                人文\n",
       "2020             22.0                财经\n",
       "222              23.0              时政资讯\n",
       "396              24.0              星座命理\n",
       "13               25.0                亲子\n",
       "40               26.0                摄影\n",
       "402              27.0              高新数码\n",
       "0                28.0              民生资讯\n",
       "98               29.0             科学与法律\n",
       "45               31.0                健身\n",
       "183              32.0                短剧\n",
       "38               33.0                自拍\n",
       "5                34.0                其他\n",
       "319              35.0                军事\n",
       "209              36.0              房产家居\n",
       "308              37.0              奇人异象\n",
       "382              38.0                读书\n",
       "523              39.0               影视综"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Map for level-1 category\n",
    "cat_l1_map = (\n",
    "    df[[\"i_cat_level1_id\", \"i_cat_level1_name\"]]\n",
    "    .drop_duplicates()\n",
    "    .sort_values(\"i_cat_level1_id\")\n",
    ")\n",
    "\n",
    "print(len(cat_l1_map))\n",
    "cat_l1_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c97d6c1-c124-45c3-a8e9-e9e0ecb30ce3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i_cat_level1_id</th>\n",
       "      <th>-124.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "      <th>3.0</th>\n",
       "      <th>4.0</th>\n",
       "      <th>5.0</th>\n",
       "      <th>6.0</th>\n",
       "      <th>7.0</th>\n",
       "      <th>8.0</th>\n",
       "      <th>9.0</th>\n",
       "      <th>...</th>\n",
       "      <th>29.0</th>\n",
       "      <th>31.0</th>\n",
       "      <th>32.0</th>\n",
       "      <th>33.0</th>\n",
       "      <th>34.0</th>\n",
       "      <th>35.0</th>\n",
       "      <th>36.0</th>\n",
       "      <th>37.0</th>\n",
       "      <th>38.0</th>\n",
       "      <th>39.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th>session</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.036364</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.036364</td>\n",
       "      <td>0.036364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">7175</th>\n",
       "      <th>110</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>555591 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "i_cat_level1_id  -124.0     1.0     2.0     3.0     4.0       5.0       6.0    \\\n",
       "user_id session                                                                 \n",
       "0       1           0.0  0.000000     0.0     0.0    0.00  0.166667  0.166667   \n",
       "        2           0.0  1.000000     0.0     0.0    0.00  0.000000  0.000000   \n",
       "        3           0.0  0.000000     0.0     0.0    0.00  0.000000  0.000000   \n",
       "        4           0.0  0.100000     0.0     0.0    0.05  0.000000  0.050000   \n",
       "        5           0.0  0.090909     0.0     0.0    0.00  0.036364  0.018182   \n",
       "...                 ...       ...     ...     ...     ...       ...       ...   \n",
       "7175    110         0.0  0.000000     0.0     0.0    0.00  0.000000  1.000000   \n",
       "        111         0.0  0.000000     0.0     0.0    0.00  0.000000  0.000000   \n",
       "        112         0.0  0.000000     0.0     0.0    0.00  0.333333  0.000000   \n",
       "        113         0.0  0.000000     0.0     0.0    0.00  0.000000  0.000000   \n",
       "        114         0.0  0.000000     0.0     0.0    0.00  0.000000  0.000000   \n",
       "\n",
       "i_cat_level1_id   7.0       8.0       9.0    ...   29.0      31.0    32.0   \\\n",
       "user_id session                              ...                             \n",
       "0       1           0.0  0.000000  0.000000  ...     0.0  0.000000     0.0   \n",
       "        2           0.0  0.000000  0.000000  ...     0.0  0.000000     0.0   \n",
       "        3           0.0  0.000000  0.000000  ...     0.0  0.000000     0.0   \n",
       "        4           0.0  0.000000  0.100000  ...     0.0  0.000000     0.0   \n",
       "        5           0.0  0.018182  0.090909  ...     0.0  0.018182     0.0   \n",
       "...                 ...       ...       ...  ...     ...       ...     ...   \n",
       "7175    110         0.0  0.000000  0.000000  ...     0.0  0.000000     0.0   \n",
       "        111         0.0  0.500000  0.000000  ...     0.0  0.000000     0.0   \n",
       "        112         0.0  0.000000  0.000000  ...     0.0  0.000000     0.0   \n",
       "        113         0.0  1.000000  0.000000  ...     0.0  0.000000     0.0   \n",
       "        114         0.0  0.000000  0.000000  ...     0.0  0.000000     0.0   \n",
       "\n",
       "i_cat_level1_id     33.0      34.0    35.0    36.0    37.0    38.0    39.0   \n",
       "user_id session                                                              \n",
       "0       1        0.000000  0.166667     0.0     0.0     0.0     0.0     0.0  \n",
       "        2        0.000000  0.000000     0.0     0.0     0.0     0.0     0.0  \n",
       "        3        0.000000  0.000000     0.0     0.0     0.0     0.0     0.0  \n",
       "        4        0.000000  0.050000     0.0     0.0     0.0     0.0     0.0  \n",
       "        5        0.036364  0.036364     0.0     0.0     0.0     0.0     0.0  \n",
       "...                   ...       ...     ...     ...     ...     ...     ...  \n",
       "7175    110      0.000000  0.000000     0.0     0.0     0.0     0.0     0.0  \n",
       "        111      0.000000  0.000000     0.0     0.0     0.0     0.0     0.0  \n",
       "        112      0.000000  0.000000     0.0     0.0     0.0     0.0     0.0  \n",
       "        113      0.000000  0.000000     0.0     0.0     0.0     0.0     0.0  \n",
       "        114      0.000000  0.000000     0.0     0.0     0.0     0.0     0.0  \n",
       "\n",
       "[555591 rows x 39 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create level-1 categorical distribution for each session\n",
    "\n",
    "# 1) counts by user–session–L1 category\n",
    "counts = (\n",
    "    df.groupby([\"user_id\", \"session\", \"i_cat_level1_id\"])\n",
    "      .size()\n",
    "      .reset_index(name=\"n_cat\")\n",
    ")\n",
    "\n",
    "# 2) grab session length from the original df\n",
    "sess_len = (\n",
    "    df.groupby([\"user_id\", \"session\"])[\"sess_len\"]\n",
    "      .first()                      # same within a session\n",
    "      .rename(\"sess_total\")\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "# 3) merge and compute probabilities\n",
    "counts = counts.merge(sess_len, on=[\"user_id\", \"session\"], how=\"left\")\n",
    "counts[\"p_cat\"] = counts[\"n_cat\"] / counts[\"sess_total\"]\n",
    "\n",
    "# 4) all possible L1 categories (including -124 for UNKNOWN)\n",
    "ALL_L1_CATS = np.sort(df[\"i_cat_level1_id\"].unique())\n",
    "\n",
    "# 5) build observed category distribution for ALL sessions\n",
    "obs_cat_all = (\n",
    "    counts\n",
    "    .pivot_table(\n",
    "        index=[\"user_id\", \"session\"],\n",
    "        columns=\"i_cat_level1_id\",\n",
    "        values=\"p_cat\",\n",
    "        aggfunc=\"sum\",\n",
    "        fill_value=0.0,\n",
    "    )\n",
    ")\n",
    "\n",
    "# 6) make sure columns are in a fixed order and include all categories\n",
    "obs_cat_all = obs_cat_all.reindex(columns=ALL_L1_CATS, fill_value=0.0)\n",
    "\n",
    "obs_cat_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2037d6-b973-4f8d-9fcf-264da3b88e45",
   "metadata": {},
   "source": [
    "### 2. Predict 4 heads using estimated GNN parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87398301-6eb0-48e8-839d-dd8aae35781f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class GNN(nn.Module):\n",
    "    \"\"\"\n",
    "    GNN that learns node embeddings with three GCN layers and predicts\n",
    "    4 edge-level scores by feeding [h_src, h_dst, edge_attr] into an MLP.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_nodes, num_edge_features, hidden_dim=64):\n",
    "        super().__init__()\n",
    "\n",
    "        self.node_emb = nn.Embedding(num_nodes, hidden_dim)\n",
    "\n",
    "        self.gcn1 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.gcn2 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.gcn3 = GCNConv(hidden_dim, hidden_dim)\n",
    "\n",
    "        self.edge_mlp = nn.Sequential(\n",
    "            nn.Linear(2 * hidden_dim + num_edge_features, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 4)\n",
    "        )\n",
    "\n",
    "    def encode_nodes(self, edge_index):\n",
    "        x = self.node_emb.weight\n",
    "        x = F.relu(self.gcn1(x, edge_index))\n",
    "        x = F.relu(self.gcn2(x, edge_index))\n",
    "        x = F.relu(self.gcn3(x, edge_index))\n",
    "        return x                    # [num_nodes, hidden_dim]\n",
    "\n",
    "    def score_edges(self, x, edge_index, edge_attr):\n",
    "        src, dst = edge_index\n",
    "        h_src = x[src]\n",
    "        h_dst = x[dst]\n",
    "\n",
    "        h_edge = torch.cat([h_src, h_dst, edge_attr], dim=-1)\n",
    "        logits = self.edge_mlp(h_edge)    # [E_batch, 4]\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3db9ba43-e1b6-40bc-b5bf-e726a0c07be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load graph tensors used in training\n",
    "gnn_data_path = BASE / \"gnn_data.pt\"\n",
    "\n",
    "data_gnn = torch.load(gnn_data_path)\n",
    "\n",
    "edge_index = data_gnn[\"edge_index\"]          # [2, E]\n",
    "train_idx  = data_gnn[\"train_idx\"]\n",
    "test_idx   = data_gnn[\"test_idx\"]\n",
    "edge_attr  = torch.nan_to_num(data_gnn[\"edge_attr\"], nan=0.0)  # [E, D_edge]\n",
    "num_nodes  = data_gnn[\"num_nodes\"]\n",
    "D_edge     = edge_attr.size(1)\n",
    "\n",
    "with torch.no_grad():\n",
    "    mu  = edge_attr[train_idx].mean(dim=0, keepdim=True)\n",
    "    std = edge_attr[train_idx].std(dim=0, keepdim=True)\n",
    "    std[std < 1e-6] = 1.0          # avoid divide by 0\n",
    "    edge_attr = (edge_attr - mu) / std\n",
    "    \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "edge_index = edge_index.to(device)\n",
    "edge_attr  = edge_attr.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48393cf5-82cd-4216-890c-e71984a42ad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GNN(\n",
       "  (node_emb): Embedding(17904, 128)\n",
       "  (gcn1): GCNConv(128, 128)\n",
       "  (gcn2): GCNConv(128, 128)\n",
       "  (gcn3): GCNConv(128, 128)\n",
       "  (edge_mlp): Sequential(\n",
       "    (0): Linear(in_features=320, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=64, out_features=4, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rebuild model and load checkpoint\n",
    "SAVE_DIR  = Path(\"/Users/haozhangao/Desktop/RecSys Research/KuaiRec 2.0/models/GNN\")\n",
    "ckpt_path = SAVE_DIR / \"GNN_multihead_best.pt\"\n",
    "\n",
    "ckpt = torch.load(ckpt_path, map_location=device)\n",
    "\n",
    "model = GNN(\n",
    "    num_nodes=num_nodes,\n",
    "    num_edge_features=D_edge,\n",
    "    hidden_dim=128,\n",
    ").to(device)\n",
    "\n",
    "model.load_state_dict(ckpt[\"state_dict\"])\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b37d742f-6da0-49a7-b2f8-758ba5070419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12527912, 4])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict 4 heads for all edges\n",
    "@torch.no_grad()\n",
    "def predict_all_heads(batch_size=50000):\n",
    "    E = edge_index.size(1)\n",
    "    all_probs = []\n",
    "\n",
    "    # node embeddings once\n",
    "    x = model.encode_nodes(edge_index)\n",
    "\n",
    "    for start in range(0, E, batch_size):\n",
    "        end = min(start + batch_size, E)\n",
    "        ei_batch = edge_index[:, start:end]        # [2, B]\n",
    "        ea_batch = edge_attr[start:end]            # [B, D_edge]\n",
    "\n",
    "        logits_batch = model.score_edges(x, ei_batch, ea_batch)  # [B, 4]\n",
    "        probs_batch  = torch.sigmoid(logits_batch)               # [B, 4]\n",
    "\n",
    "        all_probs.append(probs_batch.cpu())\n",
    "\n",
    "    probs = torch.cat(all_probs, dim=0)   # [E, 4], aligned with edge_index rows\n",
    "    return probs\n",
    "\n",
    "probs_all = predict_all_heads()\n",
    "probs_all.shape   # should be [num_edges, 4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2911086c-b548-4e19-859d-d46197fc384e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test AUC per head: ['0.8082', '0.7961', '0.8321', '0.8537']\n",
      "Test mean AUC: 0.8225\n"
     ]
    }
   ],
   "source": [
    "# Double check the AUCs on test set\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# 1) grab labels and test index from gnn_data\n",
    "y_all    = data_gnn[\"y\"].cpu().numpy()      # shape [N, 4]\n",
    "test_idx = data_gnn[\"test_idx\"].cpu().numpy()   # shape [N_test]\n",
    "\n",
    "# 2) predicted probs as numpy\n",
    "probs_np = probs_all.cpu().numpy()              # shape [N, 4]\n",
    "\n",
    "# 3) compute AUC per head on test set\n",
    "test_auc_heads = []\n",
    "for h in range(4):\n",
    "    y_h = y_all[test_idx, h]\n",
    "    p_h = probs_np[test_idx, h]\n",
    "\n",
    "    # guard against degenerate labels\n",
    "    if np.all(y_h == 0) or np.all(y_h == 1):\n",
    "        auc_h = float(\"nan\")\n",
    "    else:\n",
    "        auc_h = roc_auc_score(y_h, p_h)\n",
    "    test_auc_heads.append(auc_h)\n",
    "\n",
    "test_auc_mean = np.nanmean(test_auc_heads)\n",
    "\n",
    "print(\"Test AUC per head:\", [f\"{a:.4f}\" for a in test_auc_heads])\n",
    "print(\"Test mean AUC:\", f\"{test_auc_mean:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b598fec6-1a23-4ad5-bd4d-5ade9c482643",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_complete</th>\n",
       "      <th>yhat_complete</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.315376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.464749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.598627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.669049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.476548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   y_complete  yhat_complete\n",
       "0           1       0.315376\n",
       "1           1       0.464749\n",
       "2           0       0.598627\n",
       "3           0       0.669049\n",
       "4           0       0.476548"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge back to df\n",
    "probs_np = probs_all.cpu().numpy()\n",
    "df[\"yhat_complete\"] = probs_np[:, 0]\n",
    "df[\"yhat_long\"]     = probs_np[:, 1]\n",
    "df[\"yhat_rewatch\"]  = probs_np[:, 2]\n",
    "df[\"yhat_neg\"]      = probs_np[:, 3]\n",
    "\n",
    "df[[\"y_complete\", \"yhat_complete\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6756a1b8-2798-4f52-9e04-3259aff678f1",
   "metadata": {},
   "source": [
    "### 3. Load the toy recommender system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8ffd0f-bfe3-4808-a1cc-71d153251512",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### (1) Split edge features into user / item / session-group and create corresponding feature tables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6fd143ea-1cbd-4828-aca2-0779656b3e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical columns as integers\n",
    "cat_cols = df.select_dtypes(include=\"category\").columns.tolist()\n",
    "for c in cat_cols:\n",
    "    df[c] = df[c].cat.codes.astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9dde3aea-cf69-4024-ae21-a6f8ed364264",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34, 13, 17)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols = data_gnn[\"feature_names\"]\n",
    "len(feature_cols)\n",
    "\n",
    "feature_cols = list(feature_cols)\n",
    "\n",
    "# user-level features\n",
    "u_cols = [c for c in feature_cols if c.startswith(\"u_\")]\n",
    "\n",
    "# item-level features\n",
    "i_cols = [c for c in feature_cols if c.startswith(\"i_\")]\n",
    "\n",
    "# session-level features: burst_id, session, ctx_*, hist_*\n",
    "sess_fixed = [\"burst_id\", \"session\"]\n",
    "ctx_cols   = [c for c in feature_cols if c.startswith(\"ctx_\")]\n",
    "hist_cols  = [c for c in feature_cols if c.startswith(\"hist_\")]\n",
    "\n",
    "sess_cols = sess_fixed + ctx_cols + hist_cols\n",
    "\n",
    "len(u_cols), len(i_cols), len(sess_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a81caec-2c03-4813-b9ac-65e7d69efe72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7176, 34)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# User features\n",
    "user_feats = (\n",
    "    df[[\"user_id\"] + u_cols]\n",
    "    .drop_duplicates(subset=\"user_id\")\n",
    "    .set_index(\"user_id\")\n",
    "    .sort_index()\n",
    ")\n",
    "\n",
    "user_feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d55ef08e-f49a-4f8f-99cf-7e46410d65c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10728, 13)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Item features\n",
    "item_feats = (\n",
    "    df[[\"video_id\"] + i_cols]\n",
    "    .drop_duplicates(subset=\"video_id\")\n",
    "    .set_index(\"video_id\")\n",
    "    .sort_index()\n",
    ")\n",
    "\n",
    "item_feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f43352f9-ad5a-46f3-b1e1-dc7348626fe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(555591, 17)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sessioin features\n",
    "\n",
    "session_feats = (\n",
    "    df[[\"user_id\"] + sess_cols]\n",
    "    .groupby([\"user_id\", \"session\"], sort=False)\n",
    "    .first()\n",
    ")\n",
    "\n",
    "# make sure 'session' is also a column (used as a feature)\n",
    "session_feats = session_feats.copy()\n",
    "session_feats[\"session\"] = session_feats.index.get_level_values(\"session\")\n",
    "\n",
    "# overwrite author-history features with simple defaults\n",
    "session_feats[\"hist_has_author_history\"]   = 0.0     # treat as \"no author history\"\n",
    "session_feats[\"hist_author_recency_days\"]  = 60.0   # a large-ish recency cap\n",
    "session_feats[\"hist_last_complete_author\"] = 0.0     # no strong prior on last completion\n",
    "\n",
    "session_feats = session_feats.sort_index()\n",
    "\n",
    "session_feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "42b73343-a32d-48cd-8ce4-e126a834c7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select valid session (length >= 5) to reduce noise in estimation\n",
    "\n",
    "MIN_SESS_LEN = 5\n",
    "\n",
    "sess_len_by_sess = (\n",
    "    df.groupby([\"user_id\", \"session\"])[\"sess_len\"]\n",
    "      .first()\n",
    ")\n",
    "\n",
    "valid_sess_idx = sess_len_by_sess[sess_len_by_sess >= MIN_SESS_LEN].index\n",
    "\n",
    "session_feats = session_feats.loc[valid_sess_idx].sort_index()\n",
    "\n",
    "valid_sessions = session_feats.index.to_frame(index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "90677c86-22aa-4204-9cf8-c95b5893846f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['i_aspect_ratio', 'i_author_id', 'i_video_type', 'i_upload_type',\n",
       "       'i_visible_status', 'i_music_id', 'i_video_tag_id', 'i_video_tag_name',\n",
       "       'i_video_duration', 'i_age_since_upload_days', 'i_cat_level1_id',\n",
       "       'i_cat_level2_id', 'i_cat_level3_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_feats.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08864bdf-60c4-453f-8c36-95a045928985",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### (2) Predict heads of all candidate videos for each session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e45aca6-cc7d-4c9f-b4f3-547936d4787e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_edge_features_for_session(\n",
    "    user_id,\n",
    "    session,\n",
    "    user_feats,\n",
    "    session_feats,\n",
    "    item_feats,\n",
    "    feature_cols,\n",
    "    mu,\n",
    "    std,\n",
    "    device=\"cpu\",\n",
    "    candidate_video_ids=None,\n",
    "    return_df=False,   # <--- new arg\n",
    "):\n",
    "    \"\"\"\n",
    "    For a given (user_id, session), build edge features for a set of candidate\n",
    "    videos (default: all videos in the catalog).\n",
    "\n",
    "    Returns:\n",
    "      video_ids: 1D np.array of candidate video_ids (length V)\n",
    "      edge_tensor: torch.FloatTensor of shape [V, D] with normalized features,\n",
    "                   columns ordered as feature_cols.\n",
    "      edge_df (optional): pandas DataFrame with raw (unnormalized) features\n",
    "                          in feature_cols order (if return_df=True).\n",
    "    \"\"\"\n",
    "\n",
    "    # 0) choose candidate videos: default = all items\n",
    "    if candidate_video_ids is None:\n",
    "        candidate_video_ids = item_feats.index.values\n",
    "\n",
    "    video_ids = np.asarray(candidate_video_ids)\n",
    "\n",
    "    # 1) item features for these videos\n",
    "    item_sub = item_feats.loc[video_ids].copy()   # rows: videos, columns: i_*\n",
    "\n",
    "    # 2) single user + session rows\n",
    "    u_row = user_feats.loc[user_id]                # Series with u_* features\n",
    "    s_row = session_feats.loc[(user_id, session)]  # Series with burst/ctx/hist/session\n",
    "\n",
    "    # 3) start edge_df from item features\n",
    "    edge_df = item_sub.copy()\n",
    "\n",
    "    # add user-level features as constant columns\n",
    "    for col in u_cols:\n",
    "        edge_df[col] = u_row[col]\n",
    "\n",
    "    # add session-level features as constant columns\n",
    "    for col in sess_cols:\n",
    "        edge_df[col] = s_row[col]\n",
    "\n",
    "    # 4) reorder columns to match the exact GNN feature order\n",
    "    edge_df = edge_df[feature_cols]\n",
    "\n",
    "\n",
    "    # 4.5) make sure there are no pandas NA scalars left\n",
    "    edge_df = edge_df.replace({pd.NA: np.nan})\n",
    "    edge_df = edge_df.infer_objects(copy=False)\n",
    "    \n",
    "    # fill any remaining missing numeric values with 0.0\n",
    "    num_cols = edge_df.select_dtypes(include=[\"number\"]).columns\n",
    "    edge_df[num_cols] = edge_df[num_cols].fillna(0.0)\n",
    "    \n",
    "    edge_np = edge_df.to_numpy(dtype=\"float32\", copy=False)\n",
    "    edge_np = np.nan_to_num(edge_np, nan=0.0)\n",
    "    edge_tensor = torch.tensor(edge_np, dtype=torch.float32, device=device)\n",
    "\n",
    "    \n",
    "    # 5) convert to tensor and normalize\n",
    "    edge_tensor = torch.tensor(\n",
    "        edge_df.to_numpy().astype(\"float32\"),\n",
    "        dtype=torch.float32,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    mu_t  = mu.to(device)\n",
    "    std_t = std.to(device)\n",
    "\n",
    "    edge_tensor = (edge_tensor - mu_t) / std_t\n",
    "\n",
    "    if return_df:\n",
    "        return video_ids, edge_tensor, edge_df\n",
    "    else:\n",
    "        return video_ids, edge_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ffda07d8-853c-418e-98a2-27717d5a4422",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10728, 64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['burst_id',\n",
       " 'session',\n",
       " 'u_user_active_degree',\n",
       " 'u_is_lowactive_period',\n",
       " 'u_is_live_streamer',\n",
       " 'u_is_video_author',\n",
       " 'u_follow_user_num',\n",
       " 'u_follow_user_num_range',\n",
       " 'u_fans_user_num',\n",
       " 'u_fans_user_num_range',\n",
       " 'u_friend_user_num',\n",
       " 'u_friend_user_num_range',\n",
       " 'u_register_days',\n",
       " 'u_register_days_range',\n",
       " 'u_onehot_feat0',\n",
       " 'u_onehot_feat1',\n",
       " 'u_onehot_feat2',\n",
       " 'u_onehot_feat3',\n",
       " 'u_onehot_feat4',\n",
       " 'u_onehot_feat5',\n",
       " 'u_onehot_feat6',\n",
       " 'u_onehot_feat7',\n",
       " 'u_onehot_feat8',\n",
       " 'u_onehot_feat9',\n",
       " 'u_onehot_feat10',\n",
       " 'u_onehot_feat11',\n",
       " 'u_onehot_feat12',\n",
       " 'u_onehot_feat13',\n",
       " 'u_onehot_feat14',\n",
       " 'u_onehot_feat15',\n",
       " 'u_onehot_feat16',\n",
       " 'u_onehot_feat17',\n",
       " 'u_follow_user_num_log1p',\n",
       " 'u_fans_user_num_log1p',\n",
       " 'u_friend_user_num_log1p',\n",
       " 'u_register_days_log1p',\n",
       " 'i_aspect_ratio',\n",
       " 'i_author_id',\n",
       " 'i_video_type',\n",
       " 'i_upload_type',\n",
       " 'i_visible_status',\n",
       " 'i_music_id',\n",
       " 'i_video_tag_id',\n",
       " 'i_video_tag_name',\n",
       " 'i_video_duration',\n",
       " 'i_age_since_upload_days',\n",
       " 'i_cat_level1_id',\n",
       " 'i_cat_level2_id',\n",
       " 'i_cat_level3_id',\n",
       " 'ctx_hour_sin',\n",
       " 'ctx_hour_cos',\n",
       " 'ctx_is_weekend',\n",
       " 'hist_ema_y_complete',\n",
       " 'hist_ema_y_long',\n",
       " 'hist_ema_y_rewatch',\n",
       " 'hist_ema_y_neg',\n",
       " 'hist_ema_watchratio',\n",
       " 'hist_cat_ema_complete',\n",
       " 'hist_cat_entropy_l2',\n",
       " 'hist_author_recency_days',\n",
       " 'hist_last_complete_author',\n",
       " 'hist_has_author_history',\n",
       " 'hist_prev_sess_len',\n",
       " 'hist_intersess_gap_h']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test: pick the first (user_id, session) from valid sessions\n",
    "u0, s0 = session_feats.index[0]\n",
    "\n",
    "video_ids_0, edge_tensor_0, edge_df_0 = build_edge_features_for_session(\n",
    "    user_id=u0,\n",
    "    session=s0,\n",
    "    user_feats=user_feats,\n",
    "    session_feats=session_feats,\n",
    "    item_feats=item_feats,\n",
    "    feature_cols=feature_cols,\n",
    "    mu=mu,\n",
    "    std=std,\n",
    "    device=device,\n",
    "    return_df=True,\n",
    ")\n",
    "\n",
    "print(edge_df_0.shape)                 # should be (num_videos, 64)\n",
    "edge_df_0.columns.tolist()      # check column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f121fad-6168-4c27-8c24-728a1f4f4ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precompute node embeddings once\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "edge_index_global = data_gnn[\"edge_index\"].to(device)\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    x_nodes = model.encode_nodes(edge_index_global)   # [num_nodes, hidden_dim]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e37a95c7-dcfb-40e3-a2c4-5d355caa78cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users = int(df[\"user_id\"].max() + 1)\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_heads_for_session(user_id, session, candidate_video_ids=None):\n",
    "    # 1) build edge features for this session and candidate videos\n",
    "    video_ids, edge_feat = build_edge_features_for_session(\n",
    "        user_id=user_id,\n",
    "        session=session,\n",
    "        user_feats=user_feats,\n",
    "        session_feats=session_feats,\n",
    "        item_feats=item_feats,\n",
    "        feature_cols=feature_cols,\n",
    "        mu=mu,\n",
    "        std=std,\n",
    "        device=device,\n",
    "        candidate_video_ids=candidate_video_ids,\n",
    "    )\n",
    "\n",
    "    V = edge_feat.size(0)\n",
    "\n",
    "    # 2) build edge_index consistent with training:\n",
    "    #    src = user_id\n",
    "    #    dst = n_users + video_id\n",
    "    src_idx = torch.full(\n",
    "        (V,),\n",
    "        fill_value=int(user_id),\n",
    "        dtype=torch.long,\n",
    "        device=device,\n",
    "    )\n",
    "    dst_idx = torch.as_tensor(video_ids, dtype=torch.long, device=device) + n_users\n",
    "\n",
    "    edge_index_cf = torch.stack([src_idx, dst_idx], dim=0)  # [2, V]\n",
    "\n",
    "    # 3) use precomputed node embeddings from the full training graph\n",
    "    logits = model.score_edges(x_nodes, edge_index_cf, edge_feat)   # [V, 4]\n",
    "    probs  = torch.sigmoid(logits)                                  # [V, 4]\n",
    "\n",
    "    return video_ids, probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "697ba585-f9f1-4744-8483-344cb7128420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10728,)\n",
      "torch.Size([10728, 4])\n",
      "Execution time (s): 0.03943586349487305\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "tik = time()\n",
    "video_ids, probs = predict_heads_for_session(u0, s0)\n",
    "tok = time()\n",
    "print(video_ids.shape)  # (num_videos,)\n",
    "print(probs.shape)      # (num_videos, 4)\n",
    "print(\"Execution time (s):\",tok-tik)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebcf73f5-4903-4387-8cab-4031837e938e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### (3) Precompute heads for all valid test sessions and save output\n",
    "Only sessions with length >= 5 are considered as valid to reduce noise in estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "71970f72-947f-40c5-933f-64f07bc1b495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total test sessions: 118762\n",
      "Valid test sessions (sess_len >= 5): 66423\n"
     ]
    }
   ],
   "source": [
    "# Extract valid test sessions\n",
    "\n",
    "# 1) define \"valid\" sessions: sess_len >= 5\n",
    "valid_sessions_df = (\n",
    "    df.loc[df[\"sess_len\"] >= 5, [\"user_id\", \"session\"]]\n",
    "      .drop_duplicates()\n",
    "      .astype({\"user_id\": int, \"session\": int})\n",
    ")\n",
    "\n",
    "valid_sessions = pd.MultiIndex.from_frame(\n",
    "    valid_sessions_df,\n",
    "    names=[\"user_id\", \"session\"],\n",
    ")\n",
    "\n",
    "# 2) sessions that appear in the test edges\n",
    "test_pairs = df.loc[test_idx, [\"user_id\", \"session\"]].astype({\"user_id\": int, \"session\": int}).drop_duplicates()\n",
    "\n",
    "test_sessions = pd.MultiIndex.from_frame(\n",
    "    test_pairs,\n",
    "    names=[\"user_id\", \"session\"],\n",
    ")\n",
    "\n",
    "# 3) intersection: valid sessions that are also in test set\n",
    "valid_test_sessions = test_sessions.intersection(valid_sessions)\n",
    "\n",
    "print(\"Total test sessions:\", len(test_sessions))\n",
    "print(\"Valid test sessions (sess_len >= 5):\", len(valid_test_sessions))\n",
    "\n",
    "valid_test_sessions_list = list(valid_test_sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c2441949-9c01-4096-8b88-81adda3d9a39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5764b95a1d1d4d499c313a90504af62b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sessions:   0%|          | 0/66423 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished 66423 sessions.\n",
      "Saved precomputed heads to: /Users/haozhangao/Desktop/RecSys Research/KuaiRec 2.0/data/processed/precomputed_heads.pkl\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "sessions = list(valid_test_sessions_list)   # list of (user_id, session) pairs\n",
    "\n",
    "def _compute_heads_one_session(us):\n",
    "    user_id, sess = us\n",
    "\n",
    "    video_ids, probs = predict_heads_for_session(user_id, sess)\n",
    "    # probs: torch tensor [V, 4]\n",
    "\n",
    "    return (\n",
    "        (int(user_id), int(sess)),\n",
    "        np.asarray(video_ids, dtype=np.int32),\n",
    "        probs.detach().cpu().numpy().astype(np.float32),\n",
    "    )\n",
    "\n",
    "# parallel over sessions, with a progress bar\n",
    "results = Parallel(\n",
    "    n_jobs=-1,           # adjust based on your CPU\n",
    "    prefer=\"threads\",   # safer with PyTorch\n",
    ")(\n",
    "    delayed(_compute_heads_one_session)(us)\n",
    "    for us in tqdm(sessions, desc=\"Sessions\", mininterval=5)\n",
    ")\n",
    "\n",
    "# pack into a dict\n",
    "precomputed_heads_test = {}\n",
    "for key, vids, probs in results:\n",
    "    precomputed_heads_test[key] = {\n",
    "        \"video_ids\": vids,   # shape [V]\n",
    "        \"probs\": probs,      # shape [V, 4]\n",
    "    }\n",
    "\n",
    "print(f\"Finished {len(precomputed_heads_test)} sessions.\")\n",
    "\n",
    "# save to file\n",
    "out_path = BASE / \"precomputed_heads.pkl\"\n",
    "joblib.dump(precomputed_heads_test, out_path)\n",
    "print(f\"Saved precomputed heads to: {out_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bbe927-41b4-4eeb-b37d-19d86f828914",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### (4) Score and recommend top-K videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "41b7c249-d921-4d8c-985a-aa7c44765b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build sess_len map (K per session) from df\n",
    "sess_len_map = (\n",
    "    df[[\"user_id\", \"session\", \"sess_len\"]]\n",
    "    .drop_duplicates()\n",
    "    .set_index([\"user_id\", \"session\"])[\"sess_len\"]\n",
    ")\n",
    "\n",
    "def recommend_for_all_sessions(weights, precomputed_heads, sess_len_map):\n",
    "    \"\"\"\n",
    "    weights: array-like of shape (4,)\n",
    "    precomputed_heads: dict[(user_id, session)] -> {\"video_ids\": [V], \"probs\": [V,4]}\n",
    "    sess_len_map: Series indexed by (user_id, session) giving true sess_len\n",
    "\n",
    "    Returns:\n",
    "      recs: dict[(user_id, session)] -> {\n",
    "          \"video_ids\": np.array[K],   # recommended video ids in rank order\n",
    "          \"scores\":    np.array[K],   # corresponding scores\n",
    "      }\n",
    "    \"\"\"\n",
    "    w = np.asarray(weights, dtype=float).reshape(-1)   # [4]\n",
    "    recs = {}\n",
    "\n",
    "    for (user_id, sess), data in precomputed_heads.items():\n",
    "        vids = data[\"video_ids\"]          # [V]\n",
    "        probs = data[\"probs\"]             # [V, 4]\n",
    "\n",
    "        # 1) score each candidate video\n",
    "        scores = probs @ w                # [V]\n",
    "\n",
    "        # 2) K = session length\n",
    "        K = int(sess_len_map.loc[(user_id, sess)])\n",
    "        K_eff = min(K, scores.shape[0])\n",
    "\n",
    "        # 3) top-K\n",
    "        top_idx = np.argpartition(-scores, K_eff - 1)[:K_eff]\n",
    "        top_idx = top_idx[np.argsort(-scores[top_idx])]\n",
    "\n",
    "        rec_vids = vids[top_idx]\n",
    "        rec_scores = scores[top_idx]\n",
    "\n",
    "        recs[(user_id, sess)] = {\n",
    "            \"video_ids\": rec_vids,\n",
    "            \"scores\": rec_scores,\n",
    "        }\n",
    "\n",
    "    return recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "660cd71e-6441-4297-8382-9eea97393569",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_distribution_from_recs(\n",
    "    recs,\n",
    "    item_feats,\n",
    "    level_col=\"i_cat_level1_id\",\n",
    "    all_cats=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    recs: dict[(user_id, session)] -> {\"video_ids\": np.array[K], \"scores\": np.array[K]}\n",
    "    item_feats: DataFrame indexed by video_id, with a categorical column level_col\n",
    "    level_col: which category level to use (e.g. \"i_cat_level1_id\")\n",
    "    all_cats: optional list/array of category ids to fix the column order;\n",
    "              if None, inferred from item_feats[level_col].\n",
    "    Returns:\n",
    "      DataFrame: index = (user_id, session), columns = category ids,\n",
    "                 values = probabilities from recommended videos.\n",
    "    \"\"\"\n",
    "    if all_cats is None:\n",
    "        all_cats = np.sort(item_feats[level_col].dropna().unique())\n",
    "    all_cats = np.asarray(all_cats)\n",
    "    cat_to_pos = {c: i for i, c in enumerate(all_cats)}\n",
    "    num_cats = len(all_cats)\n",
    "\n",
    "    rows = []\n",
    "    idx = []\n",
    "\n",
    "    for (user_id, sess), d in recs.items():\n",
    "        vids = d[\"video_ids\"]\n",
    "        # lookup categories\n",
    "        cats = item_feats.loc[vids, level_col].to_numpy()\n",
    "\n",
    "        # map to positions, skip NaNs\n",
    "        mask = ~pd.isna(cats)\n",
    "        cats = cats[mask]\n",
    "\n",
    "        cat_pos = np.fromiter(\n",
    "            (cat_to_pos[c] for c in cats),\n",
    "            dtype=np.int64,\n",
    "            count=len(cats),\n",
    "        ) if len(cats) > 0 else np.array([], dtype=np.int64)\n",
    "\n",
    "        counts = np.bincount(cat_pos, minlength=num_cats).astype(float)\n",
    "        if counts.sum() > 0:\n",
    "            probs = counts / counts.sum()\n",
    "        else:\n",
    "            probs = np.zeros(num_cats, dtype=float)\n",
    "\n",
    "        rows.append(probs)\n",
    "        idx.append((user_id, sess))\n",
    "\n",
    "    cat_df = pd.DataFrame(\n",
    "        rows,\n",
    "        index=pd.MultiIndex.from_tuples(idx, names=[\"user_id\", \"session\"]),\n",
    "        columns=all_cats,\n",
    "    )\n",
    "    return cat_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "da840360-932e-4e15-937b-04972ec7631f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.116857290267944\n",
      "(66423, 39)\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "tick = time()\n",
    "recs_test = recommend_for_all_sessions(\n",
    "    weights=[0.25, 0.25, 0.25, 0.25],\n",
    "    precomputed_heads=precomputed_heads_test,\n",
    "    sess_len_map=sess_len_map,\n",
    ")\n",
    "\n",
    "sim_cat_l1_test = cat_distribution_from_recs(\n",
    "    recs_test,\n",
    "    item_feats=item_feats,\n",
    "    level_col=\"i_cat_level1_id\",\n",
    "    all_cats=ALL_L1_CATS,\n",
    ")\n",
    "tock = time()\n",
    "\n",
    "print(\"run time:\", tok-tik)\n",
    "print(sim_cat_l1_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3ec74b-f5c4-42d2-b249-68c0dc1de5b4",
   "metadata": {},
   "source": [
    "### 3. Weight estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5853ea4a-e837-4649-83f1-902dcb74ef60",
   "metadata": {},
   "source": [
    "#### (1) Loss function and objective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "71f48942-519f-47ca-9e73-380e1c889c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_cross_entropy_loss(sim_cat_df, obs_cat_df, eps=1e-8):\n",
    "    \"\"\"\n",
    "    Average cross-entropy between observed and simulated category distributions.\n",
    "\n",
    "    obs_cat_df: observed probs Q, index=(user_id, session), columns=category ids\n",
    "    sim_cat_df: simulated probs P, same structure (rows/cols may be a superset)\n",
    "\n",
    "    Returns:\n",
    "      float: mean cross-entropy over sessions\n",
    "    \"\"\"\n",
    "    # align rows (sessions) and columns (categories)\n",
    "    obs_aligned, sim_aligned = obs_cat_df.align(sim_cat_df, join=\"inner\", axis=0)\n",
    "    sim_aligned = sim_aligned[obs_aligned.columns]\n",
    "\n",
    "    Q = obs_aligned.to_numpy(dtype=float)   # observed\n",
    "    P = sim_aligned.to_numpy(dtype=float)   # simulated\n",
    "\n",
    "    P_clipped = np.clip(P, eps, 1.0)\n",
    "    per_sess_loss = -(Q * np.log(P_clipped)).sum(axis=1)\n",
    "\n",
    "    return float(per_sess_loss.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "88218ceb-1341-4c80-b9c6-6bb565e4d7ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg cross-entropy loss on valid test set: 12.700291245452902\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "w0 = [0.25, 0.25, 0.25, 0.25]\n",
    "\n",
    "# restrict observed distributions to valid test sessions\n",
    "obs_cat_valid_test = obs_cat_all.loc[valid_test_sessions]\n",
    "\n",
    "# recommend for all valid test sessions using precomputed heads\n",
    "recs_valid_test = recommend_for_all_sessions(\n",
    "    weights=w0,\n",
    "    precomputed_heads=precomputed_heads_test,   # dict for valid test sessions\n",
    "    sess_len_map=sess_len_map,                  # from df[\"sess_len\"]\n",
    ")\n",
    "\n",
    "# simulated categorical distribution for these sessions\n",
    "sim_cat_valid_test = cat_distribution_from_recs(\n",
    "    recs=recs_valid_test,\n",
    "    item_feats=item_feats,\n",
    "    level_col=\"i_cat_level1_id\",\n",
    "    all_cats=obs_cat_valid_test.columns,        # ensure same category set/order\n",
    ")\n",
    "\n",
    "# compute loss\n",
    "loss_valid_test = cat_cross_entropy_loss(\n",
    "    sim_cat_df=sim_cat_valid_test,\n",
    "    obs_cat_df=obs_cat_valid_test,\n",
    ")\n",
    "\n",
    "print(\"Avg cross-entropy loss on valid test set:\", loss_valid_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bb79c0d5-cc06-45dd-8c4d-47b6b3d1901f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obj_head_weights(weights, obs_cat_df):\n",
    "    \"\"\"\n",
    "    Objective: given head weights and observed category distributions,\n",
    "    return average cross-entropy loss on the valid test sessions.\n",
    "\n",
    "    weights: array-like of shape (4,)\n",
    "    obs_cat_df: DataFrame with observed probs, index=(user_id, session),\n",
    "                columns = category ids (e.g. L1 category ids).\n",
    "    \"\"\"\n",
    "    # sessions we actually have precomputed heads for\n",
    "    sess_keys = list(precomputed_heads_test.keys())\n",
    "    obs_sub = obs_cat_df.loc[sess_keys]\n",
    "\n",
    "    # 1) recommend videos for all these sessions under given weights\n",
    "    recs = recommend_for_all_sessions(\n",
    "        weights=weights,\n",
    "        precomputed_heads=precomputed_heads_test,\n",
    "        sess_len_map=sess_len_map,\n",
    "    )\n",
    "\n",
    "    # 2) simulated categorical distributions\n",
    "    sim_cat = cat_distribution_from_recs(\n",
    "        recs=recs,\n",
    "        item_feats=item_feats,\n",
    "        level_col=\"i_cat_level1_id\",\n",
    "        all_cats=obs_sub.columns,\n",
    "    )\n",
    "\n",
    "    # 3) cross-entropy loss\n",
    "    loss = cat_cross_entropy_loss(sim_cat_df=sim_cat, obs_cat_df=obs_sub)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a72736-70b7-436b-baa5-8f87ce885973",
   "metadata": {},
   "source": [
    "#### (2) Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4cdc57a3-9ce4-4a2d-94a0-2cc4a12bc38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "def optimize_head_weights_L1(\n",
    "    obs_cat_df,\n",
    "    w0_full=(0.25, 0.25, 0.25, 0.25),\n",
    "    maxiter=200,\n",
    "    xatol=1e-3,\n",
    "    fatol=1e-4,\n",
    "):\n",
    "    \"\"\"\n",
    "    Optimize 4 head weights with:\n",
    "      w4_raw = 1 - (w1_raw + w2_raw + w3_raw)\n",
    "      w = w_raw / sum(|w_raw|)\n",
    "    Only x = (w1_raw, w2_raw, w3_raw) are decision variables.\n",
    "    \"\"\"\n",
    "\n",
    "    # initialize 3-d params from your starting 4-d weights\n",
    "    x0 = np.asarray(w0_full[:3], dtype=float)\n",
    "\n",
    "    def objective_3(x):\n",
    "        x1, x2, x3 = x\n",
    "        w_raw = np.array(\n",
    "            [x1, x2, x3, 1.0 - (x1 + x2 + x3)],\n",
    "            dtype=float,\n",
    "        )\n",
    "\n",
    "        # L1-normalize to kill the scale degeneracy\n",
    "        norm = np.sum(np.abs(w_raw))\n",
    "        if norm < 1e-8:\n",
    "            # avoid division by ~0 – just use uniform as a fallback\n",
    "            w = np.array([0.25, 0.25, 0.25, 0.25], dtype=float)\n",
    "        else:\n",
    "            w = w_raw / norm\n",
    "\n",
    "        L = obj_head_weights(w, obs_cat_df)\n",
    "        print(f\"loss = {L:.6f}, w = {w}\")\n",
    "        return L\n",
    "\n",
    "    res = minimize(\n",
    "        objective_3,\n",
    "        x0=x0,\n",
    "        method=\"Nelder-Mead\",\n",
    "        options={\n",
    "            \"maxiter\": maxiter,\n",
    "            \"xatol\": xatol,\n",
    "            \"fatol\": fatol,\n",
    "            \"disp\": True,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # recover final normalized weights from the optimizer’s x\n",
    "    x1_opt, x2_opt, x3_opt = res.x\n",
    "    w_raw_opt = np.array(\n",
    "        [x1_opt, x2_opt, x3_opt, 1.0 - (x1_opt + x2_opt + x3_opt)],\n",
    "        dtype=float,\n",
    "    )\n",
    "    norm_opt = np.sum(np.abs(w_raw_opt))\n",
    "    if norm_opt < 1e-8:\n",
    "        w_opt = np.array([0.25, 0.25, 0.25, 0.25], dtype=float)\n",
    "    else:\n",
    "        w_opt = w_raw_opt / norm_opt\n",
    "\n",
    "    return w_opt, res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c2400416-967b-4a50-b4d4-c9de6a636e8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 12.700291, w = [0.25 0.25 0.25 0.25]\n",
      "loss = 12.681638, w = [0.2625 0.25   0.25   0.2375]\n",
      "loss = 12.692298, w = [0.25   0.2625 0.25   0.2375]\n",
      "loss = 12.680256, w = [0.25   0.25   0.2625 0.2375]\n",
      "loss = 12.669948, w = [0.25833333 0.25833333 0.25833333 0.225     ]\n",
      "loss = 12.653733, w = [0.2625 0.2625 0.2625 0.2125]\n",
      "loss = 12.654739, w = [0.26666667 0.24583333 0.26666667 0.22083333]\n",
      "loss = 12.644488, w = [0.25694444 0.25555556 0.27777778 0.20972222]\n",
      "loss = 12.628388, w = [0.25416667 0.25833333 0.29166667 0.19583333]\n",
      "loss = 12.615002, w = [0.27222222 0.26111111 0.28472222 0.18194444]\n",
      "loss = 12.590354, w = [0.28333333 0.26666667 0.29583333 0.15416667]\n",
      "loss = 12.594848, w = [0.26666667 0.27916667 0.3        0.15416667]\n",
      "loss = 12.566129, w = [0.27361111 0.27361111 0.32916667 0.12361111]\n",
      "loss = 12.538311, w = [0.27916667 0.27916667 0.3625     0.07916667]\n",
      "loss = 12.534589, w = [0.29861111 0.29166667 0.34722222 0.0625    ]\n",
      "loss = 12.505223, w = [ 0.31818182  0.30578512  0.37190083 -0.00413223]\n",
      "loss = 12.502174, w = [ 0.32132964  0.28947368  0.38781163 -0.00138504]\n",
      "loss = 12.475862, w = [ 0.30215827  0.25539568  0.37410072 -0.06834532]\n",
      "loss = 12.455185, w = [ 0.26638478  0.24524313  0.36892178 -0.11945032]\n",
      "loss = 12.420382, w = [ 0.23589744  0.21538462  0.35641026 -0.19230769]\n",
      "loss = 12.416342, w = [ 0.25123558  0.21169687  0.33360791 -0.20345964]\n",
      "loss = 12.387921, w = [ 0.23517787  0.18774704  0.31422925 -0.26284585]\n",
      "loss = 12.380238, w = [ 0.22133169  0.17139334  0.32922318 -0.27805179]\n",
      "loss = 12.350670, w = [ 0.20434783  0.14782609  0.32173913 -0.32608696]\n",
      "loss = 12.339311, w = [ 0.19332763  0.14927288  0.31137725 -0.34602224]\n",
      "loss = 12.316064, w = [ 0.17864078  0.13495146  0.30291262 -0.38349515]\n",
      "loss = 12.310794, w = [ 0.18647166  0.12797075  0.2952468  -0.39031079]\n",
      "loss = 12.295397, w = [ 0.17980636  0.11618257  0.28699862 -0.41701245]\n",
      "loss = 12.289993, w = [ 0.16888243  0.11071874  0.29518072 -0.42521811]\n",
      "loss = 12.276245, w = [ 0.16109564  0.10167131  0.29294336 -0.44428969]\n",
      "loss = 12.270124, w = [ 0.16119611  0.10375522  0.28511822 -0.44993046]\n",
      "loss = 12.260351, w = [ 0.15661538  0.09907692  0.28123077 -0.46307692]\n",
      "loss = 12.259017, w = [ 0.15834119  0.09434496  0.28124411 -0.46606975]\n",
      "loss = 12.253622, w = [ 0.15615866  0.08997912  0.27891441 -0.47494781]\n",
      "loss = 12.251522, w = [ 0.15127726  0.08971963  0.28143302 -0.47757009]\n",
      "loss = 12.247113, w = [ 0.14845248  0.08709942  0.28088195 -0.48356615]\n",
      "loss = 12.244868, w = [ 0.15031789  0.08756502  0.27697961 -0.48513748]\n",
      "loss = 12.240803, w = [ 0.14926591  0.08618815  0.27542142 -0.48912452]\n",
      "loss = 12.240443, w = [ 0.14878637  0.08410498  0.27697112 -0.49013753]\n",
      "loss = 12.238460, w = [ 0.14802117  0.08264165  0.27655479 -0.49278239]\n",
      "loss = 12.237776, w = [ 0.1465241   0.08332433  0.27663175 -0.49351982]\n",
      "loss = 12.236422, w = [ 0.145615    0.0826964   0.27641636 -0.49527224]\n",
      "loss = 12.235943, w = [ 0.1467842   0.08244434  0.27504811 -0.49572335]\n",
      "loss = 12.234792, w = [ 0.14662573  0.08200219  0.27449399 -0.49687809]\n",
      "loss = 12.234796, w = [ 0.14590344  0.08136004  0.27555364 -0.49718288]\n",
      "loss = 12.234127, w = [ 0.14550613  0.08168701  0.27501606 -0.49779081]\n",
      "loss = 12.233751, w = [ 0.14522037  0.08157854  0.27484123 -0.49835986]\n",
      "loss = 12.233686, w = [ 0.14580672  0.08127212  0.27447119 -0.49844996]\n",
      "loss = 12.233294, w = [ 0.14583024  0.08109737  0.27423253 -0.49883985]\n",
      "loss = 12.233236, w = [ 0.14570638  0.08144936  0.27403519 -0.49880907]\n",
      "loss = 12.233064, w = [ 0.14567406  0.08146401  0.27378611 -0.49907582]\n",
      "loss = 12.232881, w = [ 0.14538502  0.08122053  0.27411796 -0.49927649]\n",
      "loss = 12.232834, w = [ 0.14528115  0.08115509  0.27408648 -0.49947728]\n",
      "loss = 12.232704, w = [ 0.14560537  0.08112017  0.27378423 -0.49949023]\n",
      "loss = 12.232659, w = [ 0.14564987  0.08106719  0.27366206 -0.49962088]\n",
      "loss = 12.232568, w = [ 0.14543963  0.08119589  0.27371012 -0.49965436]\n",
      "loss = 12.232447, w = [ 0.14539656  0.08120675  0.27365252 -0.49974417]\n",
      "loss = 12.232499, w = [ 0.14539611  0.08107737  0.27374592 -0.49978059]\n",
      "loss = 12.232418, w = [ 0.14551767  0.08110844  0.27355605 -0.49981784]\n",
      "loss = 12.232357, w = [ 0.14554875  0.08110231  0.27348634 -0.4998626 ]\n",
      "loss = 12.232380, w = [ 0.14540533  0.08113909  0.27358283 -0.49987275]\n",
      "loss = 12.232344, w = [ 0.14549318  0.08117338  0.2734563  -0.49987714]\n",
      "loss = 12.232391, w = [ 0.14551546  0.08119541  0.27338983 -0.4998993 ]\n",
      "loss = 12.232337, w = [ 0.1455093   0.08111696  0.27345988 -0.49991386]\n",
      "loss = 12.232390, w = [ 0.14552355  0.08110561  0.27343553 -0.49993531]\n",
      "loss = 12.232434, w = [ 0.14559996  0.08112299  0.27337549 -0.49990156]\n",
      "loss = 12.232359, w = [ 0.14546394  0.08113424  0.27352039 -0.49988143]\n",
      "loss = 12.232406, w = [ 0.14556006  0.08112629  0.273418   -0.49989566]\n",
      "loss = 12.232325, w = [ 0.14549035  0.08113205  0.27349226 -0.49988534]\n",
      "loss = 12.232344, w = [ 0.14546787  0.08115974  0.27345785 -0.49991454]\n",
      "loss = 12.232310, w = [ 0.14548643  0.0811141   0.27347514 -0.49992433]\n",
      "loss = 12.232340, w = [ 0.14548468  0.08109879  0.27348001 -0.49993652]\n",
      "loss = 12.232341, w = [ 0.14552554  0.08107588  0.27349237 -0.49990621]\n",
      "loss = 12.232314, w = [ 0.14551009  0.08109834  0.27348313 -0.49990844]\n",
      "loss = 12.232325, w = [ 0.14547959  0.08110987  0.27350766 -0.49990288]\n",
      "loss = 12.232310, w = [ 0.14549283  0.081093    0.27348442 -0.49992975]\n",
      "loss = 12.232340, w = [ 0.14549347  0.08108298  0.27348241 -0.49994114]\n",
      "loss = 12.232338, w = [ 0.14550628  0.08109635  0.2734628  -0.49993457]\n",
      "loss = 12.232326, w = [ 0.14548843  0.08110539  0.27349281 -0.49991337]\n",
      "loss = 12.232310, w = [ 0.14548975  0.08110316  0.27347995 -0.49992714]\n",
      "loss = 12.232309, w = [ 0.14550033  0.08109532  0.27348386 -0.49992049]\n",
      "loss = 12.232307, w = [ 0.14548728  0.08110008  0.27349417 -0.49991847]\n",
      "loss = 12.232326, w = [ 0.14549189  0.08110784  0.2734874  -0.49991287]\n",
      "loss = 12.232310, w = [ 0.14549263  0.08109615  0.27348505 -0.49992617]\n",
      "loss = 12.232325, w = [ 0.14549217  0.0811035   0.27348653 -0.49991781]\n",
      "loss = 12.232310, w = [ 0.14549253  0.08109784  0.27348539 -0.49992424]\n",
      "loss = 12.232325, w = [ 0.14549388  0.08109767  0.27348895 -0.49991949]\n",
      "loss = 12.232326, w = [ 0.14548858  0.08110171  0.27348666 -0.49992305]\n",
      "loss = 12.232325, w = [ 0.14549009  0.08109802  0.27348939 -0.49992251]\n",
      "loss = 12.232307, w = [ 0.14549241  0.0810952   0.27349526 -0.49991712]\n",
      "loss = 12.232309, w = [ 0.14549455  0.08109156  0.27350008 -0.49991381]\n",
      "loss = 12.232307, w = [ 0.14549242  0.08109728  0.27349653 -0.49991377]\n",
      "loss = 12.232325, w = [ 0.14548719  0.0810974   0.27350214 -0.49991328]\n",
      "loss = 12.232308, w = [ 0.1454923   0.08109761  0.27349207 -0.49991802]\n",
      "loss = 12.232325, w = [ 0.14548896  0.08109747  0.27349865 -0.49991492]\n",
      "loss = 12.232308, w = [ 0.14549149  0.08109757  0.27349367 -0.49991727]\n",
      "loss = 12.232307, w = [ 0.14549242  0.08109622  0.27349588 -0.49991548]\n",
      "loss = 12.232307, w = [ 0.14548982  0.08109766  0.27349471 -0.4999178 ]\n",
      "loss = 12.232308, w = [ 0.14549235  0.08109641  0.27349366 -0.49991758]\n",
      "loss = 12.232307, w = [ 0.14549071  0.08109632  0.27349694 -0.49991604]\n",
      "loss = 12.232307, w = [ 0.14549395  0.08109409  0.27349739 -0.49991458]\n",
      "loss = 12.232315, w = [ 0.14549614  0.0810922   0.2734988  -0.49991286]\n",
      "loss = 12.232307, w = [ 0.14549227  0.08109421  0.27349715 -0.49991636]\n",
      "loss = 12.232307, w = [ 0.14549503  0.08109269  0.27349624 -0.49991603]\n",
      "loss = 12.232315, w = [ 0.14549719  0.08109088  0.27349589 -0.49991603]\n",
      "loss = 12.232307, w = [ 0.14549532  0.08109379  0.27349542 -0.49991548]\n",
      "loss = 12.232315, w = [ 0.14549723  0.08109176  0.27349747 -0.49991353]\n",
      "loss = 12.232307, w = [ 0.14549358  0.08109437  0.2734958  -0.49991626]\n",
      "loss = 12.232307, w = [ 0.14549531  0.08109316  0.2734943  -0.49991723]\n",
      "loss = 12.232326, w = [ 0.14549596  0.08109272  0.27349283 -0.4999185 ]\n",
      "loss = 12.232315, w = [ 0.14549686  0.08109205  0.27349483 -0.49991625]\n",
      "loss = 12.232307, w = [ 0.1454944   0.08109379  0.27349556 -0.49991625]\n",
      "loss = 12.232307, w = [ 0.14549517  0.08109293  0.27349526 -0.49991664]\n",
      "loss = 12.232307, w = [ 0.14549531  0.08109347  0.27349485 -0.49991636]\n",
      "loss = 12.232307, w = [ 0.14549445  0.08109376  0.27349505 -0.49991675]\n",
      "loss = 12.232309, w = [ 0.14549608  0.08109261  0.27349457 -0.49991674]\n",
      "loss = 12.232307, w = [ 0.14549486  0.08109347  0.27349493 -0.49991675]\n",
      "loss = 12.232307, w = [ 0.14549524  0.08109304  0.27349478 -0.49991693]\n",
      "loss = 12.232307, w = [ 0.14549531  0.08109331  0.27349458 -0.4999168 ]\n",
      "loss = 12.232307, w = [ 0.14549488  0.08109346  0.27349467 -0.49991699]\n",
      "loss = 12.232307, w = [ 0.14549569  0.08109289  0.27349443 -0.49991699]\n",
      "loss = 12.232307, w = [ 0.14549508  0.08109332  0.27349461 -0.49991699]\n",
      "loss = 12.232307, w = [ 0.14549527  0.0810931   0.27349454 -0.49991708]\n",
      "loss = 12.232307, w = [ 0.14549531  0.08109324  0.27349444 -0.49991702]\n",
      "loss = 12.232307, w = [ 0.14549509  0.08109331  0.27349449 -0.49991711]\n",
      "loss = 12.232307, w = [ 0.1454955   0.08109302  0.27349437 -0.49991711]\n",
      "loss = 12.232307, w = [ 0.1454952   0.08109324  0.27349446 -0.49991711]\n",
      "loss = 12.232307, w = [ 0.14549529  0.08109313  0.27349442 -0.49991716]\n",
      "loss = 12.232307, w = [ 0.14549531  0.0810932   0.27349437 -0.49991712]\n",
      "loss = 12.232307, w = [ 0.1454952   0.08109323  0.27349439 -0.49991717]\n",
      "loss = 12.232307, w = [ 0.1454954   0.08109309  0.27349433 -0.49991717]\n",
      "loss = 12.232307, w = [ 0.14549525  0.0810932   0.27349438 -0.49991717]\n",
      "loss = 12.232307, w = [ 0.1454953   0.08109315  0.27349436 -0.49991719]\n",
      "loss = 12.232307, w = [ 0.14549531  0.08109318  0.27349434 -0.49991718]\n",
      "loss = 12.232307, w = [ 0.14549525  0.0810932   0.27349435 -0.4999172 ]\n",
      "loss = 12.232307, w = [ 0.14549536  0.08109313  0.27349432 -0.4999172 ]\n",
      "loss = 12.232307, w = [ 0.14549528  0.08109318  0.27349434 -0.4999172 ]\n",
      "loss = 12.232307, w = [ 0.1454953   0.08109315  0.27349433 -0.49991721]\n",
      "loss = 12.232307, w = [ 0.14549531  0.08109317  0.27349432 -0.4999172 ]\n",
      "loss = 12.232307, w = [ 0.14549528  0.08109318  0.27349432 -0.49991722]\n",
      "loss = 12.232307, w = [ 0.14549533  0.08109314  0.27349431 -0.49991722]\n",
      "loss = 12.232307, w = [ 0.14549529  0.08109317  0.27349432 -0.49991722]\n",
      "loss = 12.232307, w = [ 0.14549531  0.08109316  0.27349432 -0.49991722]\n",
      "loss = 12.232307, w = [ 0.14549531  0.08109316  0.27349431 -0.49991722]\n",
      "loss = 12.232307, w = [ 0.14549529  0.08109317  0.27349431 -0.49991722]\n",
      "loss = 12.232307, w = [ 0.14549532  0.08109315  0.27349431 -0.49991722]\n",
      "loss = 12.232307, w = [ 0.1454953   0.08109316  0.27349431 -0.49991722]\n",
      "loss = 12.232307, w = [ 0.14549531  0.08109316  0.27349431 -0.49991723]\n",
      "loss = 12.232307, w = [ 0.14549531  0.08109316  0.27349431 -0.49991722]\n",
      "loss = 12.232307, w = [ 0.1454953   0.08109316  0.27349431 -0.49991723]\n",
      "loss = 12.232307, w = [ 0.14549531  0.08109316  0.2734943  -0.49991723]\n",
      "loss = 12.232307, w = [ 0.1454953   0.08109316  0.27349431 -0.49991723]\n",
      "loss = 12.232307, w = [ 0.14549531  0.08109316  0.27349431 -0.49991723]\n",
      "loss = 12.232307, w = [ 0.14549531  0.08109316  0.2734943  -0.49991723]\n",
      "loss = 12.232307, w = [ 0.1454953   0.08109316  0.2734943  -0.49991723]\n",
      "loss = 12.232307, w = [ 0.14549531  0.08109316  0.2734943  -0.49991723]\n",
      "loss = 12.232307, w = [ 0.14549531  0.08109316  0.2734943  -0.49991723]\n",
      "loss = 12.232307, w = [ 0.14549531  0.08109316  0.2734943  -0.49991723]\n",
      "loss = 12.232307, w = [ 0.14549531  0.08109316  0.2734943  -0.49991723]\n",
      "loss = 12.232307, w = [ 0.14549531  0.08109316  0.2734943  -0.49991723]\n",
      "loss = 12.232307, w = [ 0.14549531  0.08109316  0.2734943  -0.49991723]\n",
      "loss = 12.232307, w = [ 0.14549531  0.08109316  0.2734943  -0.49991723]\n",
      "loss = 12.232307, w = [ 0.14549531  0.08109316  0.2734943  -0.49991723]\n",
      "loss = 12.232307, w = [ 0.14549531  0.08109316  0.2734943  -0.49991723]\n",
      "loss = 12.232307, w = [ 0.14549531  0.08109316  0.2734943  -0.49991723]\n",
      "loss = 12.232307, w = [ 0.14549531  0.08109316  0.2734943  -0.49991723]\n",
      "loss = 12.232307, w = [ 0.14549531  0.08109316  0.2734943  -0.49991723]\n",
      "loss = 12.232307, w = [ 0.14549531  0.08109316  0.2734943  -0.49991723]\n",
      "loss = 12.232307, w = [ 0.14549531  0.08109316  0.2734943  -0.49991723]\n",
      "loss = 12.232307, w = [ 0.14549531  0.08109316  0.2734943  -0.49991723]\n",
      "loss = 12.232307, w = [ 0.14549531  0.08109316  0.2734943  -0.49991723]\n",
      "loss = 12.232307, w = [ 0.14549531  0.08109316  0.2734943  -0.49991723]\n",
      "loss = 12.232307, w = [ 0.14549531  0.08109316  0.2734943  -0.49991723]\n",
      "loss = 12.232307, w = [ 0.14549531  0.08109316  0.2734943  -0.49991723]\n",
      "loss = 12.232307, w = [ 0.14549531  0.08109316  0.2734943  -0.49991723]\n",
      "loss = 12.232307, w = [ 0.14549531  0.08109316  0.2734943  -0.49991723]\n",
      "loss = 12.232307, w = [ 0.14549531  0.08109316  0.2734943  -0.49991723]\n",
      "loss = 12.232307, w = [ 0.14549531  0.08109316  0.2734943  -0.49991723]\n",
      "loss = 12.232307, w = [ 0.14549531  0.08109316  0.2734943  -0.49991723]\n",
      "loss = 12.232307, w = [ 0.14549531  0.08109316  0.2734943  -0.49991723]\n",
      "loss = 12.232307, w = [ 0.14549531  0.08109316  0.2734943  -0.49991723]\n",
      "loss = 12.232307, w = [ 0.14549531  0.08109316  0.2734943  -0.49991723]\n",
      "loss = 12.232307, w = [ 0.14549531  0.08109316  0.2734943  -0.49991723]\n",
      "loss = 12.232307, w = [ 0.14549531  0.08109316  0.2734943  -0.49991723]\n",
      "loss = 12.232307, w = [ 0.14549531  0.08109316  0.2734943  -0.49991723]\n",
      "loss = 12.232307, w = [ 0.14549531  0.08109316  0.2734943  -0.49991723]\n",
      "loss = 12.232307, w = [ 0.14549531  0.08109316  0.2734943  -0.49991723]\n",
      "loss = 12.232307, w = [ 0.14549531  0.08109316  0.2734943  -0.49991723]\n",
      "loss = 12.232307, w = [ 0.14549531  0.08109316  0.2734943  -0.49991723]\n",
      "loss = 12.232307, w = [ 0.14549531  0.08109316  0.2734943  -0.49991723]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 12.232307\n",
      "         Iterations: 71\n",
      "         Function evaluations: 190\n",
      "Final weights: [ 0.14549531  0.08109316  0.2734943  -0.49991723]\n",
      "Final loss: 12.23230685708566\n"
     ]
    }
   ],
   "source": [
    "# Optimization\n",
    "w0 = (0.25, 0.25, 0.25, 0.25)\n",
    "\n",
    "w_opt, res = optimize_head_weights_L1(\n",
    "    obs_cat_df=obs_cat_valid_test,\n",
    "    w0_full=w0,\n",
    "    maxiter=500,\n",
    "    xatol=1e-3,\n",
    "    fatol=1e-4,\n",
    ")\n",
    "\n",
    "print(\"Final weights:\", w_opt)\n",
    "print(\"Final loss:\", res.fun)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732a564d-a689-4a20-a87b-d46aca3fdee4",
   "metadata": {},
   "source": [
    "#### (3) Robustness check: Matching on average video embeddings per session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "17f6de02-87fa-4b53-827f-f00b5465a2ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 10728)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract video embeddings\n",
    "\n",
    "with torch.no_grad():\n",
    "    video_emb = x_nodes[n_users:].detach().cpu().numpy()   # [num_videos, d]\n",
    "\n",
    "d_emb = video_emb.shape[1]\n",
    "d_emb, video_emb.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f6e5441b-ee03-4aea-ba6a-ea30c9bd7e70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observed embeddings for sessions: 66423\n"
     ]
    }
   ],
   "source": [
    "def build_observed_session_embeddings(df, test_idx, valid_test_sessions):\n",
    "    \"\"\"\n",
    "    df: long data with columns ['user_id', 'session', 'video_id', ...]\n",
    "    test_idx: indices of test edges (same as used in GNN)\n",
    "    valid_test_sessions: MultiIndex of (user_id, session) (sess_len>=5 & in test)\n",
    "    \"\"\"\n",
    "    # subset to test edges only\n",
    "    df_test = df.loc[test_idx, [\"user_id\", \"session\", \"video_id\"]].copy()\n",
    "    df_test[\"user_id\"] = df_test[\"user_id\"].astype(int)\n",
    "    df_test[\"session\"] = df_test[\"session\"].astype(int)\n",
    "    df_test[\"video_id\"] = df_test[\"video_id\"].astype(int)\n",
    "\n",
    "    # keep only valid test sessions\n",
    "    df_test = df_test.set_index([\"user_id\", \"session\"])\n",
    "    df_test = df_test.loc[df_test.index.intersection(valid_test_sessions)]\n",
    "    df_test = df_test.reset_index()\n",
    "\n",
    "    obs_emb = {}\n",
    "    for (uid, sess), g in df_test.groupby([\"user_id\", \"session\"]):\n",
    "        vids = g[\"video_id\"].to_numpy()\n",
    "        emb = video_emb[vids]            # [K, d]\n",
    "        mu_obs = emb.mean(axis=0)        # [d]\n",
    "        obs_emb[(int(uid), int(sess))] = mu_obs\n",
    "\n",
    "    return obs_emb\n",
    "\n",
    "# Create a dict to store avg video embeddings for each session (user_id, session)\n",
    "obs_session_emb = build_observed_session_embeddings(df, test_idx, valid_test_sessions)\n",
    "print(\"Observed embeddings for sessions:\", len(obs_session_emb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2ee452c1-9449-4b84-8243-bea82d0f7f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_simulated_session_embeddings(weights, precomputed_heads, sess_len_map):\n",
    "    \"\"\"\n",
    "    weights: array-like (4,) head weights\n",
    "    precomputed_heads: dict[(user_id, session)] -> {\"video_ids\": [V], \"probs\": [V,4]}\n",
    "    sess_len_map: Series indexed by (user_id, session) giving sess_len\n",
    "    \"\"\"\n",
    "    from copy import deepcopy\n",
    "\n",
    "    w = np.asarray(weights, dtype=float).reshape(-1)  # [4]\n",
    "\n",
    "    sim_emb = {}\n",
    "    for (uid, sess), data in precomputed_heads.items():\n",
    "        vids = data[\"video_ids\"]          # [V]\n",
    "        probs = data[\"probs\"]             # [V, 4]\n",
    "\n",
    "        # 1) score and top-K\n",
    "        scores = probs @ w                # [V]\n",
    "        K = int(sess_len_map.loc[(uid, sess)])\n",
    "        K_eff = min(K, scores.shape[0])\n",
    "\n",
    "        top_idx = np.argpartition(-scores, K_eff - 1)[:K_eff]\n",
    "        top_idx = top_idx[np.argsort(-scores[top_idx])]\n",
    "\n",
    "        rec_vids = vids[top_idx]          # [K_eff]\n",
    "\n",
    "        # 2) mean embedding\n",
    "        emb = video_emb[rec_vids]         # [K_eff, d]\n",
    "        mu_sim = emb.mean(axis=0)         # [d]\n",
    "\n",
    "        sim_emb[(int(uid), int(sess))] = mu_sim\n",
    "\n",
    "    return sim_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e1f14307-9fc5-45fb-8592-b7969bd0c0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_matching_loss(weights,\n",
    "                            obs_session_emb,\n",
    "                            precomputed_heads,\n",
    "                            sess_len_map):\n",
    "    \"\"\"\n",
    "    L_emb(w) = average squared L2 distance between\n",
    "               observed and simulated mean embeddings\n",
    "               across sessions where both are defined.\n",
    "    \"\"\"\n",
    "    # simulated embeddings for this w\n",
    "    sim_session_emb = build_simulated_session_embeddings(\n",
    "        weights, precomputed_heads, sess_len_map\n",
    "    )\n",
    "\n",
    "    # intersection of sessions\n",
    "    common_keys = set(obs_session_emb.keys()).intersection(sim_session_emb.keys())\n",
    "    if not common_keys:\n",
    "        raise ValueError(\"No overlapping sessions between observed and simulated embeddings.\")\n",
    "\n",
    "    diffs = []\n",
    "    for key in common_keys:\n",
    "        mu_obs = obs_session_emb[key]   # [d]\n",
    "        mu_sim = sim_session_emb[key]   # [d]\n",
    "        diff = mu_obs - mu_sim\n",
    "        diffs.append(np.dot(diff, diff))   # squared L2\n",
    "\n",
    "    return float(np.mean(diffs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c964fc48-cd45-498f-9348-e7be29613364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding-matching loss at w_opt: 2476.6748046875\n",
      "Run time: 8.754406213760376\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "tick = time()\n",
    "L_emb = embedding_matching_loss(\n",
    "    weights=w_opt,                       # optimized weights\n",
    "    obs_session_emb=obs_session_emb,\n",
    "    precomputed_heads=precomputed_heads_test,\n",
    "    sess_len_map=sess_len_map,\n",
    ")\n",
    "tock = time()\n",
    "print(\"Embedding-matching loss at w_opt:\", L_emb)\n",
    "print(\"Run time:\", tock-tick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "de68de0e-8c03-4436-a551-bdc650bc2152",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "import numpy as np\n",
    "\n",
    "def optimize_head_weights_L1_embed(\n",
    "    obs_session_emb,\n",
    "    precomputed_heads,\n",
    "    sess_len_map,\n",
    "    w0_full,\n",
    "    maxiter=200,\n",
    "    xatol=1e-3,\n",
    "    fatol=1e-4,\n",
    "):\n",
    "    \"\"\"\n",
    "    Optimize 4 head weights w for the embedding-matching loss:\n",
    "\n",
    "      L_emb(w) = avg_s || mu_s^obs - mu_s^sim(w) ||^2\n",
    "\n",
    "    Parametrization:\n",
    "      x = (w1_raw, w2_raw, w3_raw)\n",
    "      w4_raw = -(1 - (w1_raw + w2_raw + w3_raw))   # always negative\n",
    "      w = w_raw / sum(|w_raw|)                     # L1-normalized\n",
    "\n",
    "    Only x (first 3 raw weights) are decision variables.\n",
    "    \"\"\"\n",
    "\n",
    "    w0_full = np.asarray(w0_full, dtype=float)\n",
    "    x0 = w0_full[:3].copy()\n",
    "\n",
    "    def x_to_w(x):\n",
    "        \"\"\"Map 3-d decision variable -> 4-d normalized weights.\"\"\"\n",
    "        x1, x2, x3 = x\n",
    "        w_raw = np.array(\n",
    "            [x1, x2, x3, -(1.0 - (x1 + x2 + x3))],\n",
    "            dtype=float,\n",
    "        )\n",
    "        norm = np.sum(np.abs(w_raw))\n",
    "        if norm < 1e-8:\n",
    "            # fallback if optimizer goes crazy\n",
    "            return np.array([0.25, 0.25, 0.25, -0.25], dtype=float)\n",
    "        return w_raw / norm\n",
    "\n",
    "    def objective_3(x):\n",
    "        w = x_to_w(x)\n",
    "        L = embedding_matching_loss(\n",
    "            weights=w,\n",
    "            obs_session_emb=obs_session_emb,\n",
    "            precomputed_heads=precomputed_heads,\n",
    "            sess_len_map=sess_len_map,\n",
    "        )\n",
    "        print(f\"loss = {L:.6f}, w = {w}\")\n",
    "        return L\n",
    "\n",
    "    res = minimize(\n",
    "        objective_3,\n",
    "        x0=x0,\n",
    "        method=\"Nelder-Mead\",\n",
    "        options={\n",
    "            \"maxiter\": maxiter,\n",
    "            \"xatol\": xatol,\n",
    "            \"fatol\": fatol,\n",
    "            \"disp\": True,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # use the SAME mapping for the final weights\n",
    "    w_opt = x_to_w(res.x)\n",
    "    return w_opt, res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6f5d1568-be86-4cea-bdc5-633cde9baa46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 2476.674805, w = [ 0.14549531  0.08109316  0.2734943  -0.49991723]\n",
      "loss = 2476.633301, w = [ 0.15277007  0.08109316  0.2734943  -0.49264247]\n",
      "loss = 2476.712891, w = [ 0.14549531  0.08514782  0.2734943  -0.49586257]\n",
      "loss = 2477.350830, w = [ 0.14549531  0.08109316  0.28716902 -0.48624252]\n",
      "loss = 2475.879395, w = [ 0.15034515  0.08379626  0.25981959 -0.506039  ]\n",
      "loss = 2474.844482, w = [ 0.15277007  0.08514782  0.24614487 -0.51593724]\n",
      "loss = 2475.459961, w = [ 0.155195    0.07974161  0.25526135 -0.50980205]\n",
      "loss = 2474.547607, w = [ 0.16166145  0.08289523  0.24310605 -0.51233727]\n",
      "loss = 2473.087402, w = [ 0.16974453  0.08379626  0.22791192 -0.51854729]\n",
      "loss = 2470.986572, w = [ 0.16570299  0.0846973   0.21271779 -0.53688192]\n",
      "loss = 2463.661133, w = [ 0.17216945  0.08649937  0.18232953 -0.55900165]\n",
      "loss = 2464.105225, w = [ 0.17459437  0.09055403  0.18232953 -0.55252207]\n",
      "loss = 2446.764404, w = [ 0.19156882  0.08875196  0.14890245 -0.57077677]\n",
      "loss = 2355.878418, w = [ 0.2109682   0.09055403  0.10028124 -0.59819653]\n",
      "loss = 2245.040039, w = [ 0.20207682  0.09460869  0.08204829 -0.62126621]\n",
      "loss = 412.100342, w = [ 0.21824296  0.1000149   0.00911648 -0.67262566]\n",
      "loss = 492.333038, w = [ 0.22632603  0.09415817  0.0121553  -0.66736049]\n",
      "loss = 731.338318, w = [ 0.22023774  0.0859136  -0.08423014 -0.60961852]\n",
      "loss = 986.779907, w = [ 0.20040509  0.08244258 -0.11752033 -0.59963199]\n",
      "loss = 691.164490, w = [ 0.2111559   0.08766292 -0.0763802  -0.62480099]\n",
      "loss = 1872.365234, w = [ 0.19767603  0.09510926  0.05537415 -0.65184055]\n",
      "loss = 467.957703, w = [ 0.22064451  0.09007423 -0.05526072 -0.63402053]\n",
      "loss = 2045.487671, w = [ 0.21252494  0.09349074  0.06291494 -0.63106938]\n",
      "loss = 391.235504, w = [ 0.21748392  0.09148129 -0.04700718 -0.6440276 ]\n",
      "loss = 634.754700, w = [ 0.21008742  0.09220766 -0.07051006 -0.62719486]\n",
      "loss = 215.595810, w = [ 0.22573986  0.09528164 -0.01115063 -0.66782786]\n",
      "loss = 945.641846, w = [ 0.21139563  0.09769649  0.02601135 -0.66489653]\n",
      "loss = 289.665405, w = [ 0.22116054  0.09292286 -0.03711632 -0.64880028]\n",
      "loss = 590.639160, w = [ 0.220557    0.08579645 -0.06750264 -0.62614391]\n",
      "loss = 211.065186, w = [ 0.22180587  0.09734094 -0.01235896 -0.66849422]\n",
      "loss = 421.490234, w = [ 0.22475483  0.09745025  0.00910536 -0.66868956]\n",
      "loss = 267.361664, w = [ 0.22010009  0.0932597  -0.03413618 -0.65250403]\n",
      "loss = 275.270233, w = [ 2.23963257e-01  9.77885697e-02 -3.83669156e-04 -6.77864504e-01]\n",
      "loss = 218.115021, w = [ 0.22322169  0.09650115 -0.01010275 -0.67017441]\n",
      "loss = 529.474304, w = [ 0.22119967  0.09707616  0.013712   -0.66801216]\n",
      "loss = 208.764877, w = [ 0.22180212  0.09478008 -0.0229464  -0.6604714 ]\n",
      "loss = 204.770081, w = [ 0.22298919  0.095102   -0.02086515 -0.66104365]\n",
      "loss = 217.445892, w = [ 0.22287674  0.09442523 -0.02607094 -0.65662709]\n",
      "loss = 219.627151, w = [ 0.21877028  0.09616511 -0.02614938 -0.65891523]\n",
      "loss = 206.248688, w = [ 0.22395643  0.09550771 -0.01498863 -0.66554723]\n",
      "loss = 219.720139, w = [ 0.22398186  0.09297982 -0.02667499 -0.65636333]\n",
      "loss = 204.722717, w = [ 0.22236212  0.09622611 -0.01601855 -0.66539322]\n",
      "loss = 214.223618, w = [ 0.22443218  0.0964604  -0.01152739 -0.66758004]\n",
      "loss = 204.150299, w = [ 0.22244804  0.09519275 -0.020142   -0.66221722]\n",
      "loss = 208.844254, w = [ 0.22126723  0.09550174 -0.02298099 -0.66025004]\n",
      "loss = 203.943787, w = [ 0.22327572  0.0955062  -0.01701173 -0.66420636]\n",
      "loss = 206.636261, w = [ 0.2223969   0.09618571 -0.01455458 -0.66686282]\n",
      "loss = 203.764832, w = [ 0.22284257  0.09537028 -0.01930294 -0.66248422]\n",
      "loss = 205.696548, w = [ 0.22334128  0.09449607 -0.02159419 -0.66056846]\n",
      "loss = 203.767303, w = [ 0.22260904  0.09578983 -0.01742461 -0.66417652]\n",
      "loss = 205.277496, w = [ 0.22337409  0.09592105 -0.01566755 -0.66503731]\n",
      "loss = 203.611435, w = [ 0.22267795  0.09537356 -0.01903115 -0.66291734]\n",
      "loss = 204.159607, w = [ 0.22214794  0.09551554 -0.02015334 -0.66218318]\n",
      "loss = 203.602737, w = [ 0.22299239  0.09550855 -0.01780098 -0.66369808]\n",
      "loss = 204.025070, w = [ 0.22306475  0.09504691 -0.01999369 -0.66189466]\n",
      "loss = 203.567413, w = [ 0.22272343  0.09560336 -0.01806945 -0.66360377]\n",
      "loss = 203.836777, w = [ 0.22275285  0.09562038 -0.01729509 -0.66433167]\n",
      "loss = 203.503754, w = [ 0.22282021  0.09543261 -0.01880254 -0.66294464]\n",
      "loss = 203.832428, w = [ 0.22301322  0.09565651 -0.01741553 -0.66391474]\n",
      "loss = 203.487137, w = [ 0.22276155  0.09544412 -0.01862826 -0.66316606]\n",
      "loss = 203.737717, w = [ 0.2225451   0.09547812 -0.01919757 -0.66277921]\n",
      "loss = 203.493073, w = [ 0.22288032  0.09550092 -0.01815089 -0.66346786]\n",
      "loss = 203.576797, w = [ 0.22291774  0.09531532 -0.01898446 -0.66278248]\n",
      "loss = 203.496185, w = [ 0.22277207  0.09553124 -0.01829853 -0.66339815]\n",
      "loss = 203.551376, w = [ 0.22278903  0.09555167 -0.01791526 -0.66374405]\n",
      "loss = 203.486710, w = [ 0.22281242  0.09546233 -0.01858103 -0.66314421]\n",
      "loss = 203.483032, w = [ 0.22286406  0.09540703 -0.01860835 -0.66312057]\n",
      "loss = 203.499939, w = [ 0.22291     0.09534498 -0.01876311 -0.66298191]\n",
      "loss = 203.606323, w = [ 0.22274516  0.09537485 -0.01906001 -0.66281998]\n",
      "loss = 203.497498, w = [ 0.22284648  0.09546936 -0.01837849 -0.66330566]\n",
      "loss = 203.488647, w = [ 0.22283824  0.09543468 -0.01859469 -0.66313239]\n",
      "loss = 203.493118, w = [ 0.2228128   0.09542557 -0.01861831 -0.66314332]\n",
      "loss = 203.498749, w = [ 0.22287219  0.09545395 -0.01837973 -0.66329413]\n",
      "loss = 203.545776, w = [ 0.22280458  0.09539093 -0.01883429 -0.6629702 ]\n",
      "loss = 203.497192, w = [ 0.22285527  0.09543819 -0.01849345 -0.66321309]\n",
      "loss = 203.507202, w = [ 0.22282147  0.09540668 -0.01872073 -0.66305113]\n",
      "loss = 203.476898, w = [ 0.22284682  0.09543031 -0.01855029 -0.66317259]\n",
      "loss = 203.487778, w = [ 0.22288661  0.09542243 -0.01855058 -0.66314038]\n",
      "loss = 203.483948, w = [ 0.22289342  0.09540516 -0.01854479 -0.66315663]\n",
      "loss = 203.484970, w = [ 0.22284959  0.0954059  -0.01858504 -0.66315948]\n",
      "loss = 203.475128, w = [ 0.22285884  0.09541003 -0.01857643 -0.6631547 ]\n",
      "loss = 203.470322, w = [ 0.22281973  0.09542641 -0.01861192 -0.66314194]\n",
      "loss = 203.492798, w = [ 0.22278289  0.09543703 -0.01864548 -0.66313459]\n",
      "loss = 203.467743, w = [ 0.22281953  0.09543747 -0.01855074 -0.66319225]\n",
      "loss = 203.485123, w = [ 0.22279727  0.0954527  -0.01852193 -0.6632281 ]\n",
      "loss = 203.474747, w = [ 0.22281859  0.09541897 -0.0186091  -0.66315334]\n",
      "loss = 203.476685, w = [ 0.22277973  0.0954452  -0.01860475 -0.66317032]\n",
      "loss = 203.486069, w = [ 0.22283906  0.09541882 -0.01858351 -0.66315861]\n",
      "loss = 203.488281, w = [ 0.22281963  0.09543194 -0.01858133 -0.66316709]\n",
      "loss = 203.486526, w = [ 0.22281906  0.09542822 -0.01857992 -0.6631728 ]\n",
      "loss = 203.462616, w = [ 0.22283919  0.09542375 -0.01856358 -0.66317348]\n",
      "loss = 203.473801, w = [ 0.22283222  0.09542769 -0.01854816 -0.66319192]\n",
      "loss = 203.490173, w = [ 0.22284157  0.09543105 -0.0185284  -0.66319898]\n",
      "loss = 203.460526, w = [ 0.22282469  0.09542893 -0.01856704 -0.66317934]\n",
      "loss = 203.470367, w = [ 0.22282338  0.09543241 -0.01857275 -0.66317146]\n",
      "loss = 203.459793, w = [ 0.22282559  0.09543123 -0.0185666  -0.66317657]\n",
      "loss = 203.483932, w = [ 0.22284011  0.09541847 -0.01858074 -0.66316067]\n",
      "loss = 203.462112, w = [ 0.22282468  0.09543272 -0.01855824 -0.66318436]\n",
      "loss = 203.456619, w = [ 0.22281078  0.09543817 -0.01856434 -0.66318671]\n",
      "loss = 203.460220, w = [ 0.22279658  0.09544538 -0.01856472 -0.66319332]\n",
      "loss = 203.484467, w = [ 0.22281603  0.09543283 -0.01857375 -0.66317739]\n",
      "loss = 203.462830, w = [ 0.22282252  0.09543275 -0.01856212 -0.66318262]\n",
      "loss = 203.458786, w = [ 0.22281819  0.0954347  -0.01856547 -0.66318164]\n",
      "loss = 203.457794, w = [ 0.22281774  0.09543355 -0.01856569 -0.66318302]\n",
      "loss = 203.461853, w = [ 0.22281773  0.09543545 -0.01856129 -0.66318553]\n",
      "loss = 203.463974, w = [ 0.22281341  0.0954355  -0.01856904 -0.66318205]\n",
      "loss = 203.458969, w = [ 0.22281665  0.09543546 -0.01856323 -0.66318466]\n",
      "loss = 203.460327, w = [ 0.22281449  0.09543549 -0.0185671  -0.66318292]\n",
      "loss = 203.458435, w = [ 0.22281611  0.09543547 -0.0185642  -0.66318422]\n",
      "loss = 203.453995, w = [ 0.22281156  0.09543676 -0.01856402 -0.66318766]\n",
      "loss = 203.455811, w = [ 0.22280825  0.09543779 -0.01856329 -0.66319067]\n",
      "loss = 203.459747, w = [ 0.22281061  0.09543685 -0.01856517 -0.66318737]\n",
      "loss = 203.454330, w = [ 0.22281474  0.09543581 -0.01856444 -0.66318501]\n",
      "loss = 203.457901, w = [ 0.22280699  0.09544028 -0.01856284 -0.6631899 ]\n",
      "loss = 203.457458, w = [ 0.22281505  0.09543523 -0.01856498 -0.66318474]\n",
      "loss = 203.456497, w = [ 0.22280967  0.0954386  -0.01856355 -0.66318818]\n",
      "loss = 203.456085, w = [ 0.2228132   0.09543594 -0.01856367 -0.6631872 ]\n",
      "loss = 203.456039, w = [ 0.22281666  0.09543375 -0.01856453 -0.66318507]\n",
      "loss = 203.457458, w = [ 0.22281544  0.09543494 -0.01856499 -0.66318463]\n",
      "loss = 203.456085, w = [ 0.22281376  0.09543569 -0.018564   -0.66318655]\n",
      "loss = 203.454300, w = [ 0.22281315  0.09543629 -0.01856423 -0.66318634]\n",
      "loss = 203.454285, w = [ 0.22281411  0.09543525 -0.01856427 -0.66318637]\n",
      "loss = 203.456085, w = [ 0.22281238  0.09543635 -0.01856384 -0.66318743]\n",
      "loss = 203.458267, w = [ 0.2228135   0.09543585 -0.0185645  -0.66318615]\n",
      "loss = 203.455612, w = [ 0.22281266  0.09543622 -0.01856401 -0.66318711]\n",
      "loss = 203.456985, w = [ 0.22281322  0.09543597 -0.01856434 -0.66318647]\n",
      "loss = 203.454712, w = [ 0.2228128   0.09543616 -0.01856409 -0.66318695]\n",
      "loss = 203.454178, w = [ 0.22281308  0.09543604 -0.01856425 -0.66318663]\n",
      "loss = 203.454132, w = [ 0.22281269  0.09543574 -0.01856413 -0.66318743]\n",
      "loss = 203.454010, w = [ 0.22281078  0.09543711 -0.018564   -0.66318812]\n",
      "loss = 203.454086, w = [ 0.22281027  0.09543704 -0.01856384 -0.66318885]\n",
      "loss = 203.454163, w = [ 0.22280906  0.09543819 -0.01856377 -0.66318898]\n",
      "loss = 203.454132, w = [ 0.22281178  0.09543636 -0.01856404 -0.66318782]\n",
      "loss = 203.454025, w = [ 0.22281117  0.09543693 -0.01856401 -0.66318789]\n",
      "loss = 203.454056, w = [ 0.22281092  0.0954369  -0.01856393 -0.66318826]\n",
      "loss = 203.454178, w = [ 0.22281213  0.09543625 -0.01856407 -0.66318755]\n",
      "loss = 203.454147, w = [ 0.22281031  0.09543747 -0.01856389 -0.66318832]\n",
      "loss = 203.453857, w = [ 0.22281076  0.09543717 -0.01856394 -0.66318813]\n",
      "loss = 203.453995, w = [ 0.22281141  0.09543701 -0.01856404 -0.66318753]\n",
      "loss = 203.454208, w = [ 0.22281132  0.09543702 -0.01856399 -0.66318766]\n",
      "loss = 203.453949, w = [ 0.22281121  0.09543696 -0.018564   -0.66318783]\n",
      "loss = 203.454208, w = [ 0.22281094  0.09543691 -0.01856393 -0.66318822]\n",
      "loss = 203.453995, w = [ 0.2228113   0.09543698 -0.01856401 -0.6631877 ]\n",
      "loss = 203.453857, w = [ 0.22281099  0.09543706 -0.01856397 -0.66318798]\n",
      "loss = 203.453995, w = [ 0.22281116  0.09543696 -0.01856398 -0.6631879 ]\n",
      "loss = 203.453995, w = [ 0.22281109  0.09543709 -0.01856399 -0.66318783]\n",
      "loss = 203.454056, w = [ 0.22281085  0.09543704 -0.01856393 -0.66318817]\n",
      "loss = 203.453949, w = [ 0.22281103  0.09543708 -0.01856398 -0.66318792]\n",
      "loss = 203.453857, w = [ 0.22281069  0.09543724 -0.01856395 -0.66318812]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 203.453857\n",
      "         Iterations: 73\n",
      "         Function evaluations: 149\n",
      "Final weights (embedding loss): [ 0.22281076  0.09543717 -0.01856394 -0.66318813]\n",
      "Final embedding loss: 203.453857421875\n"
     ]
    }
   ],
   "source": [
    "# Reoptimize\n",
    "w0_embed = w_opt  # from previous optimization\n",
    "\n",
    "w_opt_embed, res_embed = optimize_head_weights_L1_embed(\n",
    "    obs_session_emb=obs_session_emb,\n",
    "    precomputed_heads=precomputed_heads_test,\n",
    "    sess_len_map=sess_len_map,\n",
    "    w0_full=w0_embed,\n",
    "    maxiter=200,\n",
    "    xatol=1e-3,\n",
    "    fatol=1e-4,\n",
    ")\n",
    "\n",
    "print(\"Final weights (embedding loss):\", w_opt_embed)\n",
    "print(\"Final embedding loss:\", res_embed.fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "01f884d6-fbb0-405e-8c58-bc0835e0a1ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.22281076,  0.09543717, -0.01856394,  0.66318813])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_opt_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "717b1428-5782-41d8-9241-b7b940b3a7bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding-matching loss at w_opt: 2439.9248046875\n",
      "Run time: 13.820978879928589\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "tick = time()\n",
    "L_emb = embedding_matching_loss(\n",
    "    weights=w_opt_embed,                       # optimized weights\n",
    "    obs_session_emb=obs_session_emb,\n",
    "    precomputed_heads=precomputed_heads_test,\n",
    "    sess_len_map=sess_len_map,\n",
    ")\n",
    "tock = time()\n",
    "print(\"Embedding-matching loss at w_opt:\", L_emb)\n",
    "print(\"Run time:\", tock-tick)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
