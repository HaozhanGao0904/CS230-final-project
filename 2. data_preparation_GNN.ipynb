{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcdc941d-e5d9-41f0-9aa7-ae5d3e538b85",
   "metadata": {},
   "source": [
    "# Data Preparation for GNN Estimation\n",
    "\n",
    "This notebook prepare data from `processed_data.parquet` and export it as `gnn_data.pt` for GNN training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12caef59-ad7a-4288-bace-953c57176482",
   "metadata": {},
   "source": [
    "### Train / validation / test split by burst\n",
    "\n",
    "We split the data by time within each burst, so that validation and test always come **after** training in calendar time.\n",
    "\n",
    "There are three bursts:\n",
    "\n",
    "| Burst | Calendar range        | # unique days | Train days (earliest) | Validation days | Test days (latest) | Rule                                      |\n",
    "|-------|-----------------------|---------------|------------------------|-----------------|--------------------|-------------------------------------------|\n",
    "| 1     | 2020-07-05 – 2020-07-12 | 8             | first 4 days           | next 2 days      | last 2 days        | 4 / 2 / 2 split over the 8 days           |\n",
    "| 2     | 2020-08-01 – 2020-08-10 | 10            | first 6 days           | next 2 days      | last 2 days        | 6 / 2 / 2 split over the 10 days          |\n",
    "| 3     | 2020-08-27 – 2020-09-05 | 10            | first 6 days           | next 2 days      | last 2 days        | 6 / 2 / 2 split over the 10 days          |\n",
    "\n",
    "Implementation details:\n",
    "\n",
    "- For each burst, I sort interactions by `time` and extract the unique calendar days in that burst.\n",
    "- I assign the earliest days to the training set, the middle days to the validation set, and the latest days to the test set, according to the ratios above.\n",
    "- The same time-based split is used for all models (gradient boosting, standard NN, and GNN), so their performance is directly comparable.\n",
    "- The training set has 0.8 million observations, and the validation and test sets each have 0.2 million.\n",
    "- A tiny subsample contains 10% of the edges is generated for a test run.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074d44e5-ee55-403c-a14d-9ac44c66cb80",
   "metadata": {},
   "source": [
    "### Features used for prediction:\n",
    "\n",
    "| Feature                     | Description                                                                                 |\n",
    "|-----------------------------|---------------------------------------------------------------------------------------------|\n",
    "| burst_id                    | Burst window identifier (1st, 2nd, or 3rd data burst).                                     |\n",
    "| session                     | Session ID for the user’s viewing session.                                                 |\n",
    "| u_user_active_degree        | Categorical user activity level (e.g., low / medium / high).                              |\n",
    "| u_is_lowactive_period       | Indicator if the user is in a low-activity period.                                         |\n",
    "| u_is_live_streamer          | Indicator if the user has ever done live streaming.                                        |\n",
    "| u_is_video_author           | Indicator if the user is also a content creator (has uploaded videos).                    |\n",
    "| u_follow_user_num           | Number of users this user follows.                                                         |\n",
    "| u_follow_user_num_range     | Binned range of `u_follow_user_num`.                                                       |\n",
    "| u_fans_user_num             | Number of followers (fans) this user has.                                                  |\n",
    "| u_fans_user_num_range       | Binned range of `u_fans_user_num`.                                                         |\n",
    "| u_friend_user_num           | Number of friends (mutual relationships).                                                  |\n",
    "| u_friend_user_num_range     | Binned range of `u_friend_user_num`.                                                       |\n",
    "| u_register_days             | Days since user registration at the time of interaction.                                   |\n",
    "| u_register_days_range       | Binned range of `u_register_days`.                                                         |\n",
    "| u_onehot_feat0-17           | Encrypted user categorical features.                                                       |\n",
    "| u_follow_user_num_log1p     | Log1p-transformed number of users the user follows.                                        |\n",
    "| u_fans_user_num_log1p       | Log1p-transformed number of followers (fans).                                              |\n",
    "| u_friend_user_num_log1p     | Log1p-transformed number of friends.                                                       |\n",
    "| u_register_days_log1p       | Log1p-transformed days since registration.                                                 |\n",
    "| i_aspect_ratio              | Video aspect ratio (height / width).                                                       |\n",
    "| i_author_id                 | Encoded ID of the video’s author.                                                          |\n",
    "| i_video_type                | Encoded video type (e.g., normal / live / other).                                          |\n",
    "| i_upload_type               | Encoded upload type (e.g., original / re-upload).                                          |\n",
    "| i_visible_status            | Encoded visibility status (e.g., public / private / limited).                             |\n",
    "| i_music_id                  | Encoded ID of background music used in the video.                                          |\n",
    "| i_video_tag_id              | Encoded tag ID associated with the video.                                                  |\n",
    "| i_video_tag_name            | Encoded tag-name category for the video.                                                   |\n",
    "| i_video_duration            | Video duration (seconds).                                                                  |\n",
    "| i_age_since_upload_days     | Days since the video was uploaded.                                                         |\n",
    "| i_cat_level1_id             | Encoded top-level content category ID.                                                     |\n",
    "| i_cat_level2_id             | Encoded mid-level content category ID.                                                     |\n",
    "| i_cat_level3_id             | Encoded fine-grained content category ID.                                                  |\n",
    "| ctx_hour_sin                | Sine transform of local watch hour (time-of-day feature).                                  |\n",
    "| ctx_hour_cos                | Cosine transform of local watch hour (time-of-day feature).                                |\n",
    "| ctx_is_weekend              | Indicator if the interaction happens on a weekend.                                         |\n",
    "| hist_ema_y_complete         | Per-user EMA of past completion events before this interaction.                           |\n",
    "| hist_ema_y_long             | Per-user EMA of past long-watch events before this interaction.                           |\n",
    "| hist_ema_y_rewatch          | Per-user EMA of past rewatch events before this interaction.                              |\n",
    "| hist_ema_y_neg              | Per-user EMA of past negative-feedback events before this interaction.                    |\n",
    "| hist_ema_watchratio         | Per-user EMA of past watch ratios before this interaction.                                 |\n",
    "| hist_cat_ema_complete       | Per-user & category EMA of past completion events.                                         |\n",
    "| hist_cat_entropy_l2         | Entropy-based measure of user’s category diversity (L2-regularized).                      |\n",
    "| hist_author_recency_days    | Days since the user last watched this author before this interaction.                      |\n",
    "| hist_last_complete_author   | Indicator if the last video from this author was completed by the user.                   |\n",
    "| hist_has_author_history     | Indicator if the user has any prior interaction history with this author.                 |\n",
    "| hist_prev_sess_len          | Length of the previous session for this user.                                              |\n",
    "| hist_intersess_gap_h        | Time gap (hours) between the previous session end and current interaction.                 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fafb2fe-a1a5-4e49-8da7-a68e666a4f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "BASE = Path(\"/Users/haozhangao/Desktop/RecSys Research/KuaiRec 2.0/data/processed/\")\n",
    "\n",
    "INPUT_PATH = BASE / \"processed_data.parquet\"\n",
    "OUTPUT_PATH = BASE / \"gnn_data.pt\"\n",
    "\n",
    "df = pd.read_parquet(INPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a60aa72-2fb0-40fc-a15c-64211a9f212d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of users: 7176 number of videos 10728\n",
      "Feature columns used:\n",
      " ['burst_id', 'session', 'u_user_active_degree', 'u_is_lowactive_period', 'u_is_live_streamer', 'u_is_video_author', 'u_follow_user_num', 'u_follow_user_num_range', 'u_fans_user_num', 'u_fans_user_num_range', 'u_friend_user_num', 'u_friend_user_num_range', 'u_register_days', 'u_register_days_range', 'u_onehot_feat0', 'u_onehot_feat1', 'u_onehot_feat2', 'u_onehot_feat3', 'u_onehot_feat4', 'u_onehot_feat5', 'u_onehot_feat6', 'u_onehot_feat7', 'u_onehot_feat8', 'u_onehot_feat9', 'u_onehot_feat10', 'u_onehot_feat11', 'u_onehot_feat12', 'u_onehot_feat13', 'u_onehot_feat14', 'u_onehot_feat15', 'u_onehot_feat16', 'u_onehot_feat17', 'u_follow_user_num_log1p', 'u_fans_user_num_log1p', 'u_friend_user_num_log1p', 'u_register_days_log1p', 'i_aspect_ratio', 'i_author_id', 'i_video_type', 'i_upload_type', 'i_visible_status', 'i_music_id', 'i_video_tag_id', 'i_video_tag_name', 'i_video_duration', 'i_age_since_upload_days', 'i_cat_level1_id', 'i_cat_level2_id', 'i_cat_level3_id', 'ctx_hour_sin', 'ctx_hour_cos', 'ctx_is_weekend', 'hist_ema_y_complete', 'hist_ema_y_long', 'hist_ema_y_rewatch', 'hist_ema_y_neg', 'hist_ema_watchratio', 'hist_cat_ema_complete', 'hist_cat_entropy_l2', 'hist_author_recency_days', 'hist_last_complete_author', 'hist_has_author_history', 'hist_prev_sess_len', 'hist_intersess_gap_h']\n",
      "number of edges: 12527912\n",
      "edge_index shape: (2, 12527912)\n",
      "edge_features shape: (12527912, 64)\n",
      "y shape: (12527912, 4)\n"
     ]
    }
   ],
   "source": [
    "# Basic counts\n",
    "n_users = df[\"user_id\"].max() + 1\n",
    "n_videos = df[\"video_id\"].max() + 1\n",
    "print(\"number of users:\", n_users, \"number of videos\", n_videos)\n",
    "\n",
    "# Labels (4 heads)\n",
    "label_cols = [\"y_complete\", \"y_long\", \"y_rewatch\", \"y_neg\"]\n",
    "y = df[label_cols].to_numpy().astype(\"float32\")\n",
    "\n",
    "# Edge index\n",
    "src = df[\"user_id\"].to_numpy() # source\n",
    "dst = n_users + df[\"video_id\"].to_numpy() # destination (avoid index overlapping)\n",
    "edge_index = np.vstack([src, dst]) # [2, num_edges]\n",
    "\n",
    "# Encode categorical columns to integers\n",
    "cat_cols = df.select_dtypes(include=\"category\").columns.tolist()\n",
    "for c in cat_cols:\n",
    "    df[c] = df[c].cat.codes.astype(\"int32\")\n",
    "\n",
    "# Exclude irrelevant columns\n",
    "cols_to_exclude = [\n",
    "    \"user_id\", \"video_id\",\n",
    "    \"time\",\n",
    "    \"date\", \"timestamp\",\n",
    "    \"play_duration\", \"watch_ratio\", \"sess_rank\", \"sess_len\",\n",
    "] + label_cols\n",
    "\n",
    "numeric_feature_cols = [c for c in df.columns if c not in cols_to_exclude and pd.api.types.is_numeric_dtype(df[c]) ]\n",
    "\n",
    "print(\"Feature columns used:\\n\", numeric_feature_cols)\n",
    "\n",
    "edge_features = df[numeric_feature_cols].to_numpy().astype(\"float32\")\n",
    "num_edges = edge_index.shape[1]\n",
    "\n",
    "\n",
    "\n",
    "print(\"number of edges:\", num_edges)\n",
    "print(\"edge_index shape:\", edge_index.shape)\n",
    "print(\"edge_features shape:\", edge_features.shape)\n",
    "print(\"y shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2779be1-e1d8-4adb-b415-59db6836ff80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/valid/test set sizes: 8016340 2382507 2129065\n",
      "Overlap between training and valid sets 0\n",
      "Overlap between training and test sets: 0\n",
      "Overlap between valid and test sets: 0\n"
     ]
    }
   ],
   "source": [
    "# Define training/validation/test sets\n",
    "\n",
    "time_dates = df[\"time\"].dt.normalize()\n",
    "\n",
    "train_mask = np.zeros(num_edges, dtype=bool)\n",
    "valid_mask = np.zeros(num_edges, dtype=bool)\n",
    "test_mask = np.zeros(num_edges, dtype=bool)\n",
    "\n",
    "burst_ranges = [\n",
    "    (\"2020-07-05\", \"2020-07-12\"),  # burst 1 (8 days)\n",
    "    (\"2020-08-01\", \"2020-08-10\"),  # burst 2 (10 days)\n",
    "    (\"2020-08-27\", \"2020-09-05\"),  # burst 3 (10 days)\n",
    "]\n",
    "\n",
    "for start_str, end_str in burst_ranges:\n",
    "    start = pd.to_datetime(start_str)\n",
    "    end = pd.to_datetime(end_str)\n",
    "\n",
    "    in_burst = (time_dates >= start) & (time_dates <= end)\n",
    "    burst_indx = np.where(in_burst)[0]\n",
    "\n",
    "    # Count unique days inside each burst\n",
    "    burst_days = np.sort(time_dates[in_burst].unique())\n",
    "    n_days = len(burst_days)\n",
    "\n",
    "    # Data split: 4/2/2 or 6/2/2\n",
    "    if n_days == 8:\n",
    "        n_train_days, n_valid_days, n_test_days = 4, 2, 2\n",
    "    elif n_days == 10:\n",
    "        n_train_days, n_valid_days, n_test_days = 6, 2, 2\n",
    "    else:\n",
    "        raise ValueError(f\"Burst {start_str}-{end_str} has {n_days}, not 8 or 10.\")\n",
    "\n",
    "    train_days = set(burst_days[:n_train_days])\n",
    "    valid_days = set(burst_days[n_train_days:n_train_days+n_valid_days])\n",
    "    test_days = set(burst_days[n_train_days+n_valid_days:n_train_days+n_valid_days+n_test_days])\n",
    "\n",
    "    # Update masks\n",
    "    train_mask |= in_burst & time_dates.isin(train_days)\n",
    "    valid_mask |= in_burst & time_dates.isin(valid_days)\n",
    "    test_mask |= in_burst & time_dates.isin(test_days)\n",
    "\n",
    "# Convert masks to index\n",
    "\n",
    "train_idx = np.where(train_mask)[0]\n",
    "valid_idx = np.where(valid_mask)[0]\n",
    "test_idx = np.where(test_mask)[0]\n",
    "\n",
    "print(\"train/valid/test set sizes:\", len(train_idx), len(valid_idx), len(test_idx))\n",
    "\n",
    "# Sanity check by testing overlapping\n",
    "print(\"Overlap between training and valid sets\", np.sum(train_mask & valid_mask))\n",
    "print(\"Overlap between training and test sets:\", np.sum(train_mask & test_mask))\n",
    "print(\"Overlap between valid and test sets:\", np.sum(valid_mask & test_mask))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bd15050-af65-4d4d-a6a7-e12fa59bd34e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge_idx_t: torch.Size([2, 12527912])\n",
      "edge_attr_t: torch.Size([12527912, 64])\n",
      "y_t: torch.Size([12527912, 4])\n"
     ]
    }
   ],
   "source": [
    "# Convert everything to torch tensors\n",
    "edge_index_t = torch.from_numpy(edge_index).long() # [2, E]\n",
    "edge_attr_t = torch.from_numpy(edge_features) # [E, D]\n",
    "y_t = torch.from_numpy(y) # [E, 4]\n",
    "\n",
    "train_idx_t = torch.from_numpy(train_idx).long()\n",
    "valid_idx_t = torch.from_numpy(valid_idx).long()\n",
    "test_idx_t = torch.from_numpy(test_idx).long()\n",
    "\n",
    "print(\"edge_idx_t:\", edge_index_t.shape)\n",
    "print(\"edge_attr_t:\", edge_attr_t.shape)\n",
    "print(\"y_t:\", y_t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f604efb8-7a74-4fe6-ae6d-68a5842cc34e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_nodes: 17904 num_edge_features: 64\n",
      "Saved GNN data to /Users/haozhangao/Desktop/RecSys Research/KuaiRec 2.0/data/processed/gnn_data.pt\n"
     ]
    }
   ],
   "source": [
    "# Number of nodes = users + videos\n",
    "num_nodes = int(n_users + n_videos)\n",
    "num_edge_features = edge_attr_t.shape[1]\n",
    "\n",
    "gnn_data = {\n",
    "    \"edge_index\": edge_index_t,       # [2, E]\n",
    "    \"edge_attr\": edge_attr_t,         # [E, D]\n",
    "    \"y\": y_t,                         # [E, 4]\n",
    "    \"train_idx\": train_idx_t,         # [E_train]\n",
    "    \"val_idx\": valid_idx_t,           # [E_val]\n",
    "    \"test_idx\": test_idx_t,           # [E_test]\n",
    "    \"n_users\": int(n_users),\n",
    "    \"n_items\": int(n_videos),\n",
    "    \"num_nodes\": num_nodes,\n",
    "    \"num_edge_features\": num_edge_features,\n",
    "    \"feature_names\": numeric_feature_cols\n",
    "}\n",
    "\n",
    "torch.save(gnn_data, OUTPUT_PATH)\n",
    "print(\"num_nodes:\", num_nodes, \"num_edge_features:\", num_edge_features)\n",
    "print(\"Saved GNN data to\", OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc09eadb-c71e-408d-9bb1-3d36200565f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original num edges: 12527912\n",
      "Subsampled num edges: 626395\n",
      "tiny train/val/test sizes: 501116 62639 62640\n",
      "num_nodes_small: 17898\n",
      "Saved tiny data to: /Users/haozhangao/Desktop/RecSys Research/KuaiRec 2.0/data/processed/gnn_data_tiny.pt\n"
     ]
    }
   ],
   "source": [
    "# Create a tiny sample for sanity check\n",
    "\n",
    "D_edge = edge_attr_t.shape[1]\n",
    "E = edge_index_t.shape[1]\n",
    "print(\"Original num edges:\", E)\n",
    "\n",
    "# 1) Choose a fraction of edges to keep\n",
    "frac = 0.05   # 10% of edges\n",
    "k = max(1, int(frac * E))\n",
    "\n",
    "# Randomly pick k edges\n",
    "perm_edges = torch.randperm(E)[:k]\n",
    "\n",
    "edge_index_small = edge_index_t[:, perm_edges]   # [2, k]\n",
    "edge_attr_small  = edge_attr_t[perm_edges]       # [k, D_edge]\n",
    "y_small          = y_t[perm_edges]               # [k, 4]\n",
    "\n",
    "print(\"Subsampled num edges:\", k)\n",
    "\n",
    "# 2) Make NEW random train/val/test split for this tiny graph\n",
    "num_edges_small = k\n",
    "perm = torch.randperm(num_edges_small)\n",
    "\n",
    "n_train = int(0.8 * num_edges_small)\n",
    "n_val   = int(0.1 * num_edges_small)\n",
    "n_test  = num_edges_small - n_train - n_val\n",
    "\n",
    "train_idx_small = perm[:n_train]\n",
    "val_idx_small   = perm[n_train:n_train + n_val]\n",
    "test_idx_small  = perm[n_train + n_val:]\n",
    "\n",
    "print(\"tiny train/val/test sizes:\",\n",
    "      train_idx_small.shape[0],\n",
    "      val_idx_small.shape[0],\n",
    "      test_idx_small.shape[0])\n",
    "\n",
    "# 3) Figure out the new num_nodes\n",
    "num_nodes_small = int(edge_index_small.max().item() + 1)\n",
    "print(\"num_nodes_small:\", num_nodes_small)\n",
    "\n",
    "# 4) Save a tiny dataset\n",
    "tiny_data = {\n",
    "    \"edge_index\": edge_index_small,\n",
    "    \"edge_attr\": edge_attr_small,\n",
    "    \"y\": y_small,\n",
    "    \"train_idx\": train_idx_small,\n",
    "    \"val_idx\": val_idx_small,\n",
    "    \"test_idx\": test_idx_small,\n",
    "    \"num_nodes\": num_nodes_small,\n",
    "    \"num_edge_features\": D_edge,\n",
    "    \"feature_names\": numeric_feature_cols\n",
    "}\n",
    "\n",
    "OUT_PATH_tiny = BASE / \"gnn_data_tiny.pt\"\n",
    "torch.save(tiny_data, OUT_PATH_tiny)\n",
    "print(\"Saved tiny data to:\", OUT_PATH_tiny)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
