{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fba49ea-52d8-498f-b23d-ec3a3a0a6b94",
   "metadata": {},
   "source": [
    "# GNN Model Training\n",
    "\n",
    "This notebook trains the GNN model as well as two baseline models (logistic regression, edge-only MLP neural network) for performance comparison.\n",
    "\n",
    "The estimated parameters are saved in `{model_name}_multihead_best.pt`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff1d0ad-f880-42fa-b783-fa393b12f889",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 1. Import data and feature normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc315d46-67bb-456d-a655-87a1e533b53a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge_attr shape: torch.Size([626395, 64]) y_shape torch.Size([626395, 4])\n",
      "NaN in edge_attr: False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from pathlib import Path\n",
    "from torch_geometric.nn import GCNConv\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load data and convert NaN features to 0\n",
    "BASE = Path(\"/Users/haozhangao/Desktop/RecSys Research/KuaiRec 2.0/data/processed/\")\n",
    "\n",
    "DATA_PATH = BASE / \"gnn_data_tiny.pt\"\n",
    "# DATA_PATH = BASE / \"gnn_data.pt\"\n",
    "data = torch.load(DATA_PATH)\n",
    "\n",
    "edge_index = data[\"edge_index\"]       # [2, E]\n",
    "edge_attr  = data[\"edge_attr\"]        # [E, D_edge]\n",
    "y_all      = data[\"y\"]                # [E, 4]\n",
    "train_idx  = data[\"train_idx\"]\n",
    "val_idx    = data[\"val_idx\"]\n",
    "test_idx   = data[\"test_idx\"]\n",
    "num_nodes  = data[\"num_nodes\"]\n",
    "D_edge     = data[\"num_edge_features\"]\n",
    "numeric_feature_cols = data[\"feature_names\"]\n",
    "\n",
    "edge_attr = torch.nan_to_num(edge_attr, nan=0.0)\n",
    "\n",
    "print(\"edge_attr shape:\", edge_attr.shape, \"y_shape\", y_all.shape)\n",
    "print(\"NaN in edge_attr:\", torch.isnan(edge_attr).any().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb169f1a-e7ec-4e7b-90fe-17af42bfa620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Normalization (compute mean and std on training set only)\n",
    "with torch.no_grad():\n",
    "    mu = edge_attr[train_idx].mean(dim=0, keepdim=True)\n",
    "    std = edge_attr[train_idx].std(dim=0, keepdim=True)\n",
    "    std[std < 1e-6] = 1.0\n",
    "\n",
    "    edge_attr = (edge_attr - mu)  / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41751d1d-c874-4506-b0a2-4ed7061cf80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "edge_index = edge_index.to(device)\n",
    "edge_attr = edge_attr.to(device)\n",
    "y_all = y_all.to(device)\n",
    "train_idx  = train_idx.to(device)\n",
    "val_idx    = val_idx.to(device)\n",
    "test_idx   = test_idx.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829fd286-b582-48cf-9639-45eb5e4f0da0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 2. Baseline model 1: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3583cac2-d5b3-41d3-aeb2-a18c570fe80d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------\n",
      "Logistic Regression result for y_complete:\n",
      "--------------------------------------------\n",
      "Train positives rate: 0.33711955\n",
      "Val   positives rate: 0.33672312\n",
      "Test  positives rate: 0.3394636\n",
      "Logistic baseline AUCs:\n",
      "  train AUC = 0.8268\n",
      "  val   AUC = 0.8239\n",
      "  test  AUC = 0.8297\n",
      "\n",
      "\n",
      "Top 20 most predictive features (by |coef|):\n",
      "                      feature      coef\n",
      "44           i_video_duration -4.612000\n",
      "52        hist_ema_y_complete  0.444310\n",
      "60  hist_last_complete_author  0.374057\n",
      "53            hist_ema_y_long  0.277467\n",
      "61    hist_has_author_history -0.253496\n",
      "57      hist_cat_ema_complete  0.135094\n",
      "45    i_age_since_upload_days -0.046970\n",
      "39              i_upload_type -0.041875\n",
      "38               i_video_type -0.041218\n",
      "54         hist_ema_y_rewatch -0.040980\n",
      "0                    burst_id  0.037453\n",
      "55             hist_ema_y_neg -0.036345\n",
      "34    u_friend_user_num_log1p -0.032266\n",
      "50               ctx_hour_cos  0.026199\n",
      "11    u_friend_user_num_range  0.020477\n",
      "47            i_cat_level2_id -0.020176\n",
      "12            u_register_days  0.019547\n",
      "33      u_fans_user_num_log1p  0.019352\n",
      "9       u_fans_user_num_range -0.018386\n",
      "49               ctx_hour_sin -0.016979\n",
      "\n",
      "Top 10 features with positive coefficients:\n",
      "                      feature      coef\n",
      "52        hist_ema_y_complete  0.444310\n",
      "60  hist_last_complete_author  0.374057\n",
      "53            hist_ema_y_long  0.277467\n",
      "57      hist_cat_ema_complete  0.135094\n",
      "0                    burst_id  0.037453\n",
      "50               ctx_hour_cos  0.026199\n",
      "11    u_friend_user_num_range  0.020477\n",
      "12            u_register_days  0.019547\n",
      "33      u_fans_user_num_log1p  0.019352\n",
      "41                 i_music_id  0.016621\n",
      "\n",
      "Top 10 features with negative coefficients:\n",
      "                    feature      coef\n",
      "44         i_video_duration -4.612000\n",
      "61  hist_has_author_history -0.253496\n",
      "45  i_age_since_upload_days -0.046970\n",
      "39            i_upload_type -0.041875\n",
      "38             i_video_type -0.041218\n",
      "54       hist_ema_y_rewatch -0.040980\n",
      "55           hist_ema_y_neg -0.036345\n",
      "34  u_friend_user_num_log1p -0.032266\n",
      "47          i_cat_level2_id -0.020176\n",
      "9     u_fans_user_num_range -0.018386\n",
      "\n",
      "--------------------------------------------\n",
      "Logistic Regression result for y_long:\n",
      "--------------------------------------------\n",
      "Train positives rate: 0.21521364\n",
      "Val   positives rate: 0.21451493\n",
      "Test  positives rate: 0.21467113\n",
      "Logistic baseline AUCs:\n",
      "  train AUC = 0.7703\n",
      "  val   AUC = 0.7697\n",
      "  test  AUC = 0.7718\n",
      "\n",
      "\n",
      "Top 20 most predictive features (by |coef|):\n",
      "                      feature      coef\n",
      "53            hist_ema_y_long  0.922465\n",
      "60  hist_last_complete_author  0.270519\n",
      "61    hist_has_author_history -0.208455\n",
      "44           i_video_duration -0.126565\n",
      "57      hist_cat_ema_complete  0.122784\n",
      "45    i_age_since_upload_days -0.074821\n",
      "55             hist_ema_y_neg  0.066012\n",
      "1                     session  0.064901\n",
      "47            i_cat_level2_id -0.039391\n",
      "46            i_cat_level1_id  0.036809\n",
      "40           i_visible_status -0.030481\n",
      "62         hist_prev_sess_len -0.029145\n",
      "50               ctx_hour_cos  0.028323\n",
      "15             u_onehot_feat1  0.027339\n",
      "52        hist_ema_y_complete -0.026120\n",
      "32    u_follow_user_num_log1p  0.025442\n",
      "43           i_video_tag_name  0.022051\n",
      "36             i_aspect_ratio  0.020760\n",
      "12            u_register_days  0.019812\n",
      "48            i_cat_level3_id -0.019614\n",
      "\n",
      "Top 10 features with positive coefficients:\n",
      "                      feature      coef\n",
      "53            hist_ema_y_long  0.922465\n",
      "60  hist_last_complete_author  0.270519\n",
      "57      hist_cat_ema_complete  0.122784\n",
      "55             hist_ema_y_neg  0.066012\n",
      "1                     session  0.064901\n",
      "46            i_cat_level1_id  0.036809\n",
      "50               ctx_hour_cos  0.028323\n",
      "15             u_onehot_feat1  0.027339\n",
      "32    u_follow_user_num_log1p  0.025442\n",
      "43           i_video_tag_name  0.022051\n",
      "\n",
      "Top 10 features with negative coefficients:\n",
      "                    feature      coef\n",
      "61  hist_has_author_history -0.208455\n",
      "44         i_video_duration -0.126565\n",
      "45  i_age_since_upload_days -0.074821\n",
      "47          i_cat_level2_id -0.039391\n",
      "40         i_visible_status -0.030481\n",
      "62       hist_prev_sess_len -0.029145\n",
      "52      hist_ema_y_complete -0.026120\n",
      "48          i_cat_level3_id -0.019614\n",
      "35    u_register_days_log1p -0.019478\n",
      "6         u_follow_user_num -0.018033\n",
      "\n",
      "--------------------------------------------\n",
      "Logistic Regression result for y_rewatch:\n",
      "--------------------------------------------\n",
      "Train positives rate: 0.07480104\n",
      "Val   positives rate: 0.0745063\n",
      "Test  positives rate: 0.07434547\n",
      "Logistic baseline AUCs:\n",
      "  train AUC = 0.8304\n",
      "  val   AUC = 0.8307\n",
      "  test  AUC = 0.8315\n",
      "\n",
      "\n",
      "Top 20 most predictive features (by |coef|):\n",
      "                      feature      coef\n",
      "44           i_video_duration -5.272667\n",
      "53            hist_ema_y_long  0.517007\n",
      "54         hist_ema_y_rewatch  0.383262\n",
      "52        hist_ema_y_complete -0.209663\n",
      "61    hist_has_author_history -0.202849\n",
      "60  hist_last_complete_author  0.195748\n",
      "1                     session  0.159731\n",
      "45    i_age_since_upload_days -0.129758\n",
      "55             hist_ema_y_neg  0.104530\n",
      "15             u_onehot_feat1  0.072921\n",
      "0                    burst_id -0.071116\n",
      "32    u_follow_user_num_log1p  0.070579\n",
      "62         hist_prev_sess_len -0.065614\n",
      "34    u_friend_user_num_log1p -0.062875\n",
      "57      hist_cat_ema_complete  0.057037\n",
      "39              i_upload_type -0.050253\n",
      "50               ctx_hour_cos  0.040697\n",
      "47            i_cat_level2_id -0.033713\n",
      "41                 i_music_id -0.033017\n",
      "56        hist_ema_watchratio  0.032822\n",
      "\n",
      "Top 10 features with positive coefficients:\n",
      "                      feature      coef\n",
      "53            hist_ema_y_long  0.517007\n",
      "54         hist_ema_y_rewatch  0.383262\n",
      "60  hist_last_complete_author  0.195748\n",
      "1                     session  0.159731\n",
      "55             hist_ema_y_neg  0.104530\n",
      "15             u_onehot_feat1  0.072921\n",
      "32    u_follow_user_num_log1p  0.070579\n",
      "57      hist_cat_ema_complete  0.057037\n",
      "50               ctx_hour_cos  0.040697\n",
      "56        hist_ema_watchratio  0.032822\n",
      "\n",
      "Top 10 features with negative coefficients:\n",
      "                    feature      coef\n",
      "44         i_video_duration -5.272667\n",
      "52      hist_ema_y_complete -0.209663\n",
      "61  hist_has_author_history -0.202849\n",
      "45  i_age_since_upload_days -0.129758\n",
      "0                  burst_id -0.071116\n",
      "62       hist_prev_sess_len -0.065614\n",
      "34  u_friend_user_num_log1p -0.062875\n",
      "39            i_upload_type -0.050253\n",
      "47          i_cat_level2_id -0.033713\n",
      "41               i_music_id -0.033017\n",
      "\n",
      "--------------------------------------------\n",
      "Logistic Regression result for y_neg:\n",
      "--------------------------------------------\n",
      "Train positives rate: 0.12530033\n",
      "Val   positives rate: 0.12624723\n",
      "Test  positives rate: 0.12311622\n",
      "Logistic baseline AUCs:\n",
      "  train AUC = 0.8588\n",
      "  val   AUC = 0.8573\n",
      "  test  AUC = 0.8617\n",
      "\n",
      "\n",
      "Top 20 most predictive features (by |coef|):\n",
      "                      feature      coef\n",
      "55             hist_ema_y_neg  1.123156\n",
      "60  hist_last_complete_author -0.157064\n",
      "53            hist_ema_y_long  0.133740\n",
      "61    hist_has_author_history  0.097259\n",
      "1                     session  0.072920\n",
      "0                    burst_id -0.071050\n",
      "32    u_follow_user_num_log1p  0.068427\n",
      "57      hist_cat_ema_complete -0.066002\n",
      "25            u_onehot_feat11  0.055935\n",
      "50               ctx_hour_cos -0.049379\n",
      "54         hist_ema_y_rewatch  0.047363\n",
      "49               ctx_hour_sin  0.045856\n",
      "18             u_onehot_feat4 -0.026507\n",
      "34    u_friend_user_num_log1p -0.026235\n",
      "6           u_follow_user_num -0.025935\n",
      "15             u_onehot_feat1  0.025365\n",
      "63       hist_intersess_gap_h -0.024149\n",
      "9       u_fans_user_num_range  0.022995\n",
      "29            u_onehot_feat15 -0.022150\n",
      "24            u_onehot_feat10  0.021385\n",
      "\n",
      "Top 10 features with positive coefficients:\n",
      "                    feature      coef\n",
      "55           hist_ema_y_neg  1.123156\n",
      "53          hist_ema_y_long  0.133740\n",
      "61  hist_has_author_history  0.097259\n",
      "1                   session  0.072920\n",
      "32  u_follow_user_num_log1p  0.068427\n",
      "25          u_onehot_feat11  0.055935\n",
      "54       hist_ema_y_rewatch  0.047363\n",
      "49             ctx_hour_sin  0.045856\n",
      "15           u_onehot_feat1  0.025365\n",
      "9     u_fans_user_num_range  0.022995\n",
      "\n",
      "Top 10 features with negative coefficients:\n",
      "                      feature      coef\n",
      "60  hist_last_complete_author -0.157064\n",
      "0                    burst_id -0.071050\n",
      "57      hist_cat_ema_complete -0.066002\n",
      "50               ctx_hour_cos -0.049379\n",
      "18             u_onehot_feat4 -0.026507\n",
      "34    u_friend_user_num_log1p -0.026235\n",
      "6           u_follow_user_num -0.025935\n",
      "63       hist_intersess_gap_h -0.024149\n",
      "29            u_onehot_feat15 -0.022150\n",
      "23             u_onehot_feat9 -0.018250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Baseline 1: logistic regression \n",
    "\n",
    "head_names = [\"y_complete\", \"y_long\", \"y_rewatch\", \"y_neg\"]\n",
    "\n",
    "# Move tensors to CPU\n",
    "edge_attr_np = edge_attr.detach().cpu().numpy()\n",
    "y_np         = y_all.detach().cpu().numpy()\n",
    "train_idx_np = np.asarray(train_idx.cpu())\n",
    "val_idx_np   = np.asarray(val_idx.cpu())\n",
    "test_idx_np  = np.asarray(test_idx.cpu())\n",
    "\n",
    "# Build feature matrix and standardize\n",
    "X_train = edge_attr_np[train_idx_np]\n",
    "X_val   = edge_attr_np[val_idx_np]\n",
    "X_test  = edge_attr_np[test_idx_np]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_std = scaler.fit_transform(X_train)\n",
    "X_val_std   = scaler.transform(X_val)\n",
    "X_test_std  = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "for head_idx in range(len(head_names)):\n",
    "    y_train = y_np[train_idx_np, head_idx]\n",
    "    y_val   = y_np[val_idx_np,   head_idx]\n",
    "    y_test  = y_np[test_idx_np,  head_idx]\n",
    "\n",
    "    print(\"--------------------------------------------\")\n",
    "    print(f\"Logistic Regression result for {head_names[head_idx]}:\")\n",
    "    print(\"--------------------------------------------\")\n",
    "    print(\"Train positives rate:\", y_train.mean())\n",
    "    print(\"Val   positives rate:\", y_val.mean())\n",
    "    print(\"Test  positives rate:\", y_test.mean())\n",
    "    \n",
    "    log_reg = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    n_jobs=1,\n",
    "    )\n",
    "           \n",
    "    log_reg.fit(X_train_std, y_train)\n",
    "\n",
    "    train_probs = log_reg.predict_proba(X_train_std)[:, 1]\n",
    "    val_probs   = log_reg.predict_proba(X_val_std)[:, 1]\n",
    "    test_probs  = log_reg.predict_proba(X_test_std)[:, 1]\n",
    "\n",
    "    train_auc = roc_auc_score(y_train, train_probs)\n",
    "    val_auc   = roc_auc_score(y_val,   val_probs)\n",
    "    test_auc  = roc_auc_score(y_test,  test_probs)\n",
    "    \n",
    "    print(f\"Logistic baseline AUCs:\")\n",
    "    print(f\"  train AUC = {train_auc:.4f}\")\n",
    "    print(f\"  val   AUC = {val_auc:.4f}\")\n",
    "    print(f\"  test  AUC = {test_auc:.4f}\")\n",
    "    print()\n",
    "    # Inspect feature importance via logistic coefficients\n",
    "\n",
    "    feature_names = numeric_feature_cols\n",
    "    coef = log_reg.coef_.ravel()          # shape (D,)\n",
    "    \n",
    "    imp = pd.DataFrame({\n",
    "        \"feature\": feature_names,\n",
    "        \"coef\": coef\n",
    "    })\n",
    "    imp[\"abs_coef\"] = imp[\"coef\"].abs()\n",
    "    \n",
    "    # Top 20 by absolute coefficient\n",
    "    imp_sorted = imp.sort_values(\"abs_coef\", ascending=False)\n",
    "    \n",
    "    print(\"\\nTop 20 most predictive features (by |coef|):\")\n",
    "    print(imp_sorted.head(20)[[\"feature\", \"coef\"]])\n",
    "    \n",
    "    # If you also want to see the strongest negative vs positive separately:\n",
    "    print(\"\\nTop 10 features with positive coefficients:\")\n",
    "    print(imp_sorted[imp_sorted[\"coef\"] > 0].head(10)[[\"feature\", \"coef\"]])\n",
    "    \n",
    "    print(\"\\nTop 10 features with negative coefficients:\")\n",
    "    print(imp_sorted[imp_sorted[\"coef\"] < 0].head(10)[[\"feature\", \"coef\"]])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f109f960-2abf-4412-8fc3-3180be1f404f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 3. Baseline model 2: Edge-feature-only MLP feedforward NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf03a569-0ec3-4a43-bd9f-8ade8e899866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline 2: Edge-only feedforward NN (multi-layer perceptron, no graph structure)\n",
    "\n",
    "class EdgeMLP(nn.Module):\n",
    "    \"\"\"\n",
    "    Edge-only baseline MLP that predicts 4 edge-level scores using\n",
    "    only edge features, without any graph structure.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_edge_features, hidden_dim=64):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(num_edge_features, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 4),\n",
    "        )\n",
    "\n",
    "    def forward(self, edge_index, edge_attr):\n",
    "        # ignore edge_index; just use edge features\n",
    "        logits = self.net(edge_attr)      # [E, 4]\n",
    "        return logits\n",
    "\n",
    "\n",
    "    def encode_nodes(self, edge_index):\n",
    "        \"\"\"\n",
    "        For API compatibility with GNN.\n",
    "        \"\"\"\n",
    "        return None\n",
    "\n",
    "    def score_edges(self, x, edge_index, edge_attr):\n",
    "        \"\"\"\n",
    "        Node embedding x is ignored; kept only so train_step / eval_split work unchanged.\n",
    "        \"\"\"\n",
    "        return self.forward(edge_index, edge_attr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70dd0ddb-4d93-4552-aec5-000b7ebb3a46",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 4. GNN model construction, training and evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8dd1fedc-3d71-417b-a0a4-8be90bb5b413",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN(nn.Module):\n",
    "    \"\"\"\n",
    "    GNN that learns node embeddings with three GCN layers and predicts\n",
    "    4 edge-level scores by feeding [h_src, h_dst, edge_attr] into an MLP.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_nodes, num_edge_features, hidden_dim=64):\n",
    "        super().__init__()\n",
    "\n",
    "        self.node_emb = nn.Embedding(num_nodes, hidden_dim)\n",
    "\n",
    "        self.gcn1 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.gcn2 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.gcn3 = GCNConv(hidden_dim, hidden_dim)\n",
    "\n",
    "        self.edge_mlp = nn.Sequential(\n",
    "            nn.Linear(2 * hidden_dim + num_edge_features, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 4)\n",
    "        )\n",
    "\n",
    "    def encode_nodes(self, edge_index):\n",
    "        x = self.node_emb.weight\n",
    "        x = F.relu(self.gcn1(x, edge_index))\n",
    "        x = F.relu(self.gcn2(x, edge_index))\n",
    "        x = F.relu(self.gcn3(x, edge_index))\n",
    "        return x                    # [num_nodes, hidden_dim]\n",
    "\n",
    "    def score_edges(self, x, edge_index, edge_attr):\n",
    "        src, dst = edge_index\n",
    "        h_src = x[src]\n",
    "        h_dst = x[dst]\n",
    "\n",
    "        h_edge = torch.cat([h_src, h_dst, edge_attr], dim=-1)\n",
    "        logits = self.edge_mlp(h_edge)    # [E_batch, 4]\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a967307-c10c-4d8a-8831-b618f7669186",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def eval_split(idx, split_name=\"\", batch_size=50000):\n",
    "    \"\"\"\n",
    "    Evaluate the model on a given set of edges (train/val/test) and compute\n",
    "    average loss plus per-head and mean ROC AUC. The edges are processed in\n",
    "    batches to avoid storing all logits and activations in GPU memory at once.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    x = model.encode_nodes(edge_index)\n",
    "\n",
    "    losses = []\n",
    "    n_total = 0\n",
    "    all_probs = []\n",
    "    all_labels = []\n",
    "\n",
    "    for start in range(0, idx.size(0), batch_size):\n",
    "        end = min(start + batch_size, idx.size(0))\n",
    "        batch_edges = idx[start:end]\n",
    "\n",
    "        ei_batch = edge_index[:, batch_edges]\n",
    "        ea_batch = edge_attr[batch_edges]\n",
    "        y_batch  = y_all[batch_edges]                 # [B, 4]\n",
    "\n",
    "        logits_batch = model.score_edges(x, ei_batch, ea_batch)  # [B, 4]\n",
    "        loss_batch = criterion(logits_batch, y_batch)\n",
    "\n",
    "        B = y_batch.size(0)\n",
    "        losses.append(loss_batch.item() * B)\n",
    "        n_total += B\n",
    "\n",
    "        # detach before moving to numpy\n",
    "        probs_batch = torch.sigmoid(logits_batch).detach().cpu().numpy()  # [B, 4]\n",
    "        y_np_batch  = y_batch.detach().cpu().numpy()                      # [B, 4]\n",
    "\n",
    "        all_probs.append(probs_batch)\n",
    "        all_labels.append(y_np_batch)\n",
    "\n",
    "    avg_loss = sum(losses) / max(n_total, 1)\n",
    "\n",
    "    probs = np.concatenate(all_probs, axis=0)    # [N_split, 4]\n",
    "    labels = np.concatenate(all_labels, axis=0)  # [N_split, 4]\n",
    "\n",
    "    auc_per_head = []\n",
    "    for h in range(labels.shape[1]):\n",
    "        y_h = labels[:, h]\n",
    "        p_h = probs[:, h]\n",
    "        if np.all(y_h == 0) or np.all(y_h == 1):\n",
    "            auc_h = float(\"nan\")\n",
    "        else:\n",
    "            auc_h = roc_auc_score(y_h, p_h)\n",
    "        auc_per_head.append(auc_h)\n",
    "\n",
    "    valid_aucs = [a for a in auc_per_head if not np.isnan(a)]\n",
    "    mean_auc = float(np.mean(valid_aucs)) if valid_aucs else float(\"nan\")\n",
    "\n",
    "    return avg_loss, auc_per_head, mean_auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36e66b75-ff1e-4916-a05d-8dc3c7e20787",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(batch_size=4096):\n",
    "    \"\"\"\n",
    "    Perform one training update: sample a random mini-batch of training edges,\n",
    "    compute their logits and BCE loss over 4 heads, backpropagate, and update\n",
    "    model parameters. Mini-batching is used both for stochastic gradients and\n",
    "    to keep memory usage manageable.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 1) GCN over full graph\n",
    "    x = model.encode_nodes(edge_index)              # [num_nodes, hidden_dim]\n",
    "\n",
    "    # 2) sample a mini-batch of training edges\n",
    "    perm = torch.randint(\n",
    "        low=0,\n",
    "        high=train_idx.size(0),\n",
    "        size=(batch_size,),\n",
    "        device=device,\n",
    "    )\n",
    "    batch_edges = train_idx[perm]                   # [B]\n",
    "\n",
    "    edge_index_batch = edge_index[:, batch_edges]   # [2, B]\n",
    "    edge_attr_batch  = edge_attr[batch_edges]       # [B, D_edge]\n",
    "    y_batch          = y_all[batch_edges]               # [B, 4]\n",
    "\n",
    "    # 3) forward on this batch (4 logits per edge)\n",
    "    logits_batch = model.score_edges(x, edge_index_batch, edge_attr_batch)  # [B, 4]\n",
    "\n",
    "    # 4) BCE over all 4 heads\n",
    "    loss = criterion(logits_batch, y_batch)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return float(loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f62c5d5-068a-40fd-b389-9a88f2bdb66c",
   "metadata": {},
   "source": [
    "### 5. Experiment on learning rate and batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e662e6c1-b04c-42c8-b7e3-0cb802a5e551",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Helper to (re)build GNN + optimizer for each run\n",
    "def make_gnn_model(hidden_dim, lr):\n",
    "    global model, optimizer, criterion\n",
    "\n",
    "    model = GNN(\n",
    "        num_nodes=num_nodes,\n",
    "        num_edge_features=D_edge,\n",
    "        hidden_dim=hidden_dim\n",
    "    ).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6b21a5d-1bf0-4068-8866-e6b606b29708",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== LR sweep: lr = 0.0001, batch_size = 4096 ===\n",
      "Epoch   1 | train_loss(step)=0.7111 | train_mean_auc=0.4900 | val_mean_auc=0.4937\n",
      "Epoch  10 | train_loss(step)=0.6729 | train_mean_auc=0.5071 | val_mean_auc=0.5103\n",
      "Epoch  20 | train_loss(step)=0.6388 | train_mean_auc=0.5192 | val_mean_auc=0.5220\n",
      "Epoch  30 | train_loss(step)=0.5884 | train_mean_auc=0.5172 | val_mean_auc=0.5200\n",
      "Epoch  40 | train_loss(step)=0.5172 | train_mean_auc=0.5153 | val_mean_auc=0.5180\n",
      "Epoch  50 | train_loss(step)=0.4726 | train_mean_auc=0.5148 | val_mean_auc=0.5174\n",
      "Epoch  60 | train_loss(step)=0.4560 | train_mean_auc=0.5179 | val_mean_auc=0.5205\n",
      "Epoch  70 | train_loss(step)=0.4584 | train_mean_auc=0.5238 | val_mean_auc=0.5264\n",
      "Epoch  80 | train_loss(step)=0.4554 | train_mean_auc=0.5276 | val_mean_auc=0.5302\n",
      "Epoch  90 | train_loss(step)=0.4583 | train_mean_auc=0.5327 | val_mean_auc=0.5354\n",
      "Epoch 100 | train_loss(step)=0.4552 | train_mean_auc=0.5388 | val_mean_auc=0.5414\n",
      "\n",
      "=== LR sweep: lr = 0.0003, batch_size = 4096 ===\n",
      "Epoch   1 | train_loss(step)=0.7159 | train_mean_auc=0.5172 | val_mean_auc=0.5210\n",
      "Epoch  10 | train_loss(step)=0.6149 | train_mean_auc=0.5190 | val_mean_auc=0.5210\n",
      "Epoch  20 | train_loss(step)=0.4666 | train_mean_auc=0.5148 | val_mean_auc=0.5172\n",
      "Epoch  30 | train_loss(step)=0.4732 | train_mean_auc=0.5210 | val_mean_auc=0.5233\n",
      "Epoch  40 | train_loss(step)=0.4609 | train_mean_auc=0.5267 | val_mean_auc=0.5288\n",
      "Epoch  50 | train_loss(step)=0.4574 | train_mean_auc=0.5372 | val_mean_auc=0.5390\n",
      "Epoch  60 | train_loss(step)=0.4522 | train_mean_auc=0.5559 | val_mean_auc=0.5573\n",
      "Epoch  70 | train_loss(step)=0.4438 | train_mean_auc=0.5846 | val_mean_auc=0.5851\n",
      "Epoch  80 | train_loss(step)=0.4305 | train_mean_auc=0.6219 | val_mean_auc=0.6211\n",
      "Epoch  90 | train_loss(step)=0.4365 | train_mean_auc=0.6537 | val_mean_auc=0.6516\n",
      "Epoch 100 | train_loss(step)=0.4313 | train_mean_auc=0.6763 | val_mean_auc=0.6737\n",
      "\n",
      "=== LR sweep: lr = 0.001, batch_size = 4096 ===\n",
      "Epoch   1 | train_loss(step)=0.7078 | train_mean_auc=0.5048 | val_mean_auc=0.5059\n",
      "Epoch  10 | train_loss(step)=0.4996 | train_mean_auc=0.5168 | val_mean_auc=0.5193\n",
      "Epoch  20 | train_loss(step)=0.4655 | train_mean_auc=0.5344 | val_mean_auc=0.5368\n",
      "Epoch  30 | train_loss(step)=0.4587 | train_mean_auc=0.5600 | val_mean_auc=0.5622\n",
      "Epoch  40 | train_loss(step)=0.4493 | train_mean_auc=0.6101 | val_mean_auc=0.6113\n",
      "Epoch  50 | train_loss(step)=0.4352 | train_mean_auc=0.6888 | val_mean_auc=0.6879\n",
      "Epoch  60 | train_loss(step)=0.4117 | train_mean_auc=0.7234 | val_mean_auc=0.7220\n",
      "Epoch  70 | train_loss(step)=0.4008 | train_mean_auc=0.7480 | val_mean_auc=0.7463\n",
      "Epoch  80 | train_loss(step)=0.3906 | train_mean_auc=0.7625 | val_mean_auc=0.7609\n",
      "Epoch  90 | train_loss(step)=0.3849 | train_mean_auc=0.7714 | val_mean_auc=0.7694\n",
      "Epoch 100 | train_loss(step)=0.3834 | train_mean_auc=0.7786 | val_mean_auc=0.7765\n",
      "\n",
      "=== LR sweep: lr = 0.003, batch_size = 4096 ===\n",
      "Epoch   1 | train_loss(step)=0.7022 | train_mean_auc=0.5084 | val_mean_auc=0.5098\n",
      "Epoch  10 | train_loss(step)=0.4535 | train_mean_auc=0.5354 | val_mean_auc=0.5375\n",
      "Epoch  20 | train_loss(step)=0.4390 | train_mean_auc=0.6099 | val_mean_auc=0.6107\n",
      "Epoch  30 | train_loss(step)=0.4197 | train_mean_auc=0.7040 | val_mean_auc=0.7030\n",
      "Epoch  40 | train_loss(step)=0.3913 | train_mean_auc=0.7486 | val_mean_auc=0.7471\n",
      "Epoch  50 | train_loss(step)=0.3796 | train_mean_auc=0.7679 | val_mean_auc=0.7667\n",
      "Epoch  60 | train_loss(step)=0.3833 | train_mean_auc=0.7799 | val_mean_auc=0.7780\n",
      "Epoch  70 | train_loss(step)=0.3716 | train_mean_auc=0.7883 | val_mean_auc=0.7861\n",
      "Epoch  80 | train_loss(step)=0.3678 | train_mean_auc=0.7942 | val_mean_auc=0.7915\n",
      "Epoch  90 | train_loss(step)=0.3663 | train_mean_auc=0.8008 | val_mean_auc=0.7981\n",
      "Epoch 100 | train_loss(step)=0.3551 | train_mean_auc=0.8064 | val_mean_auc=0.8029\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk4AAAGGCAYAAACNCg6xAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAtfJJREFUeJzs3Xd0FFUbwOHfpvfeAyShE3oTQi/SlSICitJBKdJB6RJAEPCjVxUElS4gRcDQpQQE6b0TSgpJSO+79/tjZWVJAruQsCn3OWcP7MydmXeSLW9uVQghBJIkSZIkSdIrGRk6AEmSJEmSpPxCJk6SJEmSJEk6komTJEmSJEmSjmTiJEmSJEmSpCOZOEmSJEmSJOlIJk6SJEmSJEk6komTJEmSJEmSjmTiJEmSJEmSpCOZOEmSJEmSJOlIJk65bNWqVSgUCk6fPm3oUPTWqFEjGjVqZOgwXtvatWuZN2+eocPI99LT0ylbtizffvttpn0XLlygT58+lChRAktLSywtLSlVqhSff/55ptf85MmTUSgUuLm5ER8fn+lcvr6+vPfee1rbFAoFCoUiy2u/6XtLoVDwxRdfvNaxWUlKSmLy5MkcOnTotY5/258VPXv2xNfX961c62348ccfUSgU2NjYZLn/zJkzvPvuu9jY2ODg4MAHH3zAnTt3MpULDQ2lZ8+euLm5YWFhQaVKlVixYkW21922bRsNGzbEzs4Oa2trypcvz/fff/9a93DlyhUmT57MvXv3Mu3La7+vZ6/XrGJ9lV27djF58uQ3un63bt1o3779G53jdcnEScrWkiVLWLJkiaHDeG0yccoZS5Ys4enTpwwePFhr+/Lly6levTonT55k6NCh7Ny5kz/++INhw4Zx+fJlatasye3btzOd78mTJ8yaNUuvGL799luio6Pf6D5yW1JSEoGBga+dOL1tEydOZOvWrYYOI0c8evSIUaNG4eXlleX+a9eu0ahRI9LS0ti4cSMrV67kxo0b1K9fnydPnmjKxcbGUq9ePfbv38+sWbPYtm0b1apVo2/fvsyZMyfTeb/99ls++OADKlSowMaNG9m+fTsDBw4kLS3tte7jypUrBAYGZpmMFKTf165duwgMDHyjc0yePJk//viDAwcO5FBUujN561eUDEIIQUpKCpaWljof4+/vn4sR6S85OVmv+KU3l5GRwezZs+nduzfW1taa7ceOHWPgwIG0adOG3377DTMzM82+Jk2aMGjQIDZt2pTl76tly5bMnTuXQYMG4eHh8coY3n33XQ4dOsQ333zD//73v5y5MYkSJUoYOoQc079/fxo0aICTkxO//fZbpv2TJk3C3NycnTt3YmdnB0D16tUpVaoU3333HTNnzgRg6dKl3Llzh9OnT1O9enUAWrRoQWhoKJMmTaJ37944ODgA8M8//zB+/HhmzJjBl19+qblW06ZNc+UeC9LvKyeUKFGCli1b8u2339KkSZO3em1Z45RH3Lx5k65du+Lm5oa5uTnlypVj8eLFWmVSUlIYOXIkVapUwd7eHicnJwICAti2bVum8z1rhli2bBnlypXD3Nyc1atXa6pXDx48yIABA3BxccHZ2ZkPPviAx48fa53jxaa6e/fuoVAo+O6775gzZw5+fn7Y2NgQEBDAiRMnMsXwww8/ULp0aczNzfH392ft2rU6Vzc/a7bZsmULVatWxcLCQvMXyuLFi2nQoAFubm5YW1tTsWJFZs2aRXp6ulbsf/zxB/fv39c09ygUCs3+tLQ0pk2bRtmyZTE3N8fV1ZVevXpp/fWZnTt37vDRRx/h5eWFubk57u7uNG3alHPnzgEwevRo7O3tUSqVmmMGDx6MQqFg9uzZmm1RUVEYGRmxcOFCzba4uDhGjRqFn58fZmZmeHt7M2zYMBITE7ViEEKwZMkSqlSpgqWlJY6Ojnz44YeZmh4aNWpEhQoVOHLkCLVr18bS0hJvb28mTpyoFV92tm/fzqNHj+jWrZvW9unTp2NsbMzy5cu1kqbnderUKcsagGnTppGRkaFzVX2ZMmXo06cPixcv5v79+zodo4/ly5drvU7Xr1+vtf/JkycMHDgQf39/bGxscHNzo0mTJhw5ckRT5t69e7i6ugIQGBioeb317NlTU+batWt8/PHHuLu7Y25uTrFixejevTupqala14uPj3/le/NVnjx5wmeffUbRokU1r++6deuyb98+TZkX34vPmlKzejx/H2/y3skNv/76K4cPH862djwjI4OdO3fSsWNHTdIE4OPjQ+PGjbVqcY4dO4a7u7smaXrmvffeIzExkT179mi2LVq0CHNz80w1sa9r1apVdOrUCYDGjRtrfvarVq0Csm6qe/Y5/8svv1CuXDmsrKyoXLkyO3fu1JQ5cuQICoWCdevWZbrmzz//jEKh4NSpUy+N7cSJE9StWxcLCwu8vLwYO3as1uftMxs2bKB58+Z4enpiaWlJuXLlGDNmjNbnV8+ePTXfbc+/xp7Vsuny+f5Mt27d2LdvX5Y127lKSLnqp59+EoA4depUtmUuX74s7O3tRcWKFcXPP/8sgoKCxMiRI4WRkZGYPHmyplxMTIzo2bOn+OWXX8SBAwfEnj17xKhRo4SRkZFYvXq11jkB4e3tLSpVqiTWrl0rDhw4IC5duqSJp3jx4mLw4MHizz//FD/++KNwdHQUjRs31jpHw4YNRcOGDTXP7969KwDh6+srWrZsKX7//Xfx+++/i4oVKwpHR0cRExOjKbt8+XIBiI4dO4qdO3eKNWvWiNKlSwsfHx/h4+Pzyp+bj4+P8PT0FMWLFxcrV64UBw8eFH///bcQQojhw4eLpUuXij179ogDBw6IuXPnChcXF9GrVy+tn2ndunWFh4eHCA4O1jyEEEKpVIqWLVsKa2trERgYKPbu3St+/PFH4e3tLfz9/UVSUtJLYytTpowoWbKk+OWXX8Thw4fF5s2bxciRI8XBgweFEELs2bNHAOL48eOaY8qWLSssLS1Fs2bNNNs2bNggAHHlyhUhhBCJiYmiSpUqwsXFRcyZM0fs27dPzJ8/X9jb24smTZoIlUqlObZfv37C1NRUjBw5UuzZs0esXbtWlC1bVri7u4uwsDCt36Gzs7Pw8vISCxYsEH/++acYMmSIAMSgQYNe+Xvo3bu3cHNz09qWkZEhLC0tRUBAwCuPf97XX38tAPHkyRMxfPhwYWJiIq5fv67Z7+PjI9q0aaN1zLM4Q0NDhZWVlejWrZtmny7vrZcBRNGiRYW/v79Yt26d2L59u2jZsqUAxKZNmzTlrl27JgYMGCDWr18vDh06JHbu3Cn69OkjjIyMNL/zlJQUze+9T58+mtfbrVu3hBBCnDt3TtjY2AhfX1+xbNkysX//fvHrr7+Kzp07i7i4OK370eW9+SotWrQQrq6u4vvvvxeHDh0Sv//+u5g0aZJYv369pkyPHj203osPHjzQeq8EBweL0aNHC0DMmjVLCPHm7x2VSiXS09N1eugiPDxcODs7i8WLF2vuydraWqvMtWvXBKAp87xRo0YJhUIhkpOThRBCNG/eXBQrVixTuWefZ2PHjtVsK168uKhWrZr45ZdfROnSpYWRkZHw9vYWX331lUhNTdUp/udFRESI6dOna2J99juIiIjQ3NuLn53PPo/feecdsXHjRrFr1y7RqFEjYWJiIm7fvq0pV7VqVVG3bt1M16xZs6aoWbPmS+O6fPmysLKy0rxPtm3bJlq0aCGKFSsmAHH37l1N2alTp4q5c+eKP/74Qxw6dEgsW7ZM+Pn5ab1+b926JT788EMBaL3WUlJShBC6fb4/Ex4eLgCxYMGCV/58c5JMnHKZLh/uLVq0EEWKFBGxsbFa27/44gthYWEhoqOjszwuIyNDpKeniz59+oiqVatq7QOEvb19pmOfxTNw4ECt7bNmzRKACA0N1WzLLnGqWLGiyMjI0Gz/+++/BSDWrVsnhFB/uHp4eIhatWppXeP+/fvC1NRU58TJ2NhY64s1K0qlUqSnp4uff/5ZGBsba91vmzZtsrzWunXrBCA2b96stf3UqVMCEEuWLMn2epGRkQIQ8+bNy7ZMYmKiMDMzE1OmTBFCCPHw4UMBiK+++kpYWlpqPiD69esnvLy8NMfNmDFDGBkZZXqt/PbbbwIQu3btEkIIERwcLADxv//9T6vcgwcPhKWlpfjyyy812xo2bCgAsW3bNq2y/fr1E0ZGRuL+/fvZ3ocQQpQrV060bNlSa1tYWJgAxEcffZSp/LPX5LPH88ne84lTZGSksLe3Fx07dtTsf1niJIQQ48ePF0ZGRuL8+fNCiJxJnCwtLbUSzYyMDFG2bFlRsmTJbI97do9NmzYVHTp00Gx/8uSJAMTXX3+d6ZgmTZoIBwcHzZdgVvR5b76KjY2NGDZs2EvLZPVF/LwjR44ICwsL8cknn2h+j2/y3hHiv3vU5aGLjh07ijp16mjiyypxOnbsmNbn0/OeJSqPHz8WQggxbNiwLN8X3bp1E4D47LPPNNvMzc2Fra2tcHR0FIsWLRIHDhwQ48ePF8bGxqJr1646xf+iTZs2CUCTkD8vu8TJ3d1dk3wLoX5/GhkZiRkzZmi2Pfu5nz17VrPt2ef2i390v6hLly7Zvk9eTJye9yxJPnz4sAA071shhBg0aJBOv+OXfb4/4+3tLbp06fLKc+Uk2VRnYCkpKezfv58OHTpgZWVFRkaG5tG6dWtSUlK0msE2bdpE3bp1sbGxwcTEBFNTU1asWMHVq1cznbtJkyY4Ojpmed22bdtqPa9UqRKATk0hbdq0wdjYONtjr1+/TlhYGJ07d9Y6rlixYtStW/eV53/+vKVLl860/ezZs7Rt2xZnZ2eMjY0xNTWle/fuKJVKbty48crz7ty5EwcHB95//32tn3eVKlXw8PB4aedeJycnSpQowezZs5kzZw5nz55FpVJplbGysiIgIEDTLLJ3714cHBwYPXo0aWlpHD16FIB9+/bx7rvvasVVoUIFqlSpohVXixYtUCgUmrh27tyJQqHg008/1Srn4eFB5cqVM8Vva2ub6ffdtWtXVCoVf/3110t/Vo8fP8bNze2lZZ5XvXp1TE1NNY/s+iQ5Ozvz1VdfsXnzZk6ePKnTub/88kucnJz46quvdI7nVZo2bYq7u7vmubGxMV26dOHWrVs8fPhQs33ZsmVUq1YNCwsLzftu//79Wb7vXpSUlMThw4fp3LmzpjnvZd7kvfnMO++8w6pVq5g2bRonTpzIspnjZa5evUrbtm2pU6cOK1eu1DRzv8l7B+D999/n1KlTOj1eZfPmzezYsYMffvhBqxk+Oy8r82zfZ599hqmpKZ988gmXL18mKiqKxYsXs2HDBgCMjP77ylSpVMTHx7NkyRIGDRpE48aNmTZtGoMHD2bt2rXcunXrlTHlhMaNG2Nra6t57u7ujpubm9br5eOPP8bNzU2r+8fChQtxdXWlS5cuLz3/wYMHs32fvOjOnTt07doVDw8PzWdzw4YNAXR6r4D+n+9ubm48evRIp3PnFJk4GVhUVBQZGRksXLhQ6wvH1NSU1q1bAxAZGQnAli1b6Ny5M97e3vz6668EBwdz6tQpevfuTUpKSqZze3p6ZntdZ2dnrefm5uaAugP2q7zq2KioKACtN9ozWW3LTlbxh4SEUL9+fR49esT8+fM5cuQIp06d0nwg6BJ/eHg4MTExmJmZZfqZh4WFaX7eWVEoFOzfv58WLVowa9YsqlWrhqurK0OGDNEaYv/uu+9y4sQJEhMT2bdvH02aNMHZ2Znq1auzb98+7t69y927d7USp/DwcC5cuJApJltbW4QQmrjCw8MRQuDu7p6p7IkTJzLFn9XP/Fmn7Ge/q+wkJydjYWGhtc3FxQVLS8ssv8jXrl3LqVOn2L59+0vPCzBs2DC8vLy0Ota+jJ2dHRMmTGDPnj0cPHhQp2NeJavO6S/+bObMmcOAAQOoVasWmzdv5sSJE5w6dYqWLVvq9Hp7+vQpSqWSIkWK6BTTm7w3n9mwYQM9evTgxx9/JCAgACcnJ7p3705YWNgrj338+DEtW7akSJEibNmyRasP25u8d0D9h0eVKlV0erxMQkICgwYNYvDgwXh5eRETE0NMTIxmNFtMTIymX82zn2dWr/Xo6GgUCoWmw3e5cuXYunUr9+/fp0KFCri4uDBz5kzNHwDe3t6aY5+dt0WLFlrnbNWqFaCe/uBtePH1AurXzPOvF3Nzcz7//HPWrl1LTEwMT548YePGjfTt21fz+spOVFTUS98nzyQkJFC/fn1OnjzJtGnTOHToEKdOnWLLli2Abq/f1/l8t7Cw0Ou9kRPkqDoDc3R0xNjYmG7dujFo0KAsy/j5+QHqTpB+fn5s2LBB66+nFzuXPqPLX2G54dkbOTw8PNM+XT64n8kq/t9//53ExES2bNmCj4+PZvuzjtm6eNbp9vmOns97/q+3rPj4+Gjmdblx4wYbN25k8uTJpKWlsWzZMkBdkzFx4kT++usv9u/fz9dff63ZHhQUpPmdPj8C51lCsnLlymzjfvavQqHgyJEjWX7ovbjtZb+HrD50X7zmi9MAGBsb06RJE4KCgggNDdVKcJ+NxNRlbhdLS0smT57MZ599xh9//PHK8gADBgxg/vz5fPXVVwwYMECnY14mq9fjiz+bX3/9lUaNGrF06VKtclnNRZUVJycnjI2NtWqwcpuLiwvz5s1j3rx5hISEsH37dsaMGUNERES2r3tQD05o3bo1KpWKXbt2YW9vn+m8b/LeWb16Nb169dLpHoQQ2e6LjIwkPDyc//3vf1nWajo6OtKuXTt+//13zRxjFy9ezFTu4sWLlCxZUuuPg1atWnH//n1u3bpFRkYGpUuXZuPGjQA0aNBAU65SpUpZvn6exf187VReMGDAAL799ltWrlxJSkoKGRkZ9O/f/5XHOTs7v/R98syBAwd4/Pgxhw4d0tQygTqJ1dXrfL5HR0e/9fmtZOJkYFZWVjRu3JizZ89SqVKlbEcogTqRMDMz00oowsLCshxVZ0hlypTBw8ODjRs3MmLECM32kJAQjh8/nu1cK7p4du/PJwdCCH744YdMZV/8q+uZ9957j/Xr16NUKqlVq9ZrxwJQunRpJkyYwObNm7X+wnznnXews7Nj3rx5hIWF0axZM0BdEzVz5kw2btyIv7+/1s/ivffeY/r06Tg7O2sSq6y89957fPvttzx69ChTc2hW4uPj2b59u1YT0Nq1azEyMtL6IshK2bJlsxyxMnbsWHbv3k3//v357bffMDU1fWUcWenduzdz585lzJgxmZo8s2JmZsa0adP45JNPNInkm9i/fz/h4eGaWjmlUsmGDRsoUaKEpoZIoVBkSkYvXLhAcHAwRYsW1WzLrmbI0tKShg0bsmnTJr755psciVsfxYoV44svvmD//v0cO3Ys23JpaWl06NCBe/fucfTo0SxryN70vfOsqe5NeXh4ZFnr+O2333L48GF2796t+TmbmJjw/vvvs2XLFmbNmqVJ7kJCQjh48CDDhw/PdB6FQkGpUqUA9c9l/vz5VKlSRev90rFjR4KCgti9ezddu3bVbN+1axdGRkbUrFlT7/t6ndpFXXl6etKpUyeWLFlCWloa77//PsWKFXvlcY0bN2b79u1Zvk+el9VnM6hHrb7o+ft8fsoSfT7fQT1i8sGDB5rWmbdFJk5vyYEDB7L8K7x169bMnz+fevXqUb9+fQYMGICvry/x8fHcunWLHTt2aCb4ejY8f+DAgXz44Yc8ePCAqVOn4unpyc2bN9/yHWXPyMiIwMBAPv/8cz788EN69+5NTEwMgYGBeHp6vtFfYs2aNcPMzIyPP/6YL7/8kpSUFJYuXcrTp08zla1YsSJbtmxh6dKlVK9eHSMjI2rUqMFHH33EmjVraN26NUOHDuWdd97B1NSUhw8fcvDgQdq1a0eHDh2yvP6FCxf44osv6NSpE6VKlcLMzIwDBw5w4cIFxowZoylnbGxMw4YN2bFjB35+fpo5WOrWrYu5uTn79+9nyJAhWuceNmwYmzdvpkGDBgwfPpxKlSqhUqkICQkhKCiIkSNHUqtWLerWrctnn31Gr169OH36NA0aNMDa2prQ0FCOHj1KxYoVtWpjnJ2dGTBgACEhIZQuXZpdu3bxww8/MGDAgFd+cDZq1IgpU6aQlJSElZWVZnvdunVZvHgxgwcPplq1anz22WeUL18eIyMjQkND2bx5M4DW8O+sGBsbM336dM3P+1l/npf5+OOP+e6779i9e3emfffu3cPPz48ePXpohnG/jIuLC02aNGHixIlYW1uzZMkSrl27pjUlwXvvvcfUqVP5+uuvadiwIdevX2fKlCn4+fmRkZGhKWdra4uPjw/btm2jadOmODk54eLigq+vL3PmzKFevXrUqlWLMWPGULJkScLDw9m+fTvLly9/ZU2NPmJjY2ncuDFdu3albNmy2NracurUKfbs2cMHH3yQ7XHDhw/nwIEDTJ8+nYSEBK2+la6urpQoUeKN3jugfi2+qpZTFxYWFlmuarBq1SqMjY0z7QsMDKRmzZq89957jBkzhpSUFCZNmoSLiwsjR47UKjt48GAaNWqEs7Mzd+7cYcGCBTx8+JDDhw9rlevVqxfLly9n4MCBREZG4u/vz759+1i8eDEDBw7UqjGZPHkygYGBHDx48KWrMVSoUAGA77//HltbWywsLPDz88uRnxnA0KFDNQnvTz/9pNMxEyZMYPv27TRp0oRJkyZhZWXF4sWLM02RUqdOHRwdHenfvz9ff/01pqamrFmzhvPnz2c6Z8WKFQGYOXMmrVq1wtjYmEqVKun1+Q7qz+OkpCQaN26sz4/hzb3VruiF0KtGkTwbkXD37l3Ru3dv4e3tLUxNTYWrq6uoU6eOmDZtmtb5vv32W+Hr6yvMzc1FuXLlxA8//KAZrfQ8shlunt1IpIMHD2YazZHdqLrZs2dnOi9ZjCb6/vvvRcmSJYWZmZkoXbq0WLlypWjXrl2mEYBZyWqE1TM7duwQlStXFhYWFsLb21uMHj1a7N69O1P80dHR4sMPPxQODg5CoVBo/YzS09PFd999pzmPjY2NKFu2rPj888/FzZs3s40rPDxc9OzZU5QtW1ZYW1sLGxsbUalSJTF37lytkYZCCDF//nwBiH79+mltb9asmQDE9u3bM50/ISFBTJgwQZQpU0aYmZlppqkYPny41qgWIYRYuXKlqFWrlrC2thaWlpaiRIkSonv37uL06dOaMg0bNhTly5cXhw4dEjVq1BDm5ubC09NTjBs3Tqch37du3RIKhUJs3Lgxy/3nzp0TvXr1En5+fsLc3FxYWFiIkiVLiu7du4v9+/drlX1+VN2L6tSpI4CXjqp7XlBQkOY99Pxr+eLFiwIQY8aMeeW9PTv3kiVLRIkSJYSpqakoW7asWLNmjVa51NRUMWrUKOHt7S0sLCxEtWrVxO+//57lKKd9+/aJqlWrCnNzcwGIHj16aPZduXJFdOrUSTg7OwszMzNRrFgx0bNnT80oS33emy+TkpIi+vfvLypVqiTs7OyEpaWlKFOmjPj6669FYmKiptyL8T8bgZnV4/n7eN33ztuQ1ai6Z06fPi2aNm0qrKyshJ2dnWjfvr1muojntWvXTnh6egpTU1Ph4eEhevbsKe7du5flOaOiosTnn38u3N3dhampqShdurSYPXu2UCqVWuVGjhwpFAqFuHr16ivvYd68ecLPz08YGxsLQPz000+ae8tqVF1W7w8fHx+t39nzfH19Rbly5V4Zx/OOHTsmateuLczNzYWHh4cYPXq0+P777zONqjt+/LgICAgQVlZWwtXVVfTt21ecOXNG6z6EUL+n+vbtK1xdXTWfzc/Oo+vnuxBCTJw4Ubi4uGjeQ2+LQoiXNCRLUg6KiYmhdOnStG/f/rXXcpL006hRIyIjI7l06dJrn+PZCKqsanjymiVLlvDll19y+/ZtvQYiSFJueuedd/Dx8WHTpk0GjePChQtUrlxZUyuWnymVSkqWLEnXrl355ptv3uq1ZVOdlCvCwsL45ptvaNy4Mc7Ozty/f5+5c+cSHx/P0KFDDR2epIcZM2ZQtWpVTp069Vr9Nt6mgwcPMmTIEJk0SXlGXFwc58+fZ/Xq1QaL4fbt29y/f59x48bh6empNRN8fvXrr7+SkJDA6NGj3/q1ZeIk5Qpzc3Pu3bvHwIEDiY6OxsrKitq1a7Ns2TLKly9v6PAkPVSoUIGffvpJrxGRhmLov+hzm0qlemUnehMT+bGel9jZ2WU78vltmTp1qmZZlk2bNmn1V8yvVCoVa9as0Uwl8TbJpjpJkqR84lkn45e5e/fuWx+eLUmFiUycJEmS8onHjx+/csHfV01rIknSm5GJkyRJkiRJko7y1tSmkiRJkiRJeZjsRZgFlUrF48ePsbW1NdiyJZIkSZIkvR1CCOLj4/Hy8nrlJM0yccrC48ePtZZSkCRJkiSp4Hvw4MErF+SWiVMWni1/8ODBg1cuGSFJkiRJUv4WFxdH0aJFdVr+SCZOWXjWPGdnZycTJ0mSJEkqJHTpniM7h0uSJEmSJOlIJk6SJEmSJEk6komTJEmSJEmSjmQfpzegVCpJT083dBjSW2RqaoqxsbGhw5AkSZIMRCZOr0EIQVhYGDExMYYORTIABwcHPDw85BxfkiRJhZBMnF7Ds6TJzc0NKysr+QVaSAghSEpKIiIiAgBPT08DRyRJkiS9bTJx0pNSqdQkTc7OzoYOR3rLLC0tAYiIiMDNzU0220mSJBUysnO4np71abKysjJwJJKhPPvdy/5tkiRJhY9MnF6TbJ4rvOTvXpIkqfAyeOK0ZMkS/Pz8sLCwoHr16hw5cuSl5desWUPlypWxsrLC09OTXr16ERUVpVVm8+bN+Pv7Y25ujr+/P1u3bs3NW5AkSZIkqZAwaOK0YcMGhg0bxvjx4zl79iz169enVatWhISEZFn+6NGjdO/enT59+nD58mU2bdrEqVOn6Nu3r6ZMcHAwXbp0oVu3bpw/f55u3brRuXNnTp48+bZuK89q1KgRw4YNM3QYkiRJkvRKqpQUki9dJmbzFsJnzOB+z148HDzY0GEZNnGaM2cOffr0oW/fvpQrV4558+ZRtGhRli5dmmX5EydO4Ovry5AhQ/Dz86NevXp8/vnnnD59WlNm3rx5NGvWjLFjx1K2bFnGjh1L06ZNmTdv3lu6Kykrr1MLePHiRRo2bIilpSXe3t5MmTIFIYRWmcOHD1O9enUsLCwoXrw4y5Yt0/vaf/31F++//z5eXl4oFAp+//33N7pXSZIkKXtCpSI9PJykM2eI3bGDyGXLCf16Mg+HDOV+9x7caduOmw0acr1ade59+CGh48cTvfpnkk6cIPHk35m+B942g42qS0tL459//mHMmDFa25s3b87x48ezPKZOnTqMHz+eXbt20apVKyIiIvjtt99o06aNpkxwcDDDhw/XOq5FixYycdJBWloaZmZmOX7eZ7WAU6dOpUOHDmzdupXOnTtz9OhRatWqleUxcXFxNGvWjMaNG3Pq1Clu3LhBz549sba2ZuTIkQDcvXuX1q1b069fP3799VeOHTvGwIEDcXV1pWPHjjpfOzExkcqVK9OrVy/NcZIkSZJ+hBCoEpNQRkeRERWFMjqajKgoMsIjSH/8+L9HWBjoOLjG2MEB87JlsShTGvPSZTAvUyaX7+LVDJY4RUZGolQqcXd319ru7u5OWFhYlsfUqVOHNWvW0KVLF1JSUsjIyKBt27YsXLhQUyYsLEyvcwKkpqaSmpqqeR4XF/c6t5Tv+Pr60rdvX27dusXWrVtp3749q1evzvHrPF8LCDB27FgOHz7MvHnzWLduXZbHrFmzhpSUFFatWoW5uTkVKlTgxo0bzJkzhxEjRqBQKFi2bBnFihXTJMXlypXj9OnTfPfdd5oESJdrt2rVilatWuX4fUuSJOVHIi2N9NBQlE+fkvH0KcqnMSifPkUZH4cqKQlVUhIiKUmdJMXHo4yN1Tx0TYgwNsbUwwNTb29Mvbww9fLE2MkZYwcHzcPE1RUTN9c8NyDH4PM4vfgDEUJk+0O6cuUKQ4YMYdKkSbRo0YLQ0FBGjx5N//79WbFixWudE2DGjBkEBga+9j0IIUhOV7728W/C0tT4jV5Us2fPZuLEiUyYMCHbMtOnT2f69OkvPc/u3bupX79+lvtepxYwODiYhg0bYm5urnXM2LFjuXfvHn5+fgQHB9O8efNM512xYgXp6emYmprKGkhJkgo1kZHxb61POOlhYWSERyBSU1CYmaEwNUVhagpGxqQ/ekTqrVuk3r5F2r37kJHx2tdUWFpi4uyMsbMTJk7OmLi6apIjUy8vTD09MXF3R2Fi8BTktRgsahcXF4yNjTPVBEVERGSqMXpmxowZ1K1bl9GjRwNQqVIlrK2tqV+/PtOmTcPT0xMPDw+9zgnqWogRI0ZonsfFxVG0aFGd7yU5XYn/pD91Lp+TrkxpgZXZ6/8amzRpwqhRo15apn///nTu3PmlZby9vbPd9zq1gGFhYfj6+mY65tk+Pz+/bM+bkZFBZGQknp6er3VtSZKk/EQZF0fyuXMknztPengYGU+ekBEZScaTJyijokGl0vucCgsLdfLj6IixkyMmjo4Y2dphZGX13MMSIzs7jO0dMHawx9jODmN7e4wK+DyHBkuczMzMqF69Onv37qVDhw6a7Xv37qVdu3ZZHpOUlITJCxnqs5mbn3UWCwgIYO/evVq1DEFBQdSpUyfbWMzNzbVqNgqTGjVqvLKMk5MTTk5Ob3QdfWsBszvmxe2vWyavVf1KkiS9ilAqyYiIIO3BA9IfPiLl0iWSzpwh9fp1eFmHaWNjdbOXuxumbu4YWVkh0tO1HiYe7piXKIl5qZKYlyiBiaen/JzMhkHryUaMGEG3bt2oUaMGAQEBfP/994SEhNC/f39AXRP06NEjfv75ZwDef/99+vXrx9KlSzVNdcOGDeOdd97By8sLgKFDh9KgQQNmzpxJu3bt2LZtG/v27ePo0aO5dh+WpsZcmdIi187/qmu/CWtr61eWedOmutepBczuGPiv5im7MiYmJprlcF7n2pIkSYagTEgg7d590h+EkB4eTkbEEzIiIsh48oT0sFDSH4dm24fI1KcYVlWrYebri4mrCyYuLhi7uGDi4oqJizMKuTxUjjFo4tSlSxeioqKYMmUKoaGhVKhQgV27duHj4wNAaGio1pxOPXv2JD4+nkWLFjFy5EgcHBxo0qQJM2fO1JSpU6cO69evZ8KECUycOJESJUqwYcOGbEdv5QSFQvFGzWV53Zs21b1OLWBAQADjxo3TGukXFBSEl5eXpgkvICCAHTt2aB0XFBREjRo1MDU1fe1rS5Ik5RZlfDxp90NID7lPWkgIafdDSLt/n7T791G+MJlzlkxMMPXywqxIEcxKlsCqWnWsqlfDxNU194OXgDzQOXzgwIEMHDgwy32rVq3KtG3w4MEMfsUEWB9++CEffvhhToQn8eZNdbrUAi5atIitW7eyf/9+ALp27UpgYCA9e/Zk3Lhx3Lx5k+nTpzNp0iRN9XH//v1ZtGgRI0aMoF+/fgQHB7NixQqtkXq6XDshIYFbt25pnt+9e5dz587h5OREsWLFXvu+JUkqPFSpqeo+RZGR6s7YTyLJiIokI+zfTtlhYaSHhaGKj3/peYxdXDArVkzdgdrVFRM3t38frpgVKaLuVC1rjwzK4ImTVPDpUgsYGRnJ7du3Nc/t7e3Zu3cvgwYNokaNGjg6OjJixAitTvx+fn7s2rWL4cOHs3jxYry8vFiwYIHWXEy6XPv06dM0btxY8/zZNXr06JFl8i5JUuGjSk0lIzSU9FB1k1n6o0ekP3pI2oOHpD98SMa/XQl0YezqglnRYpgVK4aZTzFMixXDzNcXMx8fjG1scvEupJygEIaegjMPiouLw97entjYWOzs7LT2paSkcPfuXc36elLhI18DklSwKBMSSH/8+N/EKIyMiHDS/+1blBHxhIzwcJTR0a88j8LcXD0SzdUFE2cXTJydMfFwx9TDAxN3D0w9PTD18MBIh76l0tv1su/9F8kaJ0mSJCnfE0Kgio//N9n5N+mJjlZPzBgTgzImBlVsHKrkZFSpKYiUVERKCsq4OFQJCTpdQ2FpqZmHyNTTE9OiRTErWgTTIuqHsYODHIlWCMjESZIkScrzRFoaaQ8f/jfqLCxcPaljRDgZ4epESaSkvPb5je3tMfHyUtcOebhj6ub2Xx8jV1dMPT0xsreXiZEkEydJkiTJ8IRKhfLpU/VaZg8fkvbwIekPH5H+4AFpISGkP36s00SORnZ2mLi5qpMeR6fnlvCwx9jeHoWlJUYWFijMLTCyMMfI1lbdfFbAJ22Uco5MnCRJkqRcpUpJUa97FhGhnp8oLFw9w/Vz/2aEhyNesc6ZkZUVpr4+mBXz+bffkDum7m6YuLtraoaMZL9DKZfJxEmSJEl6I8r4eNLu3CH19h3S7twm9c5d0sNC1X2LnsYgkpN1PpeJq6u6z1DRIpgVKYKpdxHMfIqpR5y5uMimMsngZOIkSZIkZUuoVOoO1tHRZERFoYyMJO3BQ82kjWn37uk8caOJqyum7u6YeHio/3V3x9Tjueeurij+nfBWkvIqmThJkiRJgLpJLeXqVVIuXiT5wkWSL14g/eEjUCpfeayJmxtmJYpj7lccsxLFMStSRL1ArKMjxg4OGNnYyNoiqUCQiZMkSVIhJNLTSb15k+RLl0i5dJmUS5dIuXEDMjKyLG9kb4+JkxPGTk6YFfHG1McHMx8fzHx8MfOVEzdKhYdMnCRJkgo4IQTpDx+SfP4CyRfOk3L+AilXryLS0jKVNXZywrJSJSwrV8KiYiXMS5XExNFRNqFJ0r9k4lSINGrUiCpVqjBv3jxDhyJJUi7LiI4m8dhxEo8eJfH4cTKePMlUxsjODssK5bEoXwGLChWwKF8eU28v2aQmSS9hZOgApMJh8+bN+Pv7Y25ujr+/P1u3bn3lMRcvXqRhw4ZYWlri7e3NlClTeHGFoMOHD1O9enUsLCwoXrw4y5Yt0/vaS5cupVKlStjZ2WFnZ0dAQAC7d+9+sxuWpFymSkkh5coVYnf+QfTPv/BkwULCpk7j0ajR3P2gIzfr1OXx6NHEbtumTppMTbGoVAnHTz/Fa9ZMSuzZTemTJyi2ciVuI0dg16I5ZkW8ZdIkSa8ga5wkjbS0NMxyoTo+ODiYLl26MHXqVDp06MDWrVvp3LkzR48e1Vps93lxcXE0a9aMxo0bc+rUKW7cuEHPnj2xtrZm5MiRANy9e5fWrVvTr18/fv31V44dO8bAgQNxdXXVLPSry7WLFCnCt99+S8mSJQFYvXo17dq14+zZs5QvXz7Hfx6SpK/0iAhSLl8m5dJlUm/cIPXmTdJCQl45IaR52bLY1KuLdb16WFatipG5+VuKWJJeT0pGCtEp0UQlR5GqTMXGzAZrU2tsTNX/mhkbvslYLvKbhYK6yO+LTXW+vr707duXW7dusXXrVtq3b8/q1atz/LpdunQhLi5OqxanZcuWODo6sm7duiyPWbp0KWPHjiU8PBzzfz/sv/32WxYuXMjDhw9RKBR89dVXbN++natXr2qO69+/P+fPnyc4OPi1rw3g5OTE7Nmz6dOnT6Z9+fk1IOVtQqUi/cEDUq5dJ/X6dfUIt0uXsmxmA/UyIWYlS2Li5qqeHdveHmMHB0xcXbF+5x1MXF3f8h1I0suphIrolGhC4kK4E3uHu7F3uRN7hwfxD4hMjiQxPfGlx3taexL0YVCOxyUX+X3bhID0JMNc29QK3qBqffbs2UycOJEJEyZkW2b69OlMnz79pefZvXs39evXz3JfcHAww4cP19rWokWLl/a1Cg4OpmHDhpqk6dkxY8eO5d69e/j5+REcHEzz5s0znXfFihWkp6djamqq97WVSiWbNm0iMTGRgICAl9yxJL25jCdPSDpzluQzZ0g+f56UGzcQSVl8lhgZYVbcD8vyFTAvVxaL0qUxL1VKTggp5VnpynQuRl7k77C/uR1zm4ikCMKTwolIiiBd9fIZ4k2NTHG2dMbC2IKk9CQS0hNIylC/L8yNDV9rKhOnnJCeBNO9DHPtcY/BzPq1D2/SpAmjRo16aZn+/fvTuXPnl5bx9vbOdl9YWBju7u5a29zd3QkLC3vpMb6+vpmOebbPz88v2/NmZGQQGRmJp6enzte+ePEiAQEBpKSkYGNjw9atW/H39882PknSl0hLI+X6DfWotgsXSDpzlvQHDzKVU5iZYV6qFOZlymBRtoy603bZsnItNSlPEkIQmxrLo8RHhCaEcif2DqfCTnEu4hwpyuwXXfay9sLP3g8/ez+KOxTH184XNys3nCycsDHNPOeXUqUkKSOJVGVqbt/SK8nEqZCrUaPGK8s4OTnh5OT0Rtd58U0ghHjlX8pZHfPi9tct8+K2MmXKcO7cOWJiYti8eTM9evTg8OHDMnmSXosyIZHUmzdIvXGT1Bs3SLlyhZTLlzMP/1coMC9dGstqVbGqWhWL8uUx8/FBYSI/mqW8QQhBVEoUN57e4GH8Q02tUXii+t/HiY9Jzsh6SR0nCydquNegkmsl3K3d8bDywM3KDVdLV0yNTfWKw9jIGFszW2yxzYnbeiPy3ZkTTK3UNT+GuvYbsLZ+dW3VmzbVeXh4ZKrhiYiIyFQTpMsx8F/NU3ZlTExMcHZ21uvaZmZmms7hNWrU4NSpU8yfP5/ly5dnG6MkgXoiyZRr10g+e47kc+dIvngxy5okUE8iaVmpkvpRpTKWVapgbGv4LwJJAnWSFBIfwoUnF7gcdZmbT29y8+lNnqY+feWxzhbOeNl4UcSmCFXcqvCOxzuUcChRIJuSZeKUExSKN2ouy+vetKkuICCAvXv3avU1CgoKok6dOi89Zty4cVoj/YKCgvDy8tI04QUEBLBjxw6t44KCgqhRowampqavfW1Qf4Ckphq+SljKezIiI9UJ0rlzJJ07R8rFS4gsXismbm6Yly6NeenSWJQtg2WlSpj6+BTILxIpf4pKjuJy1GUuR17mQuQFLkZeJDY1NlM5I4URxWyL4Wvni7u1O+5W7rhZueFm5YantSeeNp55ou/R2yITJ+mV3rSpbujQoTRo0ICZM2fSrl07tm3bxr59+zh69KimzKJFi9i6dSv79+8HoGvXrgQGBtKzZ0/GjRvHzZs3mT59OpMmTdJ88fTv359FixYxYsQI+vXrR3BwMCtWrNAaLafLtceNG0erVq0oWrQo8fHxrF+/nkOHDrFnz57XvmepYFClppJ69SrJFy6oZ90+f570hw8zlTO2t8eiSmWsqlTBsnJlzMuVw8TR0QARS1LWkjOSuRx5mfNPznMp8hKXoy4TmhiaqZyZkRnlnMtR0aUipR1LU9qpNCXsS2BhIkcQPyMTJynX1alTh/Xr1zNhwgQmTpxIiRIl2LBhg9YcTpGRkdy+fVvz3N7enr179zJo0CBq1KiBo6MjI0aMYMSIEZoyfn5+7Nq1i+HDh7N48WK8vLxYsGCBZg4nXa8dHh5Ot27dCA0Nxd7enkqVKrFnzx6aNWuWyz8ZKS9Ke/CAuD/+IP7AQVKuXoX0F0YAKRSYlyyJZZUqWFatimWVKpj5+cqaJMnglColUSlRmj5I4Unh3I+7z/kn57kefZ0Mob0OoQIFfvZ++Dv7U9GlIpVcK1HGsYze/Y8KGzmPUxYK6jxOUs6Qr4GCJz08nPg/g4j9Yycp5y9o7dNau+3f/kmyX5L0tgkheJr6lMcJj3mU8IjHCY8JSwwjIilCM9Q/MjkSpVBmew43Szcqu1WmkkslyruUp5xTOWzM5OLMIOdxkiRJypJISyPl2jVSrlwl9eZN9ePWLZTR0f8VMjLCunYt7Fq3xqp2bUy95TIk0tsjhCAsMYybMeqO2bdjbnMr5hb34u5lO3rtecYKY1wsXXC3csfd2h1Pa08qulSksmtlPKw95Gs5B8jESZKkAkuZkEDi0WPqztznz2c9JQCAQoFlpUrYtWmDXauWcsZt6a3JUGVw/el1zkWc40z4Gc5FnCMiOSLb8m6WbnjZeOFl44WntSduVm5anbVdLF0wNjJ+i3dQ+MjESZKkAkWkpZFw9BixO7aTcOBgphFvxg4OWFSooB7xVqqU+lGiOEaWlgaKWCoMMlQZxKTG8DjhMdeir2keN57eyDSpo4nCBF97X0o5lKKEQwlKOpakuH1xvGy8CtXotbxKJk6SJOV7QqUi+cwZYv/4g/jde1DGxGj2mfn5YVW7FpaV1aPe5JQAUm4RQhCeFM75J+e5+OQiV6OvEpkcSXRKNLGpsQiy7lJsa2pLZbfKVHOrRhW3KlRwqYCliUzk8yqZOEmSlC8JIUi5eJG4P3YRt2cPGeHhmn3GLi7Yt2mNXdu2WPj7y0RJynEqoeJh/EOuP73Ojac3uB59ncuRl1/azKZAgbOlM2Ucy1DWqSxlnctS1rEsxeyKYaQweovRS29CJk6SJOUrqqQkYrdtI/rnX0i7e1ez3cjGBtt338WuTWusAwLksiVSjlEJFSFxIVyOusylyEtcibrCtehrmoVnn2esMKa0Y2kquVaigksFvKy9cLRwxMnCCXtze0yM5Osyv5O/QUmS8oX00FCerl3L042bUMWqZzdWWFlh27gxdq1bYV2vHkbmsv+HlDOikqM4+ugohx8e5kToCeLT4jOVMTMyo6RjSUo7lqaMYxnKOZfD39lfNrMVcDJxkiQpzxJCkHTyb56uX0/83r2gVM9RY1qsGE7dumHfoQPGNgV3uSMpdylVSvU8SMkRPEl6wpPkJ4QlhnE67DQXIy9q9UkyNzanjFMZKjhXoLxLefyd/PG195U1SIWQ/I1LkpTnKOPiiP19G0/Xryftzh3Ndqt33sGpR3dsGjVCYSyHXEv6exj/kODQYIIfB/N32N9Zrs32TDmncjQo0oD6Rerj7+yPqZGcUVuSiVOh0qhRI6pUqcK8efMMHYokZSn90SOiVq8m5rfNiCR1/xGFlRX2bd/H8eOPsShTxsARSvlNfFo8f4f9TfDjYI4/Ps6D+Ada+02NTHG1dMXVyhVXS1dcLF0o61SW+kXq42blZqCopbxMJk7SW7F582YmTpzI7du3KVGiBN988w0dOnR46TEXL17kiy++4O+//8bJyYnPP/+ciRMnao2QOnz4MCNGjODy5ct4eXnx5Zdf0r9/f83+y5cvM2nSJP755x/u37/P3LlzGTZsWG7dpvSaUq7fIGrFj8T9sUvTHGdeqiQOH3+Mfdu2GNvIZSGkVxNCEJEUwZWoK1yOuszJ0JNcjLyotQyJicKESq6VqO1VmzpedSjvXF42t0l6MfirZcmSJcyePZvQ0FDKly/PvHnzqF+/fpZle/bsyerVqzNt9/f35/LlywCsWrWKXr16ZSqTnJws1xV7hbS0NMzMzHL8vMHBwXTp0oWpU6fSoUMHtm7dSufOnTl69KjWYrvPi4uLo1mzZjRu3JhTp05x48YNevbsibW1NSNHjgTg7t27tG7dmn79+vHrr79y7NgxBg4ciKurq2ah36SkJIoXL06nTp0YPnx4jt+b9GbSw8IImzaNhH37NdusatfGuW9frOvWkdMISC+VlJ7ExciLnAk/w4XIC1yJukJ0SnSmcr52vgR4BRDgGUBNj5pyfTbpjRg0cdqwYQPDhg1jyZIl1K1bl+XLl9OqVSuuXLlCsWLFMpWfP38+3377reZ5RkYGlStXplOnTlrl7OzsuH79utY2mTRl5uvrS9++fbl16xZbt26lffv2WSamb2revHk0a9aMsWPHAjB27FgOHz7MvHnzWLduXZbHrFmzhpSUFFatWoW5uTkVKlTgxo0bzJkzhxEjRqBQKFi2bBnFihXTND2WK1eO06dP891332kSp5o1a1KzZk0AxowZk+P3Jr0eIQQxv/1GxMxZqBISwMgI2+bNce7TB8uKFQwdnpRHJaUncTr8NCdDT3Im/AxXo69mWtTWSGFEcfvi+Dv7U9WtKgFeAXjbeBsoYqkgMmjiNGfOHPr06UPfvn0B9Rfsn3/+ydKlS5kxY0am8vb29tjb22ue//777zx9+jRTDZNCocDDwyN3g3+OEEKnxRdzg6WJ5Rv9VT579mwmTpzIhAkTsi0zffp0pk+f/tLz7N69O9uawuDg4Ey1PS1atHhpX6vg4GAaNmyI+XPDy1u0aMHYsWO5d+8efn5+BAcH07x580znXbFiBenp6Ziayo6ceVHaw0eETpxAUvAJACwqVcJz2lQsSpc2cGRSXnQ75jZ/PfyLY4+PcSb8DOmqdK39HtYeVHOrRmXXypR3KU9px9JyOgApVxkscUpLS+Off/7JVAvQvHlzjh8/rtM5VqxYwbvvvouPj4/W9oSEBHx8fFAqlVSpUoWpU6dStWrVHIv9RckZydRam3WTU2472fUkVqZWr318kyZNGDVq1EvL9O/fn86dO7+0jLd39n/RhYWF4e7urrXN3d2dsLCwlx7j6+ub6Zhn+/z8/LI9b0ZGBpGRkXh6er40ZuntUCYkknrtKilXrpBy+Qpxe/cikpJQmJvjOmwYTt27yRFykhYhBCdCT7Dy0kpOhJ7Q2udl7UWAl7rJrZpbNTxt5PtcersMljhFRkaiVCr1/kJ9JjQ0lN27d7N27Vqt7WXLlmXVqlVUrFiRuLg45s+fT926dTl//jylSpXK8lypqamkPrcQaFxc3GvcUf5Uo0aNV5ZxcnLCycnpja7zYq2YEOKVNWVZHfPidl3KSG+fSE8n5vffefrzz6Teug1Ce40uqxo18Jw2FbMXkmOpcFOqlOwP2c+KSyu4EnUFUM/EHeAVQD3vetTxqoOvna98f0sGpVfidP36ddatW8eRI0e4d+8eSUlJuLq6UrVqVVq0aEHHjh21mlZ08TpfqKDuBO7g4ED79u21tteuXZvatWtrntetW5dq1aqxcOFCFixYkOW5ZsyYQWBgoF5xP8/SxJKTXU++9vFv4k2rpK2tXz154Js21Xl4eGRKhiMiIjIlzbocA//VPGVXxsTEBGdn55fGK+UOkZFB7M6dRC5eQvqD/4Z9m3h4YOHvj4W/P5aVK2Fdty4KI7k2l6SWrkxn552drLy0kntx9wCwMLbgg1If0L18d9lHScpTdEqczp49y5dffsmRI0eoU6cO77zzDu3bt8fS0pLo6GguXbrE+PHjGTx4MF9++SXDhg17ZQLl4uKCsbGx3l+ooE6uVq5cSbdu3V45CszIyIiaNWty8+bNbMuMHTuWESNGaJ7HxcVRtGjRl573eQqF4o2ay/K6N22qCwgIYO/evVr9nIKCgqhTp85Ljxk3bpzWSL+goCC8vLw0TXgBAQHs2LFD67igoCBq1Kgh+ze9ZSI9nbg9e4hcslSzfpyxszPO/fpi//77mMhEVspCckYyW25u4adLPxGepF6k2c7Mjo/LfkzXcl1xsnizmm5Jyg06JU7t27dn9OjRbNiw4aVNNsHBwcydO5f//e9/jBs37qXnNDMzo3r16uzdu1drPp+9e/fSrl27lx57+PBhbt26RZ8+fV4ZuxCCc+fOUbFixWzLmJub611TVpi8aVPd0KFDadCgATNnzqRdu3Zs27aNffv2cfToUU2ZRYsWsXXrVvbvVw9L79q1K4GBgfTs2ZNx48Zx8+ZNpk+fzqRJkzQ1kv3792fRokWMGDGCfv36ERwczIoVK7RG6qWlpXHlyhXN/x89esS5c+ewsbGhZMmSr31PklrG06fEbNzE07VryQhXf/EZOzjg3LcPjl27YmRVcP+gkF6PUqXk3JNz7A/Zzx93/tBMH+Bi6UIP/x50KtMJa1O5jI6UhwkdpKam6lJM7/Lr168XpqamYsWKFeLKlSti2LBhwtraWty7d08IIcSYMWNEt27dMh336aefilq1amV5zsmTJ4s9e/aI27dvi7Nnz4pevXoJExMTcfLkSZ3jj42NFYCIjY3NtC85OVlcuXJFJCcn63y+vKJhw4Zi6NChmuc+Pj5i7ty5b+XamzZtEmXKlBGmpqaibNmyYvPmzVr7v/76a+Hj46O17cKFC6J+/frC3NxceHh4iMmTJwuVSqVV5tChQ6Jq1arCzMxM+Pr6iqVLl2rtv3v3rgAyPRo2bPja95KfXwM5JfXePfF40tfiauUq4kqZsuJKmbLiet164snSZSIjPsHQ4Ul5THJ6sjjy8IiYfHyyaLC+gaiwqoLm0eK3FmLDtQ0iJSPF0GFKhdjLvvdfpBDihV6br3D37l38/PxyLHFbsmQJs2bNIjQ0lAoVKjB37lwaNGgAqCe8vHfvHocOHdKUj42NxdPTk/nz59OvX79M5xs+fDhbtmwhLCwMe3t7qlatyuTJkwkICNA5pri4OOzt7YmNjcXOzk5rX0pKiuZnIOeGKpwK82sg7eFDIpcsJXbbtv9m+C5XDqce3bFr3RqjXJhAVcp/hBDcjb3LscfHOPboGKfDT5Oq/G8Ajq2ZLY2LNqZpsaY0KNJAztwtGdzLvvdfpHfiZGxsTIMGDejTpw8ffvhhgfzikImT9DKF8TWQHhpK5NJlxGzZAhkZAFg3bIBznz5Y1awpRzlJwH+dvFddXsWd2Dta+9ys3GhYpCHv+rxLTY+acsFcKU/RJ3HSO80/f/48K1euZOTIkXzxxRd06dKFPn368M4777x2wJIk5U0p168TvWo1cTt3ItLVEw9a162L6+AvsKxSxbDBSXlGUnoSv934jZ+v/Kzp5G1mZEZ19+rU9a5LXa+6lHAoIRNsqUDQO3GqUKECc+bMYdasWezYsYNVq1ZRr149SpUqRZ8+fejWrRuurq65EaskSW+BUKlIPHqU6FWrSDwerNlu9c47uA4ZjJUOc39JhUNCWgJrrq7hl6u/EJsaC6g7eXf3706n0p3kmnBSgaR3U92LUlNTWbJkCWPHjiUtLQ1TU1O6dOnCzJkz8+3MzbKpTnqZgvwaSPrnH8KmTCX12VqPRkbYtmiOc48esoZJ0khKT2LttbWsurxKkzAVsy1Grwq9eL/E+5gby1HKUv6Sq011z5w+fZqVK1eyfv16rK2tGTVqFH369OHx48dMmjSJdu3a8ffff7/u6SVJeosynj4l4rvviN28BQAja2scOnXC8dNPMSsiJx+U1NKV6ay7to4Vl1ZophHwtfNlQOUBtPBtgbGRXDpHKvj0TpzmzJnDTz/9xPXr12ndujU///wzrVu3xujfWYD9/PxYvnw5ZcuWzfFgJUnKWUIIYrf+TsSsWShjYgBw6NQJ1xHDMXF0NGxwUp5yLuIcgcGB3Iq5BUBR26IMqDyAVn6t5Kg4qVDR+9W+dOlSevfuTa9evfDw8MiyTLFixVixYsUbBydJUu5JCwkhdMJEkv6tGTYvXRqPyZOxqpZ7C2JL+U9CWgLzz8xnw/UNCAROFk4MqTqEtiXbypFxUqGkd+L0sqVLnjEzM6NHjx6vFZAkSblLKJU8XbOGiLnzEMnJKCwtcf3iC5y6d0Mhl6qRnnP4wWGmnJhCRJJ6nch2JdoxqsYoHCwcDBuYJBnQa9WvxsTE8PfffxMREYFKpdLa17179xwJTJKknJd65y6h48eTfPYsAFa1a+M5bSpmRYoYODIpL0lIS2DWqVlsvbUVUDfLTQqYRG3P2q84UpIKPr0Tpx07dvDJJ5+QmJiIra2t1rwcCoVCJk55WKNGjahSpQrz5s0zdCjSW5b++DFRP60iZsMGRFoaRtbWuI0ejUOXznJuHUnLP+H/MP7oeB4lPEKBgu7+3RlUdRCWJpaGDk2S8gQjfQ8YOXIkvXv3Jj4+npiYGJ4+fap5REdH50aMUgGwefNm/P39MTc3x9/fn61bt77ymIsXL9KwYUMsLS3x9vZmypQpvDh7xuHDh6levToWFhYUL16cZcuWae3fsmULNWrUwMHBAWtra6pUqcIvv/ySo/eWl6XeucPjseO41bwFT3/5BZGWhnXduhTfsR3Hj7rIpEnSSFWmMuefOfTa04tHCY/wtvFmZYuVjKo5SiZNkvQcvWucHj16xJAhQ7CSq54XOGlpaZjlwlpjwcHBdOnShalTp9KhQwe2bt1K586dOXr0KLVq1crymLi4OJo1a0bjxo05deoUN27coGfPnlhbWzNy5EhAvW5i69at6devH7/++ivHjh1j4MCBuLq60rFjRwCcnJwYP348ZcuWxczMjJ07d9KrVy/c3Nxo0aJFjt9rXpHx9CnhU6cSt3sP/JtsWtWujXO/vljXqSMTJgkApUrJqfBT7Lqzi3339xGfHg9A+5Lt+armV3ICS0nKgt6JU4sWLTh9+jTFixfPjXikt8jX15e+ffty69Yttm7dSvv27Vm9enWOX2fevHk0a9aMsWPHAjB27FgOHz7MvHnzWLduXZbHrFmzhpSUFFatWoW5uTkVKlTgxo0bzJkzhxEjRqBQKFi2bBnFihXTND2WK1eO06dP891332kSp0aNGmmdd+jQoaxevZqjR48W2MQp6cwZHo0YSUZYGAA27zbFpV8/LCtXNnBkUl6gEirORZxj7/297Lm3h8jkSM0+D2sPxrwzhqbFmhowQknK2/ROnNq0acPo0aO5cuUKFStWxPSFUTht27bNseDyCyEEIjnZINdWWFq+Ue3B7NmzmThxIhMmTMi2zPTp05k+ffpLz7N7927q16+f5b7g4GCGDx+uta1FixYv7WsVHBxMw4YNMTc31zpm7Nix3Lt3Dz8/P4KDg2nevHmm865YsYL09PRMr00hBAcOHOD69evMnDnzpfeTHwmViuiffiJizlxQKjHz9cXrf99hWb68oUOTDCxDlcE/4f+w9/5e9ofs10qW7M3taebTjNZ+ranuXh0jhd49OCSpUNE7cerXrx8AU6ZMybRPoVCgVCrfPKp8RiQnc71adYNcu8yZf1C8QbNpkyZNGDVq1EvL9O/fn86dO7+0jLd39rNLh4WF4e7urrXN3d2dsH9rRLI7xtfXN9Mxz/b5+flle96MjAwiIyM1S/7Exsbi7e1NamoqxsbGLFmyhGbNmr30fvIbZUwMj8eMJeHQIQDsWrfGY8oUjG2sDRuYZFBpyjS23tzK9xe/10wpAGBrakvDog1p6duSOl51MDWW01BIkq70TpxenH5Ayt9q6LBgq5OTE05OTm90nRdrxYQQr6wpy+qYF7frUsbW1pZz586RkJDA/v37GTFiBMWLF8/UjJdfqRITud+jJ6nXr6MwM8N93Dg5Wq6QS1els/3WdpZfWE5oYigADuYONCnWhHeLvUttz9oyWZKk1yTnyc8BCktLypz5x2DXfhPW1q+ukXjTpjoPD49MtUsRERGZaot0OQb+q3nKroyJiQnOzs6abUZGRpQsWRKAKlWqcPXqVWbMmFEgEichBI/HjiP1+nWMXVwo9v1yLPz9DR2WZCBCCHbd3cWis4t4mPAQAFdLV/pW7MuHpT/EzDjnB39IUmGjU+K0YMECPvvsMywsLFiwYMFLyw4ZMiRHAstPFArFGzWX5XVv2lQXEBDA3r17tfo5BQUFUadOnZceM27cOK2RfkFBQXh5eWma8AICAtixY4fWcUFBQdSoUSNT/6bnCSFITU196f3kF1HLlhEfFASmphRZsEAmTYXY5ajLfHvyW849OQeAk4UTfSr0oXOZzliYWBg2OEkqQHRKnObOncsnn3yChYUFc+fOzbacQqEolIlTQfemTXVDhw6lQYMGzJw5k3bt2rFt2zb27dvH0aNHNWUWLVrE1q1b2b9/PwBdu3YlMDCQnj17Mm7cOG7evMn06dOZNGmSpgmqf//+LFq0iBEjRtCvXz+Cg4NZsWKF1ki9GTNmUKNGDUqUKEFaWhq7du3i559/ZunSpa99P3lF/IEDPJmv/kPGY9JEucZcIRWZHMmCMwv4/dbvCASWJpb0qdCHbv7dsDItuH/QSZKh6JQ43b17N8v/S5Iu6tSpw/r165kwYQITJ06kRIkSbNiwQWsOp8jISG7fvq15bm9vz969exk0aBA1atTA0dGRESNGMGLECE0ZPz8/du3axfDhw1m8eDFeXl4sWLBAMxUBQGJiIgMHDuThw4dYWlpStmxZfv31V7p06fJ2bj6XpN6+zePRXwLg2LUrjp06GTgiyRCC7gUx6fgkEtMTAXiv+HsMqzYMd+vsm8ElSXozCvHiVMyvMGXKFEaNGpVpAszk5GRmz57NpEmTcjRAQ4iLi8Pe3p7Y2Fjs7Oy09qWkpHD37l38/PywsJDV34WRoV8Dyrg47nXqTNr9+1jVrEmxlSvk4ryFjBCCZReWseTcEgDKO5dnzDtjqOJWxbCBSVI+9bLv/RfpPWFHYGAgCQkJmbYnJSURGBio7+kkSdLTkwULSbt/HxMvT7znz5NJUyGTkpHCV399pUmauvl3Y03rNTJpkqS3RO9RddkNIz9//vwbD1mXJOnl0sMjiNm4EQCvb77BRL7nCpUnSU8YcmAIl6IuYaIwYULtCXQs3fHVB0qSlGN0TpwcHR3Vo8cUCkqXLq2VPCmVShISEujfv3+uBClJklr0yhWItDQsq1fHqnZtQ4cjvSXpqnS23tzKknNLiEqJwt7cnrmN5lLTo6ahQ5OkQkfnxGnevHkIIejduzeBgYHY29tr9pmZmeHr60tAQECuBClJEmQ8ecLT9RsAcBk4QE5wWQiohIrdd3ez+NxiHsQ/AKCEfQkWNFlAMbtiBo5OkgonnROnHj16AOqRTHXr1sXEpHDPnalnn3qpADHU7z5q5U+I1FQsK1fG+iVzYEn5X0JaAgcfHGT15dVcf3odAGcLZz6r9BmdSneSs35LkgHplP0kJiZqZphu2LChXuULmmcTKyYlJWH5hrN2S/lTUlISwEsn2cxpGVFRPP13fiqXLwbJ2qYCKDE9kUMPDvHnvT859ugYaao0QL2uXK8Kvfik3CdyXiZJygN0SpxKlizJ4MGD6dmzJ15eXlmWEUKwb98+5syZQ4MGDRg7dmyOBppXGBsb4+DgoFn+w8rKSn6JFRJCCJKSkoiIiMDBwQFjY+O3du3on35CpKRgUbEi1vXqvbXrSrkvMjmSFRdXsOnGJlKV/81o72vnS2u/1nQt1xV7c/uXnEGSpLdJp8Tp0KFDTJgwgcDAQKpUqUKNGjXw8vLCwsKCp0+fcuXKFYKDgzE1NWXs2LF89tlnuR23QXl4eAD/rZ0mFS4ODg6a18DbkPH0KdFr/61tkn2bCozY1Fh+uvQTa6+tJTkjGQAfOx9a+LaghW8LSjmUkr9rScqD9JoA8+HDh2zatIm//vqLe/fukZycjIuLC1WrVqVFixa0bt0aIyO9p4bKc3SdCEupVJKenv4WI5MMzdTU9K3WNAFEzJlL1PffY+Hvj+/m3+SXaT6Xrkpn1aVVrLy0koR09Zx4FZwrMLjqYAK8AuTvV5IMQJ8JMPWeObww0OcHKEm5KT08gjutWqFKSqLI4kXYNm1q6JCkN/Ao4RFf/fUV55+cB6CUYym+qPIFjYs2lgmTJBmQPt/7hXtonCTlYSIjg0cjR6BKSsKiQgVsmjQxdEjSG9h7fy9fH/ua+PR4bE1tGVNrDO8Vfw8jRf6vpZekwkQmTpKURz2Zv4Dk0/9gZG2N93ezZY1EPpWSkcLsU7PZeEM943sll0rMbDCTIrZFDByZJEmvQyZOkpQHxR86RNQPPwDg+c00zHx9DRuQpLd0VTo7b+9k+YXlPEp4BECfCn0YVHUQpkZyHiZJyq9k4iRJeUz6o0c8/moMAI6ffopdy5YGjkjSh1KlZNfdXSw9v1Qz27erpSvT6k6jjrecuFSS8juDN64vWbIEPz8/LCwsqF69OkeOHMm2bM+ePTXr5T3/KF++vFa5zZs34+/vj7m5Of7+/mzdujW3b0OScoRIS+PhiBGoYmOxqFgRty9HGzokSQ9Xo67Sflt7xh0dx4P4BziaOzKqxij++OAPmTRJUgGhc+J08+ZNPv74Y+Li4jLti42NpWvXrty5c0evi2/YsIFhw4Yxfvx4zp49S/369WnVqhUhISFZlp8/fz6hoaGax4MHD3BycqJTp06aMsHBwXTp0oVu3bpx/vx5unXrRufOnTl58qResUmSIYR/9x0p5y9gZGeH99y5GJmZGTokSUchcSH039efe3H3sDe3Z2i1oezpuIce5XtgaSJXGZCkgkLn6Qg+++wzHBwcmDVrVpb7v/rqK+Li4li6dKnOF69VqxbVqlXTOqZcuXK0b9+eGTNmvPL433//nQ8++IC7d+/i4+MDQJcuXYiLi2P37t2aci1btsTR0ZF1/y5Z8SpyOgLJEOL37ePhF4MBKLJkMbZyFF2+EZkcSbdd3XiY8JByTuX4scWP2JnJzw5Jyi/0+d7Xucbpr7/+0qrZeVHnzp05cOCAzkGmpaXxzz//0Lx5c63tzZs35/jx4zqdY8WKFbz77ruapAnUNU4vnrNFixY6n1OSDCHt4SMejxsPgFOvXjJpykcS0xMZuG8gDxMeUsSmCEveXSKTJkkqwHTuHH7//n3c3Nyy3e/i4sKDBw90vnBkZCRKpRJ3d3et7e7u7oSFhb3y+NDQUHbv3s3atWu1toeFhel9ztTUVFJT/1sjKqvmSEnKLSItTT1fU1wcFpUr4TZiuKFDknSUrkxn+MHhXI2+ipOFE8uaLcPF0sXQYUmSlIt0rnGyt7fn9u3b2e6/devWazVrvTg3jRBCp/lqVq1ahYODA+3bt3/jc86YMQN7e3vNo2jRoroFL0k5IGLuvP/6Nf1vDgpTOVQ9P0hXpjP+2HiCQ4OxNLFkcdPF+Nj5vPpASZLyNZ0TpwYNGrBw4cJs9y9YsID69evrfGEXFxeMjY0z1QRFRERkqjF6kRCClStX0q1bN8xe6Dzr4eGh9znHjh1LbGys5qFPzZkkvYn4gweJ/uknALymf4NZEW8DRyTp4tbTW3yy6xN2392NicKEOY3mUMGlgqHDkiTpLdA5cRo7diy7d+/mww8/5O+//9YkGSdPnqRjx478+eefjB07VucLm5mZUb16dfbu3au1fe/evdSp8/Jhu4cPH+bWrVv06dMn076AgIBM5wwKCnrpOc3NzbGzs9N6SFJuSw8NJXSM+j3j2K0btu++a+CIpFdRCRWrL6+my84uXI2+ir25PXMazaGedz1DhyZJ0luicx+nqlWr8ttvv9G7d+9M8yI5OzuzceNGqlWrptfFR4wYQbdu3ahRowYBAQF8//33hISE0L9/f0CdrD169Iiff/5Z67gVK1ZQq1YtKlTI/Bfe0KFDadCgATNnzqRdu3Zs27aNffv2cfToUb1ik6TcJIQgdMJElLGxWJQvj9voUYYOSXqJhLQEbsXcYv6Z+ZwOPw1Afe/6BNYJxNXK1cDRSZL0Nuk1c/h7773H/fv32bNnD7du3UIIQenSpWnevDlWVlZ6X7xLly5ERUUxZcoUQkNDqVChArt27dKMkgsNDc00p1NsbCybN29m/vz5WZ6zTp06rF+/ngkTJjBx4kRKlCjBhg0bqFWrlt7xSVJuidu+ncRjx1CYmeH13Ww5X1MeE5YYxurLq7n59CZ3Y+8SkRyh2WdpYsmXNb+kY6mOcv1ASSqEdJ7HqTCR8zhJuSkjKoo7rdugjI3FdfhwXD7/zNAhSc+JSYnh092fcj/uvtZ2F0sXKrlUYlSNURS1kwNIJKkg0ed7X+capylTpmS53d7enjJlytC8eXOMjAy+gosk5XnhM75FGRuLedmyOPfuZehwpOekKlMZenAo9+Pu42ntycAqAyluXxxfe185N5MkSYAeiVN2673FxMTw6NEjypcvz59//vnSuZ4kqbBLOHyYuJ07wcgIz6lT5dQDeYhKqJh4dCJnIs5ga2rLkqZLKOlY0tBhSZKUx+icOJ09ezbbfaGhoXTt2pVx48bx448/5khgklTQKBMSCZ0cCIBTjx5YVpTD1/OShWcXsvueenqBuY3nyqRJkqQs5UjbmqenJ9OmTdNryRVJKmyezJtHRmgopkWK4Dr4C0OHIz3ntxu/8eNF9R99k+tMppanHEwiSVLWcqxTkre3NxEREa8uKEmFUMq1azxdswYAzymBGL3GKFQpd1yLvsa0E9MA6F+5P+1KtjNwRJIk5WU5ljidP38eX1/fnDqdJBUoUT/8CEJg27Il1q+Y4FV6u+admYdSKGlStAkDKw80dDiSJOVxOvdxym7h29jYWE6dOsXIkSPp27dvjgUmSQVF2oMHxO3eDYDLZ/0MHI30vFNhpzj26BgmChNG1Rgl52WSJOmVdE6cHBwcsv1QUSgUfP7553z55Zc5FpgkFRTRP/0EKhXW9eph4e9v6HCkfwkhmPfPPAA6lu4o52aSJEknOidOBw8ezHK7nZ0dpUqVwsbGJseCkqSCIiMqipjNWwBwljWyecqBBwe4EHkBSxNL+lfub+hwJEnKJ3ROnBo2bPjKMufOnaNKlSpvEo8kFSjRv/yCSE3FolIlrGq9Y+hwpH9lqDJYcGYBAJ+W+xQXSxcDRyRJUn7xxp3DY2NjWbJkCdWqVaN69eo5EZMkFQjKhESerl0HgHPfPrL/TB6y4/YO7sTewd7cnl4V5OztkiTp7rUTpwMHDvDpp5/i6enJwoULad26NadPn87J2CQpX4vZuBFVXBxmfn7YvvuuocOR/pWqTGXJ+SUA9KvYD1szWwNHJElSfqJzUx3Aw4cPWbVqFStXriQxMZHOnTuTnp7O5s2b8ZedXiVJQ6SlEb16NQDOfXqjkOs45hnrr60nLDEMdyt3upTpYuhwJEnKZ3T+NG/dujX+/v5cuXKFhQsX8vjxYxYuXJibsUlSvhW7YycZ4eGYuLlh17atocOR/rXzzk5N36aBVQZiYWJh4IgkScpvdK5xCgoKYsiQIQwYMIBSpUrlZkySlK8JIYj6aSWgXpPOyMzMwBFJSpWSBWcXsPKS+vfSpGgT2paQCa0kSfrTucbpyJEjxMfHU6NGDWrVqsWiRYt48uRJbsYmSflSyqVLpN26jcLCAofOnQwdTqGXkJbA0INDNUlT34p9mdt4LiZGevVUkCRJAvRInAICAvjhhx8IDQ3l888/Z/369Xh7e6NSqdi7dy/x8fG5Gack5Ruxv28DwPbddzG2lR2PDelxwmO67e7G4YeHMTc259v63zK02lCMFLLPmSTlK8oMuPib+mFgCiGEeN2Dr1+/zooVK/jll1+IiYmhWbNmbN++PSfjM4i4uDjs7e2JjY3Fzs7O0OFI+YhIS+Nmg4YoY2Io+sMP2NSvZ+iQCi2lSkn33d25EHkBV0tXFjRZQAWXCoYOS5IkfaQnw9lf4fhCiLkPdt4w5ByY5GwXCH2+99/oz64yZcowa9YsHj58yLp1697kVJJUICQcOYIyJgYTV1esA2obOpxCbf319VyIvIC1qTW/tv5VJk2SlJ8kP4XDs2FuBdg1Sp00WTlDtR6gyjBoaDnSyG9sbEz79u1p3759TpxOkvKt2G3qGle7999HYSL70BjK44THzD8zH4AR1UfgZeNl4IgkSdJJ8lMIXgInl0FqnHqbQzEIGAxVPwUzK8PGRw4lTpIkgTImhoR/13S0bydHbBmKEIKpJ6aSnJFMNbdqfFj6Q0OHJEnSqyTHwImlcGLJfwmTW3moNxzKdwDjvJOu5J1IJCmfi9uzB5GejnnZsliUKWPocAqtXXd3cfTRUUyNTPm6zteyI7gk5VXKDLh/FC7/Dpe2QGqserubPzQaA2Xfhzw4ebBMnCQphzwbTWffrp2BIym8nqY8ZebfMwH4vNLnFLcvbuCIJEnSolLC3cNweStc3QnJ0f/tcy0Hjb6Ccu3yZML0jEycJCkHpN2/T/K5c2BkhP17bQwdTqE1+9RsnqY+paRDSXpX6G3ocCRJeib8MpxfBxc2QULYf9stnaDce+DfDoo3ydMJ0zOvlTjduHGDQ4cOERERgUql0to3adKkHAlMkvKTZ53CrevVxcTV1cDRFE7HHx9nx50dKFAQWCcQU2NTQ4ckSYVbXChc2gwX1kPYxf+2WzqCf3so3x586uWp/ku60DvaH374gQEDBuDi4oKHhwcKhUKzT6FQyMRJKnSESkXstn+b6drKZjpDSFOmMf3kdAA+LvsxlVwrGTgiSSqkkmPg6g64uBHuHgH+nSrSyBRKt4DKH0Op5jk+D9PbpHfiNG3aNL755hu++uqr3IhHkvKd5DNnSH/0CCNra2ybNjF0OIXSqsuruB93HxdLF76o+oWhw5GkwifmARz5Ds6tA2Xqf9uL1oaKH0KFjmDlZLj4cpDeidPTp0/p1EmuvyVJzzxrprNt0QIjS0sDR1P4PIx/yPcXvgdgVI1R2JrJZW4k6a2JewxH5sCZ1aBMU29zLQeVOqmTJUdfg4aXG/ROnDp16kRQUBD9+/fPjXgkKV9RpaUR9+efANi3lXM3GcLMv2eSqkzlHY93aO3X2tDhSFLhkJoAB6fDqR//q2HyrQ+Nx0GxAHiuG09Bo3fiVLJkSSZOnMiJEyeoWLEipqbaHTCHDBmSY8FJUl6XcPgwqrg4TNzdsXqnpqHDKXQOhhzk0MNDmChMGFdrnFafS0mScsnjs/BbH4i+rX5etDY0GQ9+DQwb11uid+L0/fffY2Njw+HDhzl8+LDWPoVCIRMnqVCJ27ETALv32qDIB8NoC5LkjGS+/ftbALqX704JhxIGjkiSCjiVCk4shn2BoEpXL7j7/nwo+W6BrmF6kd6J0927d3MjDknKd5RxcSQcOgSA/fvvGzaYQuiHCz/wOPExHtYefF7pc0OHI0kFW0IEbO0Pt/ern5d9D9ouLDAdvvWRvyZPkKQ8JD4oCJGWhnmpkpjLJVbeqpC4EFZdXgXAmJpjsDI1/MKfklQgqZTwzyo4MFW9AK+JBbScAdV7Fapapue9VuL08OFDtm/fTkhICGlpaVr75syZkyOBSVJeF6tppntf9q15y747/R3pqnTqeNWhSTE5BYQk5YqQk7BrFIRdUD93rwAdfwS3coaNy8D0Tpz2799P27Zt8fPz4/r161SoUIF79+4hhKBatWq5EaMk5Tnp4eEk/f03gFxi5S07/vg4Bx8cxFhhzFc1v5JJqyTllIw0iAmBp/fg0m/qJVIAzO3Vo+Vq9s13s3znBr17s44dO5aRI0dy6dIlLCws2Lx5Mw8ePKBhw4avNb/TkiVL8PPzw8LCgurVq3PkyJGXlk9NTWX8+PH4+Phgbm5OiRIlWLlypWb/qlWrUCgUmR4pKSl6xyZJ2Ynb+QcIgWX16ph6exs6nEIjXZWuWcT347IfU9xBLuIrSa9FCAi7BEfnwS8dYG4FmOYGi6rDmo7/JU1VP4XB/0Dt/jJp+pfeP4WrV6+ybp36B2piYkJycjI2NjZMmTKFdu3aMWDAAJ3PtWHDBoYNG8aSJUuoW7cuy5cvp1WrVly5coVixYpleUznzp0JDw9nxYoVlCxZkoiICDIyMrTK2NnZcf36da1tFhYWet6pJGUvdscOQHYKf9s2Xt/Indg7OJo70r+ynEtOkvSiUsGtfXB1G9zaD/GhmcuYWoGjH7iUgjqDoUiNtx9nHqd34mRtbU1qqnqyKy8vL27fvk358uUBiIyM1Otcc+bMoU+fPvTt2xeAefPm8eeff7J06VJmzJiRqfyePXs4fPgwd+7cwclJ3ZPf19c3UzmFQoGHh4desUiSrlJv3iT12jUwNcWuZQtDh1NoRKdEs/jcYgC+qPoF9ub2Bo5IkvIJZTpc2gLH5kHElf+2m1iq514q2RQ8q4CTH1i7FtpO37rSO3GqXbs2x44dw9/fnzZt2jBy5EguXrzIli1bqF27ts7nSUtL459//mHMmDFa25s3b87x48ezPGb79u3UqFGDWbNm8csvv2BtbU3btm2ZOnUqls8tdZGQkICPjw9KpZIqVaowdepUqlatmm0sqampmmQQIC4uTuf7kAqfZ53CberXx9jBwbDBFCKLzy4mPi2eMo5l6Fiqo6HDkaS8Lz0Fzv4CxxZAbIh6m5ktVOkKZVpCsTpgKltj9KV34jRnzhwSEhIAmDx5MgkJCWzYsIGSJUsyd+5cnc8TGRmJUqnE3d1da7u7uzthYWFZHnPnzh2OHj2KhYUFW7duJTIykoEDBxIdHa3p51S2bFlWrVpFxYoViYuLY/78+dStW5fz589TqlSpLM87Y8YMAgMDdY5dKryESkXszmfNdO8ZOJrC43r0dX67+RsAY94Zg7GRsYEjkqQ87sHf8PsAiLqlfm7tCrUHQI0+YOlg0NDyO4UQQhjiwo8fP8bb25vjx48TEBCg2f7NN9/wyy+/cO3atUzHNG/enCNHjhAWFoa9vbqafsuWLXz44YckJiZq1To9o1KpqFatGg0aNGDBggVZxpJVjVPRokWJjY3Fzs7uTW9VKkASjh7jQd++GFlbU+rYUYxk37lcF50STY/dPbgXd48Wvi34ruF3hg5JkvKu9GQ4+A0ELwahAhsPaDBK3cnbVC5Cnp24uDjs7e11+t5/rS7yMTEx/Pbbb9y+fZvRo0fj5OTEmTNncHd3x1vHEUYuLi4YGxtnql2KiIjIVAv1jKenJ97e3pqkCaBcuXIIIXj48GGWNUpGRkbUrFmTmzdvZhuLubk55ubmOsUtFV5CCJ7Mnw+AfccPZNL0FiSkJTBg3wDuxd3D09qTL2t+aeiQJCnvenDq31qmf7/vKneFltPB0tGwcRUwek9HcOHCBUqXLs3MmTP57rvviImJAWDr1q2MHTtW5/OYmZlRvXp19u7dq7V979691KlTJ8tj6taty+PHjzVNhQA3btzAyMiIIkWKZHmMEIJz587h6empc2ySlJX4fftIuXgRhZUVLp/LJT5yW6oylaEHh3Il6gpOFk583+x73KzcDB2WJOU9ynTYPxVWNlcnTTYe8PEG6LBUJk25QO/EacSIEfTs2ZObN29qDfFv1aoVf/31l97n+vHHH1m5ciVXr15l+PDhhISE0L+/epjx2LFj6d69u6Z8165dcXZ2plevXly5coW//vqL0aNH07t3b00zXWBgIH/++Sd37tzh3Llz9OnTh3PnzmnOKUmvQyiVmtompx7dMXF2NnBEBVuGKoMvD3/J32F/Y21qzZJ3l+Br72vosCQp74m8CSuawZHv1E1zlT6CQSfUnb+lXKF3U92pU6dYvnx5pu3e3t7ZdurOTpcuXYiKimLKlCmEhoZSoUIFdu3ahY+PDwChoaGEhIRoytvY2LB3714GDx5MjRo1cHZ2pnPnzkybNk1TJiYmhs8++0zTD6pq1ar89ddfvPPOO/reqiRpxO7YQdqt2xjZ2+Pcq5ehwynQhBBMCZ7CgQcHMDMyY2GThZR3Lm/osCQpbxECTq+EP8dDRjJYOMD786F8e0NHVuDp3Tnc3d2dPXv2ULVqVWxtbTl//jzFixcnKCiIPn368ODBg9yK9a3Rp5OYVPCJtDRut2pN+qNHuI0aifO/845JuWPrza1MOj4JI4URcxrNoWmxpoYOSZLylvArsHeiejJLgOKNoP1SsPMyaFj5mT7f+3o31bVr144pU6aQnp4OqCebDAkJYcyYMXTsKOdWkQqep5s2kf7oESaurjh+8omhwynQEtMTWXBWPfp1SNUhMmmSpOc9vQ9b+8PSOuqkydgMWkyHT7fKpOkt0jtx+u6773jy5Alubm4kJyfTsGFDSpYsia2tLd98801uxChJBqNKSiJy6TIAXAYOwCiLKS+knLPy0koikyMpaluUbv7dDB2OJOUNT+/Bri9hYfV/15AT4N8OBhyHgEFgpPdXufQG9O7jZGdnx9GjRzlw4ABnzpzRzJP07rvv5kZ8kmRQ0b/8ijIyEtMiRXCQNaq5KjQhlNWXVwMwsvpIzIzNDByRJBmIEPD4LFzfBdd2QcTl//YVbwxNJ4F3NcPFV8i99lLHTZo0oUmTJjkZiyTlKbHbthG5aBEArkMGozCTX+S5ad6ZeaQqU6nhXoMmxeRni1TIpCfDncNwYw/c+BPiH/+3T2EMvvWg/gh1fybJoF4rcfr77785dOgQERERqFQqrX1z5szJkcAkyVCESsWTefOJ+v57AGxbtMCuTRsDR1WwXXhygV13d6FAweiao1HIRUalwkAIuLQZLm5SJ00Zyf/tM7VWL75btg2Uag5WToaLU9Kid+I0ffp0JkyYQJkyZXB3d9f6gJMfdlJ+p0pK4vFXY4j/d2JW588+w3XYUBSyD0GuEUIw69QsANqWaIu/s7+BI5KktyAtEXYMg4sb/9tmV0Q9/1LpluBbXy7Am0fpnTjNnz+flStX0rNnz1wIR5IMJz08gocDB5Jy+TKYmuI5dQoO7dsbOqwC7897f3L+yXksTSwZUm2IocORpNwXdRs2dFP3XVIYQ92hUKEjuJcHWQGR5+mdOBkZGVG3bt3ciEWSDCbt4SNCevUi/cEDjB0dKbJoIVbVqxs6rAIvMT2ROf+om/d7V+gtl1SRCr7ru2HL55AaC9Zu0GkV+Mrv1PxE7/aH4cOHs3jx4tyIRZIMIvXuXe5/+inpDx5gWrQovhs3yKTpLZl1ahahiaF423jTo3wPQ4cjSblHCDg0E9Z9pE6aitaCz/+SSVM+pHeN06hRo2jTpg0lSpTA398fU1NTrf1btmzJseAkKbel3LhBSO8+KCMjMStenGI/rcTU3d3QYRUKB0IOsOXmFhQo+KbeN1iayDmypAJKmQ47h8HZX9XPa/WHZlPBRI7UzY/0TpwGDx7MwYMHady4Mc7OzrJDuJRvJV++zIM+fVHGxGBetizFVvwoF+99S6KSowgMDgSgZ/meVHeXNXxSAZWaAJt6wq29oDCCNnOghlzvMj/TO3H6+eef2bx5M23k8GwpH0u9fZuQnr1QxcdjUbEixX74HmMHB0OHVSgIIQgMDiQ6JZpSjqX4ouoXhg5JknJHwhNY20k9maWJJXT6Ccq0MnRU0hvSO3FycnKiRIkSuRGLJL0VIi2NR6NGo4qPx7JqVYr+8D3GNjaGDqvQ+P3W7xx8cBATIxNm1JshZwiXCqboO/DLB/D0Llg5Q9eNUKSGoaOScoDencMnT57M119/TVJSUm7EI0m57smCBaRevYqxgwPe8+fJpOktepTwiJmnZgLwRZUvKONUxsARSVIuiLgGK1upkyZHX+izVyZNBYjeNU4LFizg9u3buLu74+vrm6lz+JkzZ3IsOEnKaYkn/yZqxUoAPKdNxdRNDn9/W5QqJeOOjCMxPZFqbtXoWb6noUOSpJwXegF+aQ9JUeDmD91+B1s54KQg0Ttxai8nBJTyKWVsLI+/+gqEwKHTh9jKhanfqp8u/8SZiDNYmVgxrd40jI2MDR2SJOWsB6dgTUdIiQWvqvDpFrlUSgGkd+L09ddf50YckpSrhBCEBU4hIywMU59iuI8ZY+iQCpXLkZdZfFY9/9vYWmMpalvUwBFJUg67cwjWfwJpCVC0NnyyESzsDR2VlAtea5FfScpv4nbsIG7XLjA2xnvWLIysrQ0dUqGRlJ7EmCNjyBAZNPNpRrsS7QwdkiS9ufgwuHsE7h6Gu39BzH319uKN4KO1YCY/YwoqmThJBZ4yPp6wad8A4DJoIJaVKxs4osLlf6f/x724e7hZujGp9iQ595uUf6UlweWt8M8qePi39j4jEyj/AbRdKBfnLeBk4iQVeE/XrEUVF4dZiRK4fPaZocMpVA4/OMzGG+rV36fVm4aDhYNhA5Kk1xF+WZ0snd+gXi4FAAV4VAS/BuDXEHwCwNzWkFFKb4lMnKQCTZWURPTq1QC4fP4ZChP5kn9bIpMjmXR8EgDd/LsR4BVg4IgkSU8qJeydBMGL/tvm4APVe0CVT8DWw3CxSQYjv0WkAi1m0yaUT59iWrQodq1bGzqcQkMIwcRjEzWzgw+tNtTQIUmSflLjYXNfuLFH/bzc+1CjN/g1AiO9p0CUChC9EyelUsmqVavYv38/ERERqFQqrf0HDhzIseAk6U2o0tI0czY59+sra5veorXX1nL00VHMjMyYWX8m5sbmhg5JknQX+xDWfgThF8HEAtovhQofGDoqKY/Q+5tk6NChrFq1ijZt2lChQgXZ0VPKs2K3bCUjIgITd3fs5fxjb8316Ov87/T/ABhVcxSlHEsZOCJJ0sOjf2Ddx5AQDtau8PF6Oeu3pEXvxGn9+vVs3LiR1rLZQ8rDREYGUT/+CIBznz4Ymcn10N6GlIwUvvrrK9JV6TQs0pCPynxk6JAkSXe39qvnYspIVs/63XUDOBQzdFRSHqN34mRmZkbJkiVzIxZJyjFxf/xB+sOHGDs54dDpQ0OHU2j87/T/uB17G2cLZwLrBMoaaSn/uLoTfusFyjQo0QQ6rQYLO0NHJeVBevdwGzlyJPPnz0cIkRvxSNIbEyoVkcu/B8CpZ0+MLC0NHFHhcOjBIdZfXw/AN/W+wdnS2bABSZKuLv4GG7urk6ZybeHjDTJpkrKld43T0aNHOXjwILt376Z8+fKZFvndsmVLjgUnSa8jPmgvaXfuYGRnh2PXjw0dTqEQnRLNpGP/TT1Q17uugSOSJB39sxp2DAUEVPoI2i0GYzmQRMqe3q8OBwcHOnTokBuxSNIbE0IQtWIFAE6ffoqxjY2BIyocZpycwdPUp5RyLMWwasMMHY4k6ebEMtjzlfr/NXpD6//JqQakV9I7cfrpp59yIw5JyhHJZ8+RcvEiCjMzHD/9xNDhFAr77+9nz709GCuMmVp3KmbGsiO+lA88nzQFfAHNp4Hskyfp4LXrI588ecL169dRKBSULl0aV1fXnIxLkl5L9M8/A2DX9n1MnJwMHE3BF5say9QTUwHoVaEX5Z3LGzgiSdLBye//S5rqjYCmk2TSJOlM7zrJxMREevfujaenJw0aNKB+/fp4eXnRp08fkpKSciNGSdJJ+qNHxAcFAeDUrbuBoykcZp2aRVRKFMXti9O/cn9DhyNJr/b3D7B7tPr/9YbLpEnSm96J04gRIzh8+DA7duwgJiaGmJgYtm3bxuHDhxk5cmRuxChJOolesxZUKqzrBGBRprShwynw/nr4F9tvb0eBgil1p8jZwaW879QK2DVK/f+6Q6Hp1zJpkvSmd1Pd5s2b+e2332jUqJFmW+vWrbG0tKRz584sXbo0J+OTJJ2oEhOJ2bQJAMfusrYpt8WnxTMleAqgHkVX2bWygSOSpJdIiobDs+Dkv99PdQbDu4EyaZJei941TklJSbi7u2fa7ubm9lpNdUuWLMHPzw8LCwuqV6/OkSNHXlo+NTWV8ePH4+Pjg7m5OSVKlGDlypVaZTZv3oy/vz/m5ub4+/uzdetWveOS8peYrb+jio/HzNcXmwYNDB1OgSaEYMbJGYQnhVPMthhfVP3C0CFJUtbSk+HoXJhf5b+kKeALaDZVJk3Sa9M7cQoICODrr78mJSVFsy05OZnAwEACAgL0OteGDRsYNmwY48eP5+zZs9SvX59WrVoREhKS7TGdO3dm//79rFixguvXr7Nu3TrKli2r2R8cHEyXLl3o1q0b58+fp1u3bnTu3JmTJ0/qe6tSPiFUKqJ/UXcKd+zeDYUcTpyrVl5ayY47OzBWGDOl7hQsTeQEo1Ieo1LBubWwsDrsmwypseBeET7dAi2+kUmT9EYUQs8pwC9dukTLli1JSUmhcuXKKBQKzp07h4WFBX/++Sfly+s+qqZWrVpUq1ZNq3mvXLlytG/fnhkzZmQqv2fPHj766CPu3LmDUzYjprp06UJcXBy7d+/WbGvZsiWOjo6sW7dOp7ji4uKwt7cnNjYWOzs5e2xeF3/gIA8HDsTIzo5SBw9gZG1t6JAKrH339zH80HAAxtcaz0dl5Vp0Uh5z/zjsGQOh59XP7YpA04lQsbOco0nKlj7f+3q/iipUqMDNmzeZMWMGVapUoVKlSnz77bfcvHlTr6QpLS2Nf/75h+bNm2ttb968OcePH8/ymO3bt1OjRg1mzZqFt7c3pUuXZtSoUSQnJ2vKBAcHZzpnixYtsj0nqJv/4uLitB5S/hG9ejUADp0+lElTLrocdZmxR8YC0LVsV5k0SXnL03uwsQf81EqdNJnZwruTYfBpqPyRTJqkHPNa8zhZWlrSr1+/N7pwZGQkSqUyU38pd3d3wsLCsjzmzp07HD16FAsLC7Zu3UpkZCQDBw4kOjpa088pLCxMr3MCzJgxg8DAwDe6H8kwUq5dI+nkSTA2xukTOeFlbglPDGfI/iGkKFOo612X0TVHGzokSVJTZsCR7+DIHFCmgsIIqnWHxhPARs4vKOU8nRKn7du306pVK0xNTdm+fftLy7Zt21avAF5cPV0Ike2K6iqVCoVCwZo1a7C3twdgzpw5fPjhhyxevBjLfxdz1eecAGPHjmXEiBGa53FxcRQtWlSv+5AMI/qnVQDYNm+GqZeXYYMpoJLSkxh8YDARyRGUdCjJ7AazMTGSa3lJeUDMA9jSD0KC1c9960PLGeBR0bBxSQWaTp9+7du3JywsDDc3N9q3b59tOYVCgVKp1OnCLi4uGBsbZ6oJioiIyHLUHoCnpyfe3t6apAnUfaKEEDx8+JBSpUrh4eGh1zkBzM3NMTeXc9DkN+nhEcTu2gWAc69eBo6mYIpLi2PQvkFcjb6Kk4UTC5ssxNbM1tBhSRJc3QnbBkFKjLpZ7r25UPFD2fFbynU6NfqqVCrc3Nw0/8/uoWvSBGBmZkb16tXZu3ev1va9e/dSp06dLI+pW7cujx8/JiEhQbPtxo0bGBkZUaRIEUA96u/FcwYFBWV7Tin/evrrr5CejmX16lhWqmTocAqc6JRo+v7Zl3NPzmFrZsuiJosoYlvE0GFJhV16Cuz6EjZ8ok6avKpC/7+gUieZNElvhd695X7++WdSU1MzbU9LS+Pnf9cJ09WIESP48ccfWblyJVevXmX48OGEhITQv7966YaxY8fS/bnJDLt27YqzszO9evXiypUr/PXXX4wePZrevXtrmumGDh1KUFAQM2fO5Nq1a8ycOZN9+/YxbNgwfW9VysNUiYk83bABAOdePQ0bTAEUnhhOrz29NDVNP7X4iYqusvlDMrDwy/BDE/h7ufp5wBfQOwicihs2LqlQ0Ttx6tWrF7GxsZm2x8fH00vP5pIuXbowb948pkyZQpUqVfjrr7/YtWsXPj4+AISGhmrN6WRjY8PevXuJiYmhRo0afPLJJ7z//vssWLBAU6ZOnTqsX7+en376iUqVKrFq1So2bNhArVq19L1VKQ+L2bIVVVwcpj7FsGnc2NDhFCgP4x/SY08P7sTewd3KnVUtV1HGqYyhw5IKM5UKghfD940g4jJYuUDXTeo5mUzMDB2dVMjoPY+TkZER4eHhuLpqj1Y4f/48jRs3Jjo6OkcDNAQ5j1PeJpRKbrdsRfqDB7hPmohT166GDqnAeBD/gJ57ehKRFEFR26L80PwHvG28DR2WVJjFPoLfB8Ddw+rnpVtC24Vg42bYuKQCRZ/vfZ2HxlStWhWFQoFCoaBp06aYmPx3qFKp5O7du7Rs2fL1o5YkHcXv20/6gwcY29vj0KGDocMpMMISw+gX1I+IpAhK2Jfgh+Y/4Golh3NLBiIEnFsDf45X92UysYSW06F6L9mXSTIonROnZ6Ppzp07R4sWLbCxsdHsMzMzw9fXl44dO+Z4gJL0ouiffgLA4eOPMLKUy33khMjkSPoG9eVRwiN87Hz4scWPuFi6GDosqbCKug07h8Hdv9TPvarCBz+ASymDhiVJoEfi9PXXXwPg6+tLly5dsLCwyLWgJCk7SWfPknzuHApTUznhZQ6JSYmhX1A/7sfdx8vaix+by6RJMhBlOgQvgkPfQkaKupap8VioPQiM5dxhUt6g9yuxR48euRGHJOnk2YSXdu+/j4mrbEZ6U/Fp8Xy+73NuxdzCzdKNH5v/iIe1h6HDkgoblQqu7YCD0+HJNfW24o3UczPJEXNSHqN34qRUKpk7dy4bN24kJCSEtLQ0rf0FoXO4lDcl/fMP8f/O0eXUUybwbyopPYlB+wdxJeoKThZO/NDiB4rayRnzpbdICLi+W50whV9Ub7N0hBbTofLHsi+TlCfpPR1BYGAgc+bMoXPnzsTGxjJixAg++OADjIyMmDx5ci6EKEmgSk4mdNx4EAL7Dz7AonRpQ4eUr6Up0xh2cBhnI85ia2bL982+p7i9/MteeovuHYMfGsP6j9VJk5ktNPwKhpyDKl1l0iTlWXrXOK1Zs4YffviBNm3aEBgYyMcff0yJEiWoVKkSJ06cYMiQIbkRp1TIPVmwkLT79zFxc8N9zFeGDidfy1BlMPrwaIJDg7E0sWTpu0vlPE3S25MUDXsnwtlf1c9NraHW51BnMFg5GTY2SdKB3olTWFgYFSuqZxC2sbHRTIb53nvvMXHixJyNTpKA5HPniF69GgCPKYEYy7m1XptKqJh0bBIHHhzAzMiMhU0WUtm1sqHDkgoDIeDCRvhzHCRFqrdV7wlNJoK1HIwg5R96N9UVKVKE0NBQAEqWLElQUBAAp06dkgvlSjlOlZrK43HjQaXCvl1bbBs1MnRI+ZYQguknp7Pjzg5MFCb8r9H/qOUpZ9SX3oKn9+CX9rD1M3XS5FpOvVTK+/Nl0iTlO3rXOHXo0IH9+/dTq1Ythg4dyscff8yKFSsICQlh+PDhuRGjVIhFLlpE2p07GLu64D52rKHDybdUQsWMkzPYcH0DChR8U+8bGhVtZOiwpIJOpYLTK2Dv15CeCCYW0GA01Bkil0qR8i29l1x50YkTJzh+/DglS5akbdu2ORWXQcklV94uoVSS9M8/JP71F6q0NIzMzFCYmSOEiqjl34NKRZHFi7Bt2tTQoeZL6cp0xh8bz+67u1Gg4OuAr+lYWk5WK+Wy6LuwfTDcO6J+7lNXvVSKcwnDxiVJWciVJVeyU7t2bWrXrv2mp5EKGSEEKefPE7trF/F7/iQjIiLbsnZt2sik6TUlpScx4vAIjj06honChOn1p9PKr5Whw5IKMpUSTv0I+yZDehKYWsG7k6FmPzDSu3eIJOU5OiVO27dv1/mEBaXWSco9GU+eEPL556ReuarZZmRnh22TJpi4uiLS0hDpaeraJ0srXL8YZMBo86/Y1FgG7R/E+SfnsTSxZE6jOdTzrmfosKSC7PFZ2DEMQs+pn/vUg3YL5SSWUoGiU+L0bJ26ZxQKBS+28Cn+nXNDqVTmTGRSgZQRGcn9Hj1Ju3MHhZUVtk2bYte6FTZ166Iwk30ecsqD+AcMOTCEWzG3sDOzY3HTxVRxq2LosKSCKiUWDkxT1zQJFZjbQdNJUKOPrGWSChydXtEqlUrzCAoKokqVKuzevZuYmBhiY2PZvXs31apVY8+ePbkdr5SPZURFcb+nOmky8fCg+O9b8Z49C9vGjWXSlIOOPTrGRzs/0iyjsqrlKpk0SbnnynZY9A78/b06aarYCb44De/IpjmpYNK7j9OwYcNYtmwZ9er9V+XfokULrKys+Oyzz7h69epLjpYKq4zoaEJ69iLt1m1M3NzwWb0Ks2LFDB1WgSKEYMWlFSw4swCBoJJLJeY0moO7tbuhQ5MKoqRo2P0lXNykfu5UAtr8D0o0NmxckpTL9E6cbt++jb29fabt9vb23Lt3LydikgqYjKdPCenVm9SbNzFxdcXn59WY+fgYOqwCJSk9iQnHJrD3vnotv46lOjKu1jjMjGVNnpQLbgSpR8wlhIHCCOoOUy+XYmph6MgkKdfpnTjVrFmTYcOG8euvv+Lp6QmoZxMfOXIk77zzTo4HKOVvQggejxxJ6vXrGLu6UGz1asx8fQ0dVoFyJ/YOIw6O4HbsbUyMTBhXaxydSncydFhSQZQYCfu+/m+5FOdS0GEZFKlh2Lgk6S3SO3FauXIlHTp0wMfHh2L/NrWEhIRQunRpfv/995yOT8rn4vftI/F4MAozM3xWrsS8uJ+hQypQgu4FMfHYRJIyknC1dGVOozmyP5OU81Ji4fgiOLEE0hIABQQMgiYTwNTS0NFJ0luld+JUsmRJLly4wN69e7l27RpCCPz9/Xn33Xc1I+skCdTLpUTMnAWAU5/emJcqZeCICo50VTrz/pnHz1d+BqCmR01mNZiFi6VcvkLKQenJ6k7fR+dC8lP1Ns8q0HIG+NQxaGiSZCivNQGmQqGgefPmNG/ePKfjkQqQ6FWrSX/4EBN3d1z69TN0OAXGvdh7fH38a85EnAGgV4VeDKk6BBOjN57PVpLU0pLgn5/g2HxICFdvcymtrmEq1xbkH8lSIabTJ+2CBQv47LPPsLCwYMGCBS8tO2TIkBwJTMrf0sPDiVy+HAC3USMxsrIycET5353YO3x/4Xt2392NSqiwMbVhWt1pNPWRs6pLOSQ1Hk6tgOML1YvxAtgXhUZjoVIXMJbJuSTptFadn58fp0+fxtnZGT+/7PuoKBQK7ty5k6MBGoJcq+7NPf7qK2K3bceyShV81q2Vzbhv4E7sHZafX87uu7sRqN+ujYo0YlTNUfjYydGJ0hsSAsIuqqcVOPvLf01yDj5QfwRU7ioX5JUKvBxfq+7u3btZ/l+SspJ87hyx29TL9LiPHy+TpteUocpgxcUVLDu/jAyRAUCjoo3oX7k/5Z3LGzg6Kd+LvgMXN6sTpsjr/213KgENRqknsjQ2NVx8kpRHyXpXKUcJlYqwb6YDYP/BB1hWrGDgiPKnB3EPGHt0LOefnAegQZEGDKoyCH9nfwNHJuVrQsCdgxC8GG7t+2+7sTmUaQkVO0OZVmBkbLgYJSmP0ylxGjFihM4nnDNnzmsHI+V/cX/8QcrFixhZWeE2fJihw8l3hBBsvbWVmX/PJCkjCRtTG8bVGsd7xd+TNXfS60tPgYsb4cRSiLjy70YFFG8ElTpD2TZgkXliY0mSMtMpcTp79qxOJ5Mf7IWbUCqJXLwEAOfP+mHi6mrgiPKXVGUqE45OYM899ZqP1d2rM73edLxsvAwcmZRvPevsHbwYEiPU28xsoOqnUOtzcCpu2PgkKR/SKXE6ePBgbschFQBxu3aRdu8exvb2OH7azdDh5CuxqbEMPjCYsxFnMTEyYUjVIXT3746xbDKRXkdSNJxcDieXQUqMeptdEajdH6p2A0sHQ0YnSfma7OMk5QihVBK5ZCkATr16YWxjbeCI8o9HCY8YsG8Ad2PvYmtqy/wm86npUdPQYUn5UUIEBC9S1zKlJai3OZdSj46Tnb0lKUe8VuJ06tQpNm3aREhICGlpaVr7tmzZkiOBSflL3O49pN29i5G9PY6ffmLocPKNq1FXGbh/IJHJkXhYe7C06VJKOpY0dFhSfhP3GI4tgH9WQUayept7RWgwUj1hpay5lKQcY6TvAevXr6du3bpcuXKFrVu3kp6ezpUrVzhw4AD29rJzYWEklEoil6prm5x79sDYxsbAEeUPRx4eoeeenkQmR1LasTS/tvpVJk2SfqLvws7hML8ynFyqTpq8q8PHG6D/ESjfQSZNkpTD9K5xmj59OnPnzmXQoEHY2toyf/58/Pz8+Pzzz/H09MyNGKU8Lv7PP0m7fRsjOzscP/3U0OHkeUII1lxdw+zTs1EJFbU8azG30VxszWwNHZqUXzz6R13DdHU7CJV6W7E60HA0FG8sl0SRpFykd+J0+/Zt2rRpA4C5uTmJiYkoFAqGDx9OkyZNCAwMzPEgpbxLqFQ8WaIeSefUozvGtvLL/2XSVenMODmDTTc2AdChZAcm1p6Iqex7Ir2KMgNuBqn7MN0/9t/2ku9CveHgW89wsUlSIaJ34uTk5ER8fDwA3t7eXLp0iYoVKxITE0NSUlKOByjlbfF//knardsY2dri1E2OpHuZ2NRYRh4eycnQkyhQMKL6CHqU7yGn8ZBeLvIWnPsVzq2DhDD1NiMTdWfvOoPBXc4iL0lvk959nOrXr8/evXsB6Ny5M0OHDqVfv358/PHHNG2q/2KjS5Yswc/PDwsLC6pXr86RI0eyLXvo0CEUCkWmx7Vr1zRlVq1alWWZlJQUvWOTXk6oVP+NpOveHWO5rl+2bj69yae7PuVk6EksTSyZ33g+PSv0lEmTlLWkaPhnNaxsBYuqw9G56qTJyhnqDIGhF6DDMpk0SZIB6FzjdO7/7d15fFTlvfjxz+xL9n0BkgAiS8JmQGUpFVAE3LVCXenVavEqQqlWrPhzq2J7e621VVq8ihdBoVzUouICyiKiYpEga0ABE7IQsk622Z/fHyeZJIZlAkkmhO/79TqvM3POmZNnngmZL8/yfXJyGDZsGH/7298CQcjDDz+MyWRi8+bNXH/99Tz66KNt+uErVqxgzpw5vPTSS4wZM4Z//OMfTJkyhT179pCWlnbC1+Xm5rZYhC/hR4kWIyMjyc3NbXHMarW2qWzi1Bzvv4/rwAH04eHE3i6tTcejlOKd797hma+ewelzkhyWzN8m/I3+sf1DXTTR1dRXwr73YfdbcHAD+LX1CdHpte644bfC+VNkwV0hQkynlFLBXKjX6xk+fDi//OUvufnmm9tlBt1FF13EBRdcwMKGGVkAAwcO5Nprr2XBggWtrt+wYQPjx4+noqKC6Ojo497ztddeY86cOVRWVp52udqySvK5SrndfD/1CjxHjpAwZw7xM38V6iJ1OXWeOn7/5e959+C7AIxJHcMzP3mGWGtsiEsmuoTaUsj7EvK+gPyvoHB7U7AEWjqBrOtgyM8hqkfoyinEOaAt3/tBtzh9/vnnvPrqq8ybN4/f/OY3XH/99dx5552MHz/+tArpdrvZtm0b8+bNa3F80qRJbNmy5aSvHT58OE6nk0GDBjF//vxWZaipqSE9PR2fz8ewYcN46qmnGD58+Anv53K5cLlcgecOh+M03tG5pWLFP/EcOYIhIV5am45jf8V+Htj4AIeqDqHX6Zk1fBZ3ZN2BXtfm3nHRHfj9UJqrBUj5W7V92Xetr0scpKUQyLwO4vt1fjmFEKcUdOA0atQoRo0axQsvvMA///lPFi9ezKWXXkpGRgZ33HEHM2bMoGfPnkH/4NLSUnw+H0lJSS2OJyUlUVxcfNzXpKSksGjRIrKzs3G5XLz++utMnDiRDRs2MG7cOAAGDBjAa6+9xuDBg3E4HPzlL39hzJgx7Nixg379jv+HaMGCBTIbsA18NbWBvE0J996L3m4PcYm6Dp/fx5I9S/jr9r/i8XtItCfyx3F/JDspO9RFE52tthT2fwS5a+DwZ+Csan1NwkBIuxjSRkHaRRCT0enFFEK0TdBddcfz/fffs3jxYpYsWUJRURGXXXYZa9asCeq1hYWF9OjRgy1btjBq1KjA8aeffprXX3+9xYDvk7nqqqvQ6XSsXr36uOf9fj8XXHAB48aN44UXXjjuNcdrcerVq5d01Z3Asb+9SOnf/oY5PZ0+772LziRT6QHyHHnM/3w+20u0RbHH9RzHU2Oekq65c0lVAexcCbkfaK1KNPvzarJrySl7XaRtPUeAXX43hOgKOqSr7nj69u3LvHnz6NWrF7/73e/46KOPgn5tfHw8BoOhVetSSUlJq1aok7n44otZunTpCc/r9XpGjhzJgQMHTniNxWLBYrEE/TPPZd6yMspffRWAhDmzJWhCGwD+z9x/8t/b/pt6bz12o52HLnyI6867TmbNnQt8Htj/IXyzBL5b15SQEiB5CPSfCv0mQcoQWStOiG7gtAOnjRs38uqrr7Jq1SoMBgPTpk3jzjvvDPr1ZrOZ7Oxs1q5dy3XXXRc4vnbtWq655pqg77N9+/aTZixXSpGTk8PgwYODvqc4sdKFf8dfV4c1K4uIyy8PdXFCblfpLv6w9Q/kHMsBYGTySJ4a8xQ9wmUwb7dXcVhbG277MqgtaTqePkYbo9R/CkQFP3xBCHF2aFPglJ+fz2uvvcZrr73GoUOHGD16NH/961+ZNm0aYWFhbf7hc+fO5bbbbmPEiBGMGjWKRYsWkZeXx8yZMwEt3UFBQQFLliwB4PnnnycjI4PMzEzcbjdLly5l1apVrFq1KnDPJ554gosvvph+/frhcDh44YUXyMnJ4cUXX2xz+URL7vx8KlasACDxN3PR6c/dgc5Ha4/ywvYXWP291kVsM9q4f/j93DzwZhkA3p35fVr27q9f0VqXGrviwhJg2M0w/HaIl/UGhejOgg6cLrvsMtavX09CQgK33347d9xxB/37n1kumunTp1NWVsaTTz5JUVERWVlZrFmzhvT0dACKiorIy8sLXO92u3nggQcoKCjAZrORmZnJ+++/z9SpUwPXVFZWcvfdd1NcXExUVBTDhw9n06ZNXHjhhWdU1nOd8vs5+uwfwOMhbPRowpqNSzuXVDoreTP3TRbvWkx9wyr0V/e9mvuH309SWPBdzOIsU10M21/XklJW5Tcd7zsBsv9Da12SbjghzglBDw6/+uqrufPOO7nyyisxGLr3atuSx6m1o3/8L21sk8lE7xXLsQ4aFOoidaq9ZXt5c9+brDm0BpdPm0gwNGEoD418iMEJ0g3cLfn9cPBT+PdibbC38mnHbTFaMsrs/4C4vqEtoxDnAKUUpTVuCivrcXn9XNi7/SdVdMjg8BPNWhPdX/mS1wMDwlOfefqcCZoqnBVsPLKRVftXBcYwAQyIHcAdWXcwOWOyDP7ujirzYcebsH0pVP7QdLzXxTDiP2DQtWCSlQiEaC8en5/CynqOVNRTUFlPQcO+sHGrcuL2apMu+iSE8elvLglpec9oVp04+7jz8qhcuRJPQQFho0cTPmECxtgTR++Ojz7maEMW94S5c4m66qrOKmpI5Ffnsz5vPevz1/NNyTf4G2ZIGXVGLku/jJsH3szQhKESMHU3nnrY+y7kLIODGwmMXbJGwdCbIPsXkDgwlCUU4qzm9PjIK6/jh7I6fiirJa+8jsMNj49U1OPzn7zzS6eDpAgryZGh/0+LBE7nAOX1UrNxIxVvLqd28+bAcceaD0D/GPYRI4i47DLsI7IxpaSgj4pCp9NRt20bhQ8+CEoRc/NNxN31yxC+i47hcDv4uvhrviz8ki+LvuSw43CL8/1j+nNp+qXc0O8GEuwJx7+JODv5fXBok5Z3ae+74Gq2YkDGT7TuuIFXg1kSvApxKi6vj8JKJ0cq6rSWo4r6wOP8ijqOOlwnfb3VpKdHtI0eMXZ6RFvpEW0jNdoW2CdHWTEZusbEGwmcurn6HTs48utf4y0s0g7odISNHYs1K5OajRtx7dlL3dat1G3dGniNzm7HlJyMt6QE5XYTPnEiSY880uVbWZRSuHwu6rx1OL1OXD4XHr8Hj8+D2++m0llJYW0hRTVFFNYWcqT6CLkVuYFWJQCDzkB2Ujbje41nfNp4SSvQ3SgFBd/Arv+DXaug5mjTuag0bWbcsJskg7cQzSilqHF5OepwUlDppLChO62wUguKjlTUU+xwcqoR0xFWI+lxdtJjw0iPs5MR17CPDyMxwtLlv2ManVHm8O6quwwO9zkcHLzmWrxFRRiio4m64Xpipk/HnJYWuMZ95AjVa9dR88knuA4exFde3uIetqFDSXttMXqbrbOL30Kdp4595fvYXbabI9VHqHBVUOGsoNJVSYWzglpPLXXeuhZBULAyIjMYlTqKi1MuZmTySCLMER3wDkTI+P1wZCvsWQ17/gWOI03nbDFazqXBN2pjmM7hFBvi3OP0+ChxuCipdlJa4+JYjZvSahelNdp2rNrFsYa903Pqv602k4GeMbaGzU6PZo/TY+1E201dNjhqy/e+BE7H0V0Cp4IHHsTx3nuY0tLo/dYqDOHhp3yN3+nEW1yMp6gIX0UFYePGBfW69lTvrSe3PJc9ZXvYXbabPWV7OFh1sE1BkcVgwaw3YzKYMBvMmPQmIswRpIalkhKeEthnxmWSHJbcge9GhIS7VhurdOAjbb246qKmc+ZwOH+yFiz1nQBGc+jKKUQ7q3f7GoIgF6XVLspq3ZTVuCitcVNa46Ksxs2xGhdHHU6qnd423TvCYqRHTFP3WUq0lV4xdnrG2OgVaycuzNxlA6NT6bQlV0TXVfXuezjeew8MBnr88Q9BBz96qxVzRgbmjIyOLeCP7Di2g7cPvM23pd9ysPIgvsap380k2hPJisuid1RvYq2xxFhjiLZEE2ONIdwUjt1kx260YzPaMOi7d8oM8SNKQdl38P16LVg69Bn4mo2psERquZYGXaMFS6bQtqAKESylFBV1HoqrnIFWoMZ9ea2b8jq3tq91U1Hrptbd+m/nyViMehIjLSSEW4gPtxAf0bAPN5MYYSEhwkJCuJX4CDN2s4QMIIFTt+QpLKT4yScBiL/nHmzDhoW2QCfg8Xn4+IePWbZ3GTtLd7Y4F2eNIzM+k0Fxg8iMyyQzLlMGZ4uWqo9qg7sPbtC25l1woI1ZOn8S9Lsc+vwUjLIepeg6lFJUu7xaINSsS+xYtYuSahdFVfUUVToprKoPqpusObNR3xAImYlr2MeHW1o8Toq0kBBhJdJqPGtbiUJFAqduRvl8FD40D391NbahQ4mf+atQF6mVWk8tb+57kzf3vklJvbbGl0lvYmrvqUxIm0BmXCaJ9kT5xyxaqiqAHz6Hw5vhhy1Q9qOFuw1mSLsY+k6E8y+HhAHaHGYhOlm920dhQ+BT7HBytMXW1GLk8gYfEMWGaS1Aja1BCRFaIBQbZibWbiY2XNvHhZsJt0gw1JEkcOpmyhcvpu7rr9HZ7aT+1x/RGbvOR1zvrWf5vuUs3rWYClcFAPG2eKb1n8aN599IvC0+xCUUXYLfr7UeFe+Eoh1QmKPta4p/dKEOkrOgz3jocwmkjZLUAaLD+fyK0hqXNrOsIUGjlrDR2ZCssZ7KOk/Q94uwGIlv7BKL0LrMEiIsJEdaSY22kRptJSnSitUkww+6iq7zrSrOmDM3l5K/vABA8iO/azF7LpScXicr96/klZ2vUOYsAyA9Mp27Bt/FlN5TMBtkcG7I+X3a1HxHITgKwOvWBk0bLFoXl9EC5jBtYLU5HCzhYLK3vUVHKXDXQG1pw3YMaku0bN1lB6Dse21rWAewBZ0eUoZC+hjIGKu1Ltli2uf9C4E2y0zrKnNSVOWkuGErcjQ9Pupw4j1FskaAcIuRlCgryVFa4JMcaSUp0kJipLVFgCQB0dlHAqduQnk8FD78MHg8hE+cSNT114e6SNR761mZu5LFuxdTWl8KQI/wHswcOpMr+1yJUS+/fp1OKW2R2sIcKNwORTlwLFdbxPY4A/JPTgdGq7b8iNGm7fVG7ThoQZVS4HWCpw7cddqeICby6o2QMFALlBq35CwteBPiFHx+Ra3bi6Peg6Pei8Pp0R47vVTWuamoc1NZ56GyzkNZbdPYIkeQs8z0OkiKbJakMaYxWWNjK5GNSKss+txdyTdXN1H68su49uzFEBVFyuOPhbR/u9ZTy/J9y1myZwnlTi0vVEpYCncPuZtrzrsGk17+oHQopbSWnMp8qDgE5QebttIDUF9+/NfpDBCZChEp2qwznxu8robNqU3xd9dqLUYobfPWN7QOVbStjEYbhCdAWMMWkQLx/SDuPG2LTgeD/Hk619S7fVTWa0FNVb0W2DjqPVS7vNQ4vdS4PNS4fNS6vNS5fTg9Puo9Purd2r7a6aXW5aXe09b/BDQxG/UkRVpIibSRFGUlpaHFKCWqcbMRH27G2EWyWIvOJ3+ZugFnbi6lC/8OQNKjj2JMCM3ss1pPLW/sfYP/3fO/VLmqAOgZ3pNfDv4lV/e9GpNBAqZ24/dpC9CWfqdNwy87oAVGVUe0zes88Wv1Rm3dtdThkDIMkgdDVC8IT4Rg0jj4/Q0tSLVa0ORxNu39jf9jb2hVUkoLwkx2bfyRKayhyy9MBm6fA+rcXkqrtbxBjTmEymu1nEKNU+jLa91U1mnT6ts6e+xUzAY9kTYTkTYjkVYTkTYTMXYT0TYT0XYzMXYTMWHaQOvECK0LTWaZiVORwOks16KL7tKJRF4xtdPL0DhL7rXdrwUCpozIDO4achdTe0+VLrkz5XFCyW5tgHTjdnRPyzxFreggIllruYnrC7F9tC2uL8T317rVTpder41xsnRuYlTRdfj9itJaF8VVTgornRRX1VPkcHK0SptFVlzlpKTaRV0bcwoBGPU6omwmouwmbW8zEWE1EW4xEmE1Em4xEmYxYjcbsJkMWE0GbA2Pwy2N5w2EWYwyfkh0CPlGO8u16KJ7rHO76GrcNSzPXd4qYPrV0F8xJWOKJKE8Xa5qyP9Km3L/wxYo2KZ1m/2Y0QqxfRuCoX5aYBSdprUeRfaQjNjitPn8iqKqevLKtXXIGhdtLaiso6CynqNVLty+4FqHLEZ9YOp8QriZuDALseFm4sK0qfMxdm2LDTMTbTfJVHrR5UngdBZr0UU3f36nddFVu6t5Y+8bLNmzBIdbW1FeAqYz4HFqgdKhjVoix8Lt8OPlZWyxkDqsYaD0MEgZAtEZsraaOG01Li95ZXXkldeRV17bsK8nv7yOIxV1eHwnH8Sv00FihIWUKFtg9lhyZNMssqRIK/GSU0h0QxI4hUJ1sdaNcgZ8VVUUPvBAUxfdlVe0U+FOrMpVxbK9y1i6ZynVnmpAC5juHnI3U3tP7ZSAqdblpahh6YHSZmsxtRxA6qXW7cPj9eP1+/H4FB6fP7Byt07XsKHDqNdhNOgw6vUYDTpMBj1mgx6LSY/FqMdsNGA16gmzGLGZDYSZDdjMRiIsRsKtTV0HEdamcRSn7B7wuqHwGzj8mZbMMe/L1mOSotO1affpo7Utto+MCRJtUuf2UlBRz5GGPEP5FXUcKdf2+eV1VJwi15DJoKNXYKFWbT2yHs1mkCVGWDDJAGlxDpLAqbNtXwbv/wZufA36Tz6tW/jr6sj/1UxcB77DkBB/Zl10Xhcc+Bh2/p+Ww8fn1gb4+tygFCopkx3J/VjpKeGjoi24GsbV9I3qy6+G/opJ6ZPaPWDy+xWHy2rZXehg/9Hqhv8J15FXVkdZ7XG6rLoYi7FhQKrVSLTVQF9TKf11+fTxHaJP/U56VO/E6G8ZKPnCklAZ4zCcNx5dn59CVM8QlV6cDZwen5ZXqCEbdWGlk6Kq+sC+qMpJeRD/VmLsJtLiwkiL1VavT4u1kxan7ZMirRj0EqwL8WMSOHUmpWD/h9oMpBW3wA3/A5nXte0WbjdH7p9NfU4O+shI0v7nlbZ30SmljZvZ8SbsWgX1raeSFxgNfGazsbKymv313wSOD9Db+WXiaC477yr0iUODm4V1CsVVTrYeLmfb4XJ2FTrYW+Q46aDSCIuRhMalByK0MRONYyPCGwePmo2YjHpMeh1Gg9aaZNDptEn0SjXstbEcXp8fT+Pep3D7/Lg8PlxeP26vPzDduc7to86ttWbVurxUOz3a9Od6FwZXOTHuItI4SpoqId1ZQl9XIec78gnTtR7EXaoi2eofwFf+gXzuz+Q7Zw8o02HK0RFp3Uuk7TsircaGAMxEmMWA3WwM7O1mbVCs1aTHajRgaba3GLXjFqMBi1GP1WzAajRgMuiky6QLc3p8gVlmZQ0LtpY2W7/sWI2LEoeLo9XOoDNTR1iN9IhuajFqXMW+V4ydnrGSa0iI06FTSgWRje7c4nA4iIqKoqqqisjIyPa9uc8Db8+EXf+nZUK+5kUYdnNQL1U+H4UPPohjzQfobDbSXn0F+/Dhbfv5R/4NH/xWC5wa7xuRwpFBU/l3WCT/rvmBfzsOUuhqyvVjUTom19YyzeFgsMtNi6/eiFSI7a1lcLZGg61hM4U1TUM3WRumo2szsUrdJj7Pd/H5EQ9f/qC1KP2Y1aRnQHIkA1MiyYizkx5n1/7gx9rb/4+93w8uh7Y5q7RAsq5cy3dUV64db0ze6K7V9s2vqa/kZEkdfXozFWF9Kbb25ZClPztNg9nvS6WyXkvQV9WwBZON+EwY9DqsRn1DwNUUbFlNTceaP7Y0XNt8bzY2dmUamro0DQ3Hj3O+8bnZqO+2rRdKKZweP7VuL3UuH3Uercu4eddxjVNLwljt9AYSMTZ+9pX1bqrqPW2eim8zGRrGE1lIjbKREq3lGEpt2PeIkcBIiGC15XtfAqfj6NDACbQcPO/Ohu2va8+n/gkuvOukL1FKUfz4E1SuWAEmE71eeonwn4wN/mdWF8O6J2DHG7h0sM8WQU7aMLaHR5FTWxBYCqWRQWcgMy6Tyb0nc3Xfq4nSmbQBzPlb4ehObR2xisNtfOOt1SkLlYThMkais0VjCY8hLDKW8KhY9LZosEQ0ZKVu2IxWbfkPnV7LR6Q3aIkbfe6GDNX1TckaGwMhZ8PeXdOUwLExmaOrWrvujOm05JExvSE2A2IytBlvSVna+KRTJHNUSlHn9gWCqKYvWC0BYG1ja5erqdWrsVXM6fHh9Gh7rbXMj8vbcMzro6v8C9frtOSCjePITAY9JqM2rszUbIyZqdmYM71OG4em12sthga9Dp0O9Dodeh3odDotkG9MVo4uMBRMB80etw7a/ErhV6BQgdZHn1/h9fvx+cHXbHycp7E10qvVbWO9uxpaJNurjo16nbZoa8OMs9gwC4kNa5g17hsHXku+ISHajwROZ6jDAyfQWjk+ehi+0mbFcekTMGb2cQcAK5+Po08/Q8Ubb4BOR/iC/8eWATo+zf+UgpoCoixRxFpiibHGEGONIcIcgc1o0zYM6A9+yqH973FArzhgNpNnNvHjjjCj3khWXBYjk0cyImkEwxKHYTedYsFUpwOO7obqInBWaq0w9dre566jrKKSiioHtbXVmP1OwqgnXOckDCf243RfhZzBAtZIbQabPbZhHwOWqIakjY0JHO1a61rgmlitxa0LJvhUSut6dLq1IKre3TzY8uH0+huO+VoEYM5mwVfzvdvrbxGcuX1ad6YWUDR73HD8XGMzGbCbDYEu4+a5hyJtJiKs2gSCCGtTjqLohnxFjePiJBgSovNJ4HSGOiVwAm2QzSdPwubntOd9J8CVz0NMeuASf309Bb95gJpPPwXg/Z+l8b/9Cs/4R8dYYhiaOJRhCcMYnjiczPhMLAbLGd2z1uXlk30lfLCziA25x1osexBjNzHu/AQu6Z/AT/olEG83ai09zYItnJVay5CrWgvKXA7tsae+oSWpYe9za4Gn36utr+b3akFP8zXTTHawRoElUguGrFHNFqcNawqELFHaeUvkmSWFFK0opQItNm6v1mrjDjxu3ZLj8fvx+prGnPmatfw07v2qWUuR0lqKGluMGsetQdOxk2lsuWpsmTLo9Rj1WqtWYytXoGUs0BqmD3RnWowN48nMesLMRmwmA/pu2h0pRHfXlu99GRweSjodXPoY1d/V4t6wnHDHJix5o2Dio3Dh3XgrKsm/5z9xfvstXqOOF67U8WVD0DQ0YSgT0iaQFZeFw+2g3FlOhbOCiorvqS3aTn3FYep1CqdOh8dopVdiFv16T6Jf7Pn0i+lHgi2hXf5n2xgsrfm2iPW5JbiatTL0iLYxKTOJyzOTGZEe03ptJ1uMrG7fjel0OsxGHWajnrAzi8mFEKLLkMAphJTPR8lzz1H+yrtAGCU5YViiPERs/z32Acso2mLEU3gUb7iVJ671cDjDyvwRDzIhbQIJ9mYz6erKtdlxOcu1/ECNeoyA0ffBgKvadcHUyjo36/aW8OGuYjYdONaiSyYjzs7UwSlMHZxCZmqkdDsIIYToViRwChFfVRUFc39D7eefA2AdOgTn7j24qsBVZYJd2mBtFW3koek+8mN1PDryt0zrP027QW0ZHNoAu96C/R+Bv2F6st4I/afAqFmQdlG7lfeHslrW7yth3d4SvjhYhq/ZDLCMODtXDNGCpUEpEiwJIYToviRwCgHXgQPk33sfnrw8dFYrqc88TeTUqfgqK6n+5FMc7/2L2q++xhzj4uFpivxoE5f5LdxY44R1j8P3n0LRt7SYAp88GIbeDINvhPAzX3qlzu3l68MVbMgtYUPuMQ6V1rY4PyA5gslZyUzOSqZ/UoQES0IIIc4JMjj8ODpycLhj7VqKHpqHv64OU2oqPV96EeuAAa2u8zmd/G7TXNYUfUaK18fKgkKifpznJzETzpsIQ6ZDctYZlavO7WXbDxV8ebCMLw+WsyO/skVeIaNex8iMWMYPSGDSoGQy4sPO6OcJIYQQXYUMDu+ilFJUvfU2/ro67BddRI/n/4wx5viDo9898iFrij7DoDPwx0tfIOq7zfDdWkgYqM2+63MJRCSddlmcHh/b8yr54mAZX3xfSk5+ZatFPVOjrIGZcGPOiydCkukJIYQ4x0mL03F0ZIuTr7qaimXLiLvzTnSm4wcieY48fvbuz6j31nP/8Pu5a8jJk2MGK6+sjk/3HeXT3GN8dbCsxQw40AKli/vGcXGfOEb1iaNnjE264IQQQnR70uLUhfnDrKy7JJobDXqOt8qbUorHv3icem89I5NHckfWHaf/s/yK7fmVfLS7mE/3lfBdSU2L8wkRFkb31YKk0X3j6RUrgZIQQghxMhI4dSKlFHPWz2HTkU3kV+fz4MgHW12z6sAqvi7+GpvRxhOjn8DQxkV0/X7FtrwK1uws4sNdxRRVOQPnDHodIzNimDAgkUv6J9IvMVwCJSGEEKINJHDqRDqdjit6X8GmI5tYsmcJvSJ68fMBPw+cP1p7lP/+938DcN+w++gV0Suo+2otSxW8u6OID3YVcdTRtJxJuMXIxIGJXDYoiZ/0SyDKJuOUhBBCiNOlP/UlHeull16id+/eWK1WsrOz+eyzz0547YYNG7RFPX+07du3r8V1q1atYtCgQVgsFgYNGsTbb7/d0W8jaFP7TGXW8FkALNi6gE1HNgFaa9TTXz1NjaeGwfGDuWXgLSe9j1KKnUeqeOq9PYz5w6fcsPALXttymKMOFxEWI9cP78H/3D6Cf8+/lL/8fDhXDkmVoEkIIYQ4QyFtcVqxYgVz5szhpZdeYsyYMfzjH/9gypQp7Nmzh7S0tBO+Ljc3t8XgrYSEprxFX3zxBdOnT+epp57iuuuu4+2332batGls3ryZiy5qv4SQZ+KuwXeR58jjX9//iwc3PsiSKUs47DjM+vz1GHVGHh/9+Am76Cpq3byTU8CKr/PZV1wdOB5uMXLZoCSuHJLC2H7xWIxt6+ITQgghxKmFdFbdRRddxAUXXMDChQsDxwYOHMi1117LggULWl2/YcMGxo8fT0VFBdHR0ce95/Tp03E4HHzwwQeBY5MnTyYmJoY333wzqHJ1xiK/Hp+HmetmsrV4K0n2JDx+D+XOcmYOncm9w+5tdf3OI1X8Y9P3fLz7KG6fNhvObNQzaVASVw9NZdz5CVhNEiwJIYQQbXVWzKpzu91s27aNefPmtTg+adIktmzZctLXDh8+HKfTyaBBg5g/fz7jx48PnPviiy/49a9/3eL6yy+/nOeff/6E93O5XLhcTeOCHA5HG97J6TEZTDx3yXPc9sFtHKo6BECfqD7cNbhl6oE9hQ7+vG4/a/ccDRwblBLJ9JG9uGZYKtF2c4eXVQghhBCakAVOpaWl+Hw+kpJaJnFMSkqiuLj4uK9JSUlh0aJFZGdn43K5eP3115k4cSIbNmxg3LhxABQXF7fpngALFizgiSeeOMN31HZRlihenPgit665FYfbwROjn8Bs0AKh/UereX7dftbs1Mqt18G1w3pwx9jeZPWI6vSyCiGEEKILzKr78XR4pdQJp8j379+f/v37B56PGjWK/Px8/vSnPwUCp7beE+Dhhx9m7ty5gecOh4NevYKb0XamekX04v3r3qfSVUnPiJ4cLq3lz+v2s3pHIUqBTgdXDkll9sR+nJcY3illEkIIIcTxhSxwio+Px2AwtGoJKikpadVidDIXX3wxS5cuDTxPTk5u8z0tFgsWiyXon9news3hVNUZmLfqW1ZuO4KvYY24KVnJzLn0fPonR4SsbEIIIYRoErJ0BGazmezsbNauXdvi+Nq1axk9enTQ99m+fTspKSmB56NGjWp1z48//rhN9+wsLq+P9bklPLhyB+P/awPLv87H51eM75/Ae7PGsvDWbAmahBBCiC4kpF11c+fO5bbbbmPEiBGMGjWKRYsWkZeXx8yZMwGtC62goIAlS5YA8Pzzz5ORkUFmZiZut5ulS5eyatUqVq1aFbjn7NmzGTduHH/4wx+45ppr+Ne//sW6devYvHlzSN7jj9W7fWzcX8KHu4r5ZG8J1S5v4NyoPnE8cPn5ZKfHhrCEQgghhDiRkAZO06dPp6ysjCeffJKioiKysrJYs2YN6enpABQVFZGXlxe43u1288ADD1BQUIDNZiMzM5P333+fqVOnBq4ZPXo0y5cvZ/78+Tz66KP07duXFStWdJkcTr9auo1N+48FnidGWJiclcxVQ1MZmSEBkxBCCNGVhTSPU1fVkXmc/nfLYV7+7CBTspKZnJXM8F4x6PWyXpwQQggRKmdFHqdz1c0XpXH7qHRZXFcIIYQ4C0ng1MlMhpAvDyiEEEKI0yTf4kIIIYQQQZLASQghhBAiSBI4CSGEEEIESQInIYQQQoggSeAkhBBCCBEkCZyEEEIIIYIkgZMQQgghRJAkcBJCCCGECJIETkIIIYQQQZLASQghhBAiSLLkynE0rnvscDhCXBIhhBBCdLTG7/vG7/+TkcDpOKqrqwHo1atXiEsihBBCiM5SXV1NVFTUSa/RqWDCq3OM3++nsLCQiIgIdDrdGd3L4XDQq1cv8vPziYyMbKcSipOROg8NqffQkHrvfFLnodGR9a6Uorq6mtTUVPT6k49ikhan49Dr9fTs2bNd7xkZGSn/wDqZ1HloSL2HhtR755M6D42OqvdTtTQ1ksHhQgghhBBBksBJCCGEECJIEjh1MIvFwmOPPYbFYgl1Uc4ZUuehIfUeGlLvnU/qPDS6Sr3L4HAhhBBCiCBJi5MQQgghRJAkcBJCCCGECJIETkIIIYQQQZLAqQO99NJL9O7dG6vVSnZ2Np999lmoi9StLFiwgJEjRxIREUFiYiLXXnstubm5La5RSvH444+TmpqKzWbjkksuYffu3SEqcfezYMECdDodc+bMCRyTOu8YBQUF3HrrrcTFxWG32xk2bBjbtm0LnJd6b19er5f58+fTu3dvbDYbffr04cknn8Tv9weukTo/c5s2beKqq64iNTUVnU7HO++80+J8MHXscrmYNWsW8fHxhIWFcfXVV3PkyJGOK7QSHWL58uXKZDKpl19+We3Zs0fNnj1bhYWFqR9++CHURes2Lr/8crV48WK1a9culZOTo6644gqVlpamampqAtc8++yzKiIiQq1atUrt3LlTTZ8+XaWkpCiHwxHCkncPW7duVRkZGWrIkCFq9uzZgeNS5+2vvLxcpaenq1/84hfqq6++UocOHVLr1q1T3333XeAaqff29fvf/17FxcWp9957Tx06dEitXLlShYeHq+effz5wjdT5mVuzZo165JFH1KpVqxSg3n777Rbng6njmTNnqh49eqi1a9eqb775Ro0fP14NHTpUeb3eDimzBE4d5MILL1QzZ85scWzAgAFq3rx5ISpR91dSUqIAtXHjRqWUUn6/XyUnJ6tnn302cI3T6VRRUVHq73//e6iK2S1UV1erfv36qbVr16qf/vSngcBJ6rxjPPTQQ2rs2LEnPC/13v6uuOIKdccdd7Q4dv3116tbb71VKSV13hF+HDgFU8eVlZXKZDKp5cuXB64pKChQer1effjhhx1STumq6wBut5tt27YxadKkFscnTZrEli1bQlSq7q+qqgqA2NhYAA4dOkRxcXGLz8FisfDTn/5UPoczdO+993LFFVdw6aWXtjgudd4xVq9ezYgRI7jxxhtJTExk+PDhvPzyy4HzUu/tb+zYsXzyySfs378fgB07drB582amTp0KSJ13hmDqeNu2bXg8nhbXpKamkpWV1WGfg6xV1wFKS0vx+XwkJSW1OJ6UlERxcXGIStW9KaWYO3cuY8eOJSsrCyBQ18f7HH744YdOL2N3sXz5cr755hu+/vrrVuekzjvGwYMHWbhwIXPnzuV3v/sdW7du5f7778disXD77bdLvXeAhx56iKqqKgYMGIDBYMDn8/H0009z0003AfK73hmCqePi4mLMZjMxMTGtrumo71sJnDqQTqdr8Vwp1eqYaB/33Xcf3377LZs3b251Tj6H9pOfn8/s2bP5+OOPsVqtJ7xO6rx9+f1+RowYwTPPPAPA8OHD2b17NwsXLuT2228PXCf13n5WrFjB0qVLeeONN8jMzCQnJ4c5c+aQmprKjBkzAtdJnXe806njjvwcpKuuA8THx2MwGFpFuyUlJa0iZ3HmZs2axerVq1m/fj09e/YMHE9OTgaQz6Edbdu2jZKSErKzszEajRiNRjZu3MgLL7yA0WgM1KvUeftKSUlh0KBBLY4NHDiQvLw8QH7XO8KDDz7IvHnz+PnPf87gwYO57bbb+PWvf82CBQsAqfPOEEwdJycn43a7qaioOOE17U0Cpw5gNpvJzs5m7dq1LY6vXbuW0aNHh6hU3Y9Sivvuu4+33nqLTz/9lN69e7c437t3b5KTk1t8Dm63m40bN8rncJomTpzIzp07ycnJCWwjRozglltuIScnhz59+kidd4AxY8a0SrWxf/9+0tPTAfld7wh1dXXo9S2/Ig0GQyAdgdR5xwumjrOzszGZTC2uKSoqYteuXR33OXTIkHMRSEfwyiuvqD179qg5c+aosLAwdfjw4VAXrdu45557VFRUlNqwYYMqKioKbHV1dYFrnn32WRUVFaXeeusttXPnTnXTTTfJdOF21nxWnVJS5x1h69atymg0qqefflodOHBALVu2TNntdrV06dLANVLv7WvGjBmqR48egXQEb731loqPj1e//e1vA9dInZ+56upqtX37drV9+3YFqOeee05t3749kLonmDqeOXOm6tmzp1q3bp365ptv1IQJEyQdwdnqxRdfVOnp6cpsNqsLLrggME1etA/guNvixYsD1/j9fvXYY4+p5ORkZbFY1Lhx49TOnTtDV+hu6MeBk9R5x3j33XdVVlaWslgsasCAAWrRokUtzku9ty+Hw6Fmz56t0tLSlNVqVX369FGPPPKIcrlcgWukzs/c+vXrj/t3fMaMGUqp4Oq4vr5e3XfffSo2NlbZbDZ15ZVXqry8vA4rs04ppTqmLUsIIYQQonuRMU5CCCGEEEGSwEkIIYQQIkgSOAkhhBBCBEkCJyGEEEKIIEngJIQQQggRJAmchBBCCCGCJIGTEEIIIUSQJHASQgghhAiSBE5CCHGGdDod77zzTqiLIYToBBI4CSHOar/4xS/Q6XSttsmTJ4e6aEKIbsgY6gIIIcSZmjx5MosXL25xzGKxhKg0QojuTFqchBBnPYvFQnJycostJiYG0LrRFi5cyJQpU7DZbPTu3ZuVK1e2eP3OnTuZMGECNpuNuLg47r77bmpqalpc8+qrr5KZmYnFYiElJYX77ruvxfnS0lKuu+467HY7/fr1Y/Xq1R37poUQISGBkxCi23v00Ue54YYb2LFjB7feeis33XQTe/fuBaCuro7JkycTExPD119/zcqVK1m3bl2LwGjhwoXce++93H333ezcuZPVq1dz3nnntfgZTzzxBNOmTePbb79l6tSp3HLLLZSXl3fq+xRCdAIlhBBnsRkzZiiDwaDCwsJabE8++aRSSilAzZw5s8VrLrroInXPPfcopZRatGiRiomJUTU1NYHz77//vtLr9aq4uFgppVRqaqp65JFHTlgGQM2fPz/wvKamRul0OvXBBx+02/sUQnQNMsZJCHHWGz9+PAsXLmxxLDY2NvB41KhRLc6NGjWKnJwcAPbu3cvQoUMJCwsLnB8zZgx+v5/c3Fx0Oh2FhYVMnDjxpGUYMmRI4HFYWBgRERGUlJSc7lsSQnRREjgJIc56YWFhrbrOTkWn0wGglAo8Pt41NpstqPuZTKZWr/X7/W0qkxCi65MxTkKIbu/LL79s9XzAgAEADBo0iJycHGprawPnP//8c/R6Peeffz4RERFkZGTwySefdGqZhRBdk7Q4CSHOei6Xi+Li4hbHjEYj8fHxAKxcuZIRI0YwduxYli1bxtatW3nllVcAuOWWW3jssceYMWMGjz/+OMeOHWPWrFncdtttJCUlAfD4448zc+ZMEhMTmTJlCtXV1Xz++efMmjWrc9+oECLkJHASQpz1PvzwQ1JSUloc69+/P/v27QO0GW/Lly/nP//zP0lOTmbZsmUMGjQIALvdzkcffcTs2bMZOXIkdrudG264geeeey5wrxkzZuB0Ovnzn//MAw88QHx8PD/72c867w0KIboMnVJKhboQQgjRUXQ6HW+//TbXXnttqIsihOgGZIyTEEIIIUSQJHASQgghhAiSjHESQnRrMhpBCNGepMVJCCGEECJIEjgJIYQQQgRJAichhBBCiCBJ4CSEEEIIESQJnIQQQgghgiSBkxBCCCFEkCRwEkIIIYQIkgROQgghhBBBksBJCCGEECJI/x8lJfXhrXbEzAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def lr_sweep_on_tiny(\n",
    "    lrs=(1e-4, 3e-4, 1e-3),\n",
    "    hidden_dim=128,\n",
    "    batch_size=4096,\n",
    "    num_epochs=100,\n",
    "    seed=0,\n",
    "):\n",
    "    \"\"\"\n",
    "    For each learning rate:\n",
    "      - reinitialize the GNN\n",
    "      - train for num_epochs on the tiny train set\n",
    "      - record validation mean AUC after each epoch\n",
    "\n",
    "    Uses global: train_idx, val_idx, edge_index, edge_attr, y_all, train_step, eval_split.\n",
    "    \"\"\"\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    history = {}\n",
    "\n",
    "    for lr in lrs:\n",
    "        print(f\"\\n=== LR sweep: lr = {lr}, batch_size = {batch_size} ===\")\n",
    "        make_gnn_model(hidden_dim=hidden_dim, lr=lr)\n",
    "\n",
    "        epochs = []\n",
    "        val_auc_curve = []\n",
    "        train_auc_curve = []\n",
    "\n",
    "        for epoch in range(1, num_epochs + 1):\n",
    "            # one stochastic update on a random minibatch of train_idx\n",
    "            train_loss_step = train_step(batch_size=batch_size)\n",
    "\n",
    "            # full train / val evaluation (for monitoring)\n",
    "            train_loss_eval, train_auc_heads, train_auc_mean = eval_split(\n",
    "                train_idx, split_name=\"train\"\n",
    "            )\n",
    "            val_loss, val_auc_heads, val_auc_mean = eval_split(\n",
    "                val_idx, split_name=\"val\"\n",
    "            )\n",
    "\n",
    "            epochs.append(epoch)\n",
    "            train_auc_curve.append(float(train_auc_mean))\n",
    "            val_auc_curve.append(float(val_auc_mean))\n",
    "\n",
    "            if epoch == 1 or epoch % 10 == 0:\n",
    "                print(\n",
    "                    f\"Epoch {epoch:3d} | \"\n",
    "                    f\"train_loss(step)={train_loss_step:.4f} | \"\n",
    "                    f\"train_mean_auc={train_auc_mean:.4f} | \"\n",
    "                    f\"val_mean_auc={val_auc_mean:.4f}\"\n",
    "                )\n",
    "\n",
    "        history[lr] = {\n",
    "            \"epochs\": np.array(epochs),\n",
    "            \"train_auc_mean\": np.array(train_auc_curve),\n",
    "            \"val_auc_mean\": np.array(val_auc_curve),\n",
    "        }\n",
    "\n",
    "    return history\n",
    "\n",
    "\n",
    "# run the sweep on tiny data (gnn_data_tiny.pt)\n",
    "lrs = [1e-4, 3e-4, 1e-3, 3e-3]\n",
    "lr_history = lr_sweep_on_tiny(\n",
    "    lrs=lrs,\n",
    "    hidden_dim=128,\n",
    "    batch_size=4096,\n",
    "    num_epochs=100,\n",
    ")\n",
    "\n",
    "# Plot: validation mean AUC vs epoch for each learning rate\n",
    "plt.figure(figsize=(6, 4))\n",
    "for lr in lrs:\n",
    "    h = lr_history[lr]\n",
    "    plt.plot(\n",
    "        h[\"epochs\"],\n",
    "        h[\"val_auc_mean\"],\n",
    "        label=f\"lr = {lr}\",\n",
    "    )\n",
    "\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Validation mean AUC (tiny)\")\n",
    "plt.title(\"Learning rate sweep (GNN, batch_size = 4096, tiny data)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e350543-6624-4e85-bc88-1dab206cfeb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Batch-size sweep: batch_size = 1024, lr = 0.001 ===\n",
      "Epoch   1 | train_loss(step)=0.7116 | train_mean_auc=0.5130 | val_mean_auc=0.5154\n",
      "Epoch  10 | train_loss(step)=0.4749 | train_mean_auc=0.5142 | val_mean_auc=0.5168\n",
      "Epoch  20 | train_loss(step)=0.4589 | train_mean_auc=0.5264 | val_mean_auc=0.5290\n",
      "Epoch  30 | train_loss(step)=0.4673 | train_mean_auc=0.5521 | val_mean_auc=0.5545\n",
      "Epoch  40 | train_loss(step)=0.4615 | train_mean_auc=0.5757 | val_mean_auc=0.5776\n",
      "Epoch  50 | train_loss(step)=0.4424 | train_mean_auc=0.6365 | val_mean_auc=0.6367\n",
      "Epoch  60 | train_loss(step)=0.4277 | train_mean_auc=0.6796 | val_mean_auc=0.6781\n",
      "Epoch  70 | train_loss(step)=0.4101 | train_mean_auc=0.7156 | val_mean_auc=0.7141\n",
      "Epoch  80 | train_loss(step)=0.3962 | train_mean_auc=0.7376 | val_mean_auc=0.7357\n",
      "Epoch  90 | train_loss(step)=0.3964 | train_mean_auc=0.7465 | val_mean_auc=0.7444\n",
      "Epoch 100 | train_loss(step)=0.3880 | train_mean_auc=0.7563 | val_mean_auc=0.7544\n",
      "\n",
      "=== Batch-size sweep: batch_size = 2048, lr = 0.001 ===\n",
      "Epoch   1 | train_loss(step)=0.6590 | train_mean_auc=0.5174 | val_mean_auc=0.5194\n",
      "Epoch  10 | train_loss(step)=0.4631 | train_mean_auc=0.5299 | val_mean_auc=0.5323\n",
      "Epoch  20 | train_loss(step)=0.4651 | train_mean_auc=0.5420 | val_mean_auc=0.5441\n",
      "Epoch  30 | train_loss(step)=0.4547 | train_mean_auc=0.5800 | val_mean_auc=0.5814\n",
      "Epoch  40 | train_loss(step)=0.4356 | train_mean_auc=0.6376 | val_mean_auc=0.6375\n",
      "Epoch  50 | train_loss(step)=0.4074 | train_mean_auc=0.7032 | val_mean_auc=0.7014\n",
      "Epoch  60 | train_loss(step)=0.4089 | train_mean_auc=0.7343 | val_mean_auc=0.7323\n",
      "Epoch  70 | train_loss(step)=0.3954 | train_mean_auc=0.7512 | val_mean_auc=0.7494\n",
      "Epoch  80 | train_loss(step)=0.3942 | train_mean_auc=0.7601 | val_mean_auc=0.7584\n",
      "Epoch  90 | train_loss(step)=0.3820 | train_mean_auc=0.7696 | val_mean_auc=0.7678\n",
      "Epoch 100 | train_loss(step)=0.3780 | train_mean_auc=0.7760 | val_mean_auc=0.7740\n",
      "\n",
      "=== Batch-size sweep: batch_size = 4096, lr = 0.001 ===\n",
      "Epoch   1 | train_loss(step)=0.6913 | train_mean_auc=0.5047 | val_mean_auc=0.5075\n",
      "Epoch  10 | train_loss(step)=0.4617 | train_mean_auc=0.5244 | val_mean_auc=0.5267\n",
      "Epoch  20 | train_loss(step)=0.4599 | train_mean_auc=0.5421 | val_mean_auc=0.5445\n",
      "Epoch  30 | train_loss(step)=0.4454 | train_mean_auc=0.5911 | val_mean_auc=0.5928\n",
      "Epoch  40 | train_loss(step)=0.4212 | train_mean_auc=0.6482 | val_mean_auc=0.6484\n",
      "Epoch  50 | train_loss(step)=0.4232 | train_mean_auc=0.6953 | val_mean_auc=0.6937\n",
      "Epoch  60 | train_loss(step)=0.4059 | train_mean_auc=0.7215 | val_mean_auc=0.7196\n",
      "Epoch  70 | train_loss(step)=0.4005 | train_mean_auc=0.7541 | val_mean_auc=0.7521\n",
      "Epoch  80 | train_loss(step)=0.3860 | train_mean_auc=0.7682 | val_mean_auc=0.7655\n",
      "Epoch  90 | train_loss(step)=0.3871 | train_mean_auc=0.7770 | val_mean_auc=0.7742\n",
      "Epoch 100 | train_loss(step)=0.3765 | train_mean_auc=0.7839 | val_mean_auc=0.7809\n",
      "\n",
      "=== Batch-size sweep: batch_size = 8192, lr = 0.001 ===\n",
      "Epoch   1 | train_loss(step)=0.6564 | train_mean_auc=0.5141 | val_mean_auc=0.5168\n",
      "Epoch  10 | train_loss(step)=0.4553 | train_mean_auc=0.5204 | val_mean_auc=0.5228\n",
      "Epoch  20 | train_loss(step)=0.4568 | train_mean_auc=0.5335 | val_mean_auc=0.5358\n",
      "Epoch  30 | train_loss(step)=0.4534 | train_mean_auc=0.5686 | val_mean_auc=0.5706\n",
      "Epoch  40 | train_loss(step)=0.4370 | train_mean_auc=0.6339 | val_mean_auc=0.6349\n",
      "Epoch  50 | train_loss(step)=0.4232 | train_mean_auc=0.7016 | val_mean_auc=0.7007\n",
      "Epoch  60 | train_loss(step)=0.4018 | train_mean_auc=0.7363 | val_mean_auc=0.7346\n",
      "Epoch  70 | train_loss(step)=0.3982 | train_mean_auc=0.7576 | val_mean_auc=0.7554\n",
      "Epoch  80 | train_loss(step)=0.3838 | train_mean_auc=0.7681 | val_mean_auc=0.7658\n",
      "Epoch  90 | train_loss(step)=0.3801 | train_mean_auc=0.7793 | val_mean_auc=0.7763\n",
      "Epoch 100 | train_loss(step)=0.3809 | train_mean_auc=0.7869 | val_mean_auc=0.7836\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Helper: (re)build GNN + optimizer for each run\n",
    "def make_gnn_model(hidden_dim, lr):\n",
    "    global model, optimizer, criterion\n",
    "\n",
    "    model = GNN(\n",
    "        num_nodes=num_nodes,\n",
    "        num_edge_features=D_edge,\n",
    "        hidden_dim=hidden_dim\n",
    "    ).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "\n",
    "def batchsize_sweep_on_tiny(\n",
    "    batch_sizes=(1024, 2048, 4096, 8192),\n",
    "    hidden_dim=128,\n",
    "    lr=1e-3,\n",
    "    num_epochs=100,\n",
    "    seed=0,\n",
    "):\n",
    "    \"\"\"\n",
    "    For each batch size:\n",
    "      - reinitialize the GNN\n",
    "      - train for num_epochs on the tiny train set\n",
    "      - record validation mean AUC after each epoch.\n",
    "\n",
    "    Assumes global:\n",
    "      train_idx, val_idx, train_step(batch_size), eval_split(idx, split_name).\n",
    "    \"\"\"\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    history = {}\n",
    "\n",
    "    for bs in batch_sizes:\n",
    "        print(f\"\\n=== Batch-size sweep: batch_size = {bs}, lr = {lr} ===\")\n",
    "        make_gnn_model(hidden_dim=hidden_dim, lr=lr)\n",
    "\n",
    "        epochs = []\n",
    "        train_auc_curve = []\n",
    "        val_auc_curve = []\n",
    "\n",
    "        for epoch in range(1, num_epochs + 1):\n",
    "            # one stochastic update on a random minibatch of train_idx\n",
    "            train_loss_step = train_step(batch_size=bs)\n",
    "\n",
    "            # full train / val evaluation (for monitoring)\n",
    "            train_loss_eval, train_auc_heads, train_auc_mean = eval_split(\n",
    "                train_idx, split_name=\"train\"\n",
    "            )\n",
    "            val_loss, val_auc_heads, val_auc_mean = eval_split(\n",
    "                val_idx, split_name=\"val\"\n",
    "            )\n",
    "\n",
    "            epochs.append(epoch)\n",
    "            train_auc_curve.append(float(train_auc_mean))\n",
    "            val_auc_curve.append(float(val_auc_mean))\n",
    "\n",
    "            if epoch == 1 or epoch % 10 == 0:\n",
    "                print(\n",
    "                    f\"Epoch {epoch:3d} | \"\n",
    "                    f\"train_loss(step)={train_loss_step:.4f} | \"\n",
    "                    f\"train_mean_auc={train_auc_mean:.4f} | \"\n",
    "                    f\"val_mean_auc={val_auc_mean:.4f}\"\n",
    "                )\n",
    "\n",
    "        history[bs] = {\n",
    "            \"epochs\": np.array(epochs),\n",
    "            \"train_auc_mean\": np.array(train_auc_curve),\n",
    "            \"val_auc_mean\": np.array(val_auc_curve),\n",
    "        }\n",
    "\n",
    "    return history\n",
    "\n",
    "\n",
    "# run the sweep on tiny data with lr = 1e-3\n",
    "batch_sizes = [1024, 2048, 4096, 8192]\n",
    "bs_history = batchsize_sweep_on_tiny(\n",
    "    batch_sizes=batch_sizes,\n",
    "    hidden_dim=128,\n",
    "    lr=1e-3,\n",
    "    num_epochs=100,\n",
    ")\n",
    "\n",
    "# Plot: validation mean AUC vs epoch for each batch size\n",
    "plt.figure(figsize=(6, 4))\n",
    "for bs in batch_sizes:\n",
    "    h = bs_history[bs]\n",
    "    plt.plot(\n",
    "        h[\"epochs\"],\n",
    "        h[\"val_auc_mean\"],\n",
    "        label=f\"batch = {bs}\",\n",
    "    )\n",
    "\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Validation mean AUC (tiny)\")\n",
    "plt.title(\"Batch-size sweep (GNN, lr = 1e-3, tiny data)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9521dc49-5481-4ad3-8129-093b7f02d272",
   "metadata": {},
   "source": [
    "### 6. Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "becc51ce-ec18-469c-82c6-897f01383f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Selection\n",
    "\n",
    "model = EdgeMLP(num_edge_features=D_edge, hidden_dim=64).to(device)\n",
    "\n",
    "\n",
    "# model = GNN(\n",
    "#     num_nodes=num_nodes,\n",
    "#     num_edge_features=D_edge,\n",
    "#     hidden_dim=128\n",
    "# ).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.BCEWithLogitsLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8173a9ce-b585-46b9-955e-18b29f55fadb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | train_loss(step) = 0.6845 | train_loss(eval) = 0.6735 | train_mean_auc = 0.5192 | val_mean_auc = 0.5184\n",
      "  train AUC per head: h0: 0.5248 | h1: 0.5425 | h2: 0.4954 | h3: 0.5141\n",
      "  val   AUC per head: h0: 0.5255 | h1: 0.5414 | h2: 0.4919 | h3: 0.5150\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.5255', '0.5414', '0.4919', '0.5150']\n",
      "  [EdgeMLP] best mean val AUC = 0.5184\n",
      "Epoch 002 | train_loss(step) = 0.6737 | train_loss(eval) = 0.6629 | train_mean_auc = 0.5228 | val_mean_auc = 0.5235\n",
      "  train AUC per head: h0: 0.5439 | h1: 0.5597 | h2: 0.4852 | h3: 0.5023\n",
      "  val   AUC per head: h0: 0.5443 | h1: 0.5601 | h2: 0.4863 | h3: 0.5032\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.5443', '0.5601', '0.4919', '0.5150']\n",
      "  [EdgeMLP] best mean val AUC = 0.5235\n",
      "Epoch 003 | train_loss(step) = 0.6633 | train_loss(eval) = 0.6525 | train_mean_auc = 0.5243 | val_mean_auc = 0.5262\n",
      "  train AUC per head: h0: 0.5482 | h1: 0.5748 | h2: 0.4790 | h3: 0.4951\n",
      "  val   AUC per head: h0: 0.5491 | h1: 0.5756 | h2: 0.4825 | h3: 0.4974\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.5491', '0.5756', '0.4919', '0.5150']\n",
      "  [EdgeMLP] best mean val AUC = 0.5262\n",
      "Epoch 004 | train_loss(step) = 0.6524 | train_loss(eval) = 0.6419 | train_mean_auc = 0.5241 | val_mean_auc = 0.5266\n",
      "  train AUC per head: h0: 0.5464 | h1: 0.5835 | h2: 0.4764 | h3: 0.4900\n",
      "  val   AUC per head: h0: 0.5476 | h1: 0.5849 | h2: 0.4812 | h3: 0.4928\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.5491', '0.5849', '0.4919', '0.5150']\n",
      "  [EdgeMLP] best mean val AUC = 0.5266\n",
      "Epoch 005 | train_loss(step) = 0.6421 | train_loss(eval) = 0.6308 | train_mean_auc = 0.5240 | val_mean_auc = 0.5266\n",
      "  train AUC per head: h0: 0.5447 | h1: 0.5864 | h2: 0.4777 | h3: 0.4873\n",
      "  val   AUC per head: h0: 0.5460 | h1: 0.5883 | h2: 0.4830 | h3: 0.4891\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.5491', '0.5883', '0.4919', '0.5150']\n",
      "  [EdgeMLP] best mean val AUC = 0.5266\n",
      "Epoch 006 | train_loss(step) = 0.6314 | train_loss(eval) = 0.6189 | train_mean_auc = 0.5240 | val_mean_auc = 0.5263\n",
      "  train AUC per head: h0: 0.5444 | h1: 0.5849 | h2: 0.4814 | h3: 0.4853\n",
      "  val   AUC per head: h0: 0.5458 | h1: 0.5872 | h2: 0.4864 | h3: 0.4860\n",
      "  no improvement this epoch. no_improve_heads = [3, 1, 5, 5]\n",
      "Epoch 007 | train_loss(step) = 0.6197 | train_loss(eval) = 0.6061 | train_mean_auc = 0.5238 | val_mean_auc = 0.5260\n",
      "  train AUC per head: h0: 0.5455 | h1: 0.5805 | h2: 0.4859 | h3: 0.4832\n",
      "  val   AUC per head: h0: 0.5469 | h1: 0.5833 | h2: 0.4908 | h3: 0.4830\n",
      "  no improvement this epoch. no_improve_heads = [4, 2, 6, 6]\n",
      "Epoch 008 | train_loss(step) = 0.6048 | train_loss(eval) = 0.5921 | train_mean_auc = 0.5233 | val_mean_auc = 0.5255\n",
      "  train AUC per head: h0: 0.5472 | h1: 0.5751 | h2: 0.4905 | h3: 0.4805\n",
      "  val   AUC per head: h0: 0.5486 | h1: 0.5782 | h2: 0.4953 | h3: 0.4797\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.5491', '0.5883', '0.4953', '0.5150']\n",
      "  [EdgeMLP] best mean val AUC = 0.5266\n",
      "Epoch 009 | train_loss(step) = 0.5927 | train_loss(eval) = 0.5772 | train_mean_auc = 0.5229 | val_mean_auc = 0.5251\n",
      "  train AUC per head: h0: 0.5494 | h1: 0.5697 | h2: 0.4949 | h3: 0.4777\n",
      "  val   AUC per head: h0: 0.5508 | h1: 0.5730 | h2: 0.4998 | h3: 0.4766\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.5508', '0.5883', '0.4998', '0.5150']\n",
      "  [EdgeMLP] best mean val AUC = 0.5266\n",
      "Epoch 010 | train_loss(step) = 0.5783 | train_loss(eval) = 0.5614 | train_mean_auc = 0.5229 | val_mean_auc = 0.5250\n",
      "  train AUC per head: h0: 0.5522 | h1: 0.5650 | h2: 0.4993 | h3: 0.4749\n",
      "  val   AUC per head: h0: 0.5537 | h1: 0.5683 | h2: 0.5043 | h3: 0.4737\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.5537', '0.5883', '0.5043', '0.5150']\n",
      "  [EdgeMLP] best mean val AUC = 0.5266\n",
      "Epoch 011 | train_loss(step) = 0.5616 | train_loss(eval) = 0.5450 | train_mean_auc = 0.5233 | val_mean_auc = 0.5255\n",
      "  train AUC per head: h0: 0.5555 | h1: 0.5612 | h2: 0.5040 | h3: 0.4725\n",
      "  val   AUC per head: h0: 0.5571 | h1: 0.5645 | h2: 0.5090 | h3: 0.4713\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.5571', '0.5883', '0.5090', '0.5150']\n",
      "  [EdgeMLP] best mean val AUC = 0.5266\n",
      "Epoch 012 | train_loss(step) = 0.5448 | train_loss(eval) = 0.5284 | train_mean_auc = 0.5245 | val_mean_auc = 0.5266\n",
      "  train AUC per head: h0: 0.5591 | h1: 0.5588 | h2: 0.5094 | h3: 0.4708\n",
      "  val   AUC per head: h0: 0.5608 | h1: 0.5620 | h2: 0.5143 | h3: 0.4695\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.5608', '0.5883', '0.5143', '0.5150']\n",
      "  [EdgeMLP] best mean val AUC = 0.5266\n",
      "Epoch 013 | train_loss(step) = 0.5284 | train_loss(eval) = 0.5120 | train_mean_auc = 0.5265 | val_mean_auc = 0.5286\n",
      "  train AUC per head: h0: 0.5630 | h1: 0.5579 | h2: 0.5154 | h3: 0.4698\n",
      "  val   AUC per head: h0: 0.5647 | h1: 0.5609 | h2: 0.5203 | h3: 0.4683\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.5647', '0.5883', '0.5203', '0.5150']\n",
      "  [EdgeMLP] best mean val AUC = 0.5286\n",
      "Epoch 014 | train_loss(step) = 0.5113 | train_loss(eval) = 0.4966 | train_mean_auc = 0.5294 | val_mean_auc = 0.5314\n",
      "  train AUC per head: h0: 0.5671 | h1: 0.5587 | h2: 0.5224 | h3: 0.4693\n",
      "  val   AUC per head: h0: 0.5689 | h1: 0.5616 | h2: 0.5273 | h3: 0.4679\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.5689', '0.5883', '0.5273', '0.5150']\n",
      "  [EdgeMLP] best mean val AUC = 0.5314\n",
      "Epoch 015 | train_loss(step) = 0.4967 | train_loss(eval) = 0.4828 | train_mean_auc = 0.5332 | val_mean_auc = 0.5353\n",
      "  train AUC per head: h0: 0.5719 | h1: 0.5610 | h2: 0.5304 | h3: 0.4695\n",
      "  val   AUC per head: h0: 0.5738 | h1: 0.5639 | h2: 0.5353 | h3: 0.4680\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.5738', '0.5883', '0.5353', '0.5150']\n",
      "  [EdgeMLP] best mean val AUC = 0.5353\n",
      "Epoch 016 | train_loss(step) = 0.4775 | train_loss(eval) = 0.4713 | train_mean_auc = 0.5381 | val_mean_auc = 0.5402\n",
      "  train AUC per head: h0: 0.5772 | h1: 0.5649 | h2: 0.5397 | h3: 0.4704\n",
      "  val   AUC per head: h0: 0.5792 | h1: 0.5678 | h2: 0.5446 | h3: 0.4691\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.5792', '0.5883', '0.5446', '0.5150']\n",
      "  [EdgeMLP] best mean val AUC = 0.5402\n",
      "Epoch 017 | train_loss(step) = 0.4645 | train_loss(eval) = 0.4627 | train_mean_auc = 0.5441 | val_mean_auc = 0.5463\n",
      "  train AUC per head: h0: 0.5835 | h1: 0.5705 | h2: 0.5502 | h3: 0.4723\n",
      "  val   AUC per head: h0: 0.5855 | h1: 0.5734 | h2: 0.5552 | h3: 0.4710\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.5855', '0.5883', '0.5552', '0.5150']\n",
      "  [EdgeMLP] best mean val AUC = 0.5463\n",
      "Epoch 018 | train_loss(step) = 0.4526 | train_loss(eval) = 0.4574 | train_mean_auc = 0.5515 | val_mean_auc = 0.5537\n",
      "  train AUC per head: h0: 0.5908 | h1: 0.5778 | h2: 0.5622 | h3: 0.4750\n",
      "  val   AUC per head: h0: 0.5929 | h1: 0.5808 | h2: 0.5674 | h3: 0.4738\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.5929', '0.5883', '0.5674', '0.5150']\n",
      "  [EdgeMLP] best mean val AUC = 0.5537\n",
      "Epoch 019 | train_loss(step) = 0.4530 | train_loss(eval) = 0.4549 | train_mean_auc = 0.5602 | val_mean_auc = 0.5626\n",
      "  train AUC per head: h0: 0.5993 | h1: 0.5871 | h2: 0.5757 | h3: 0.4787\n",
      "  val   AUC per head: h0: 0.6015 | h1: 0.5902 | h2: 0.5810 | h3: 0.4777\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.6015', '0.5902', '0.5810', '0.5150']\n",
      "  [EdgeMLP] best mean val AUC = 0.5626\n",
      "Epoch 020 | train_loss(step) = 0.4460 | train_loss(eval) = 0.4547 | train_mean_auc = 0.5703 | val_mean_auc = 0.5728\n",
      "  train AUC per head: h0: 0.6089 | h1: 0.5982 | h2: 0.5905 | h3: 0.4836\n",
      "  val   AUC per head: h0: 0.6111 | h1: 0.6014 | h2: 0.5960 | h3: 0.4827\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.6111', '0.6014', '0.5960', '0.5150']\n",
      "  [EdgeMLP] best mean val AUC = 0.5728\n",
      "Epoch 021 | train_loss(step) = 0.4540 | train_loss(eval) = 0.4557 | train_mean_auc = 0.5813 | val_mean_auc = 0.5839\n",
      "  train AUC per head: h0: 0.6190 | h1: 0.6104 | h2: 0.6061 | h3: 0.4897\n",
      "  val   AUC per head: h0: 0.6211 | h1: 0.6136 | h2: 0.6117 | h3: 0.4890\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.6211', '0.6136', '0.6117', '0.5150']\n",
      "  [EdgeMLP] best mean val AUC = 0.5839\n",
      "Epoch 022 | train_loss(step) = 0.4687 | train_loss(eval) = 0.4565 | train_mean_auc = 0.5927 | val_mean_auc = 0.5953\n",
      "  train AUC per head: h0: 0.6291 | h1: 0.6230 | h2: 0.6218 | h3: 0.4969\n",
      "  val   AUC per head: h0: 0.6311 | h1: 0.6261 | h2: 0.6275 | h3: 0.4963\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.6311', '0.6261', '0.6275', '0.5150']\n",
      "  [EdgeMLP] best mean val AUC = 0.5953\n",
      "Epoch 023 | train_loss(step) = 0.4524 | train_loss(eval) = 0.4566 | train_mean_auc = 0.6039 | val_mean_auc = 0.6064\n",
      "  train AUC per head: h0: 0.6392 | h1: 0.6350 | h2: 0.6367 | h3: 0.5045\n",
      "  val   AUC per head: h0: 0.6409 | h1: 0.6382 | h2: 0.6425 | h3: 0.5040\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.6409', '0.6382', '0.6425', '0.5150']\n",
      "  [EdgeMLP] best mean val AUC = 0.6064\n",
      "Epoch 024 | train_loss(step) = 0.4608 | train_loss(eval) = 0.4555 | train_mean_auc = 0.6146 | val_mean_auc = 0.6171\n",
      "  train AUC per head: h0: 0.6493 | h1: 0.6464 | h2: 0.6505 | h3: 0.5123\n",
      "  val   AUC per head: h0: 0.6507 | h1: 0.6494 | h2: 0.6565 | h3: 0.5119\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.6507', '0.6494', '0.6565', '0.5150']\n",
      "  [EdgeMLP] best mean val AUC = 0.6171\n",
      "Epoch 025 | train_loss(step) = 0.4612 | train_loss(eval) = 0.4532 | train_mean_auc = 0.6247 | val_mean_auc = 0.6271\n",
      "  train AUC per head: h0: 0.6589 | h1: 0.6567 | h2: 0.6629 | h3: 0.5202\n",
      "  val   AUC per head: h0: 0.6600 | h1: 0.6596 | h2: 0.6690 | h3: 0.5198\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.6600', '0.6596', '0.6690', '0.5198']\n",
      "  [EdgeMLP] best mean val AUC = 0.6271\n",
      "Epoch 026 | train_loss(step) = 0.4501 | train_loss(eval) = 0.4503 | train_mean_auc = 0.6339 | val_mean_auc = 0.6362\n",
      "  train AUC per head: h0: 0.6683 | h1: 0.6658 | h2: 0.6737 | h3: 0.5278\n",
      "  val   AUC per head: h0: 0.6690 | h1: 0.6685 | h2: 0.6798 | h3: 0.5274\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.6690', '0.6685', '0.6798', '0.5274']\n",
      "  [EdgeMLP] best mean val AUC = 0.6362\n",
      "Epoch 027 | train_loss(step) = 0.4520 | train_loss(eval) = 0.4469 | train_mean_auc = 0.6424 | val_mean_auc = 0.6447\n",
      "  train AUC per head: h0: 0.6776 | h1: 0.6739 | h2: 0.6831 | h3: 0.5352\n",
      "  val   AUC per head: h0: 0.6780 | h1: 0.6764 | h2: 0.6892 | h3: 0.5350\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.6780', '0.6764', '0.6892', '0.5350']\n",
      "  [EdgeMLP] best mean val AUC = 0.6447\n",
      "Epoch 028 | train_loss(step) = 0.4422 | train_loss(eval) = 0.4436 | train_mean_auc = 0.6503 | val_mean_auc = 0.6525\n",
      "  train AUC per head: h0: 0.6864 | h1: 0.6811 | h2: 0.6913 | h3: 0.5427\n",
      "  val   AUC per head: h0: 0.6865 | h1: 0.6835 | h2: 0.6975 | h3: 0.5426\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.6865', '0.6835', '0.6975', '0.5426']\n",
      "  [EdgeMLP] best mean val AUC = 0.6525\n",
      "Epoch 029 | train_loss(step) = 0.4385 | train_loss(eval) = 0.4404 | train_mean_auc = 0.6575 | val_mean_auc = 0.6596\n",
      "  train AUC per head: h0: 0.6942 | h1: 0.6875 | h2: 0.6983 | h3: 0.5499\n",
      "  val   AUC per head: h0: 0.6941 | h1: 0.6899 | h2: 0.7046 | h3: 0.5499\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.6941', '0.6899', '0.7046', '0.5499']\n",
      "  [EdgeMLP] best mean val AUC = 0.6596\n",
      "Epoch 030 | train_loss(step) = 0.4420 | train_loss(eval) = 0.4376 | train_mean_auc = 0.6639 | val_mean_auc = 0.6659\n",
      "  train AUC per head: h0: 0.7007 | h1: 0.6932 | h2: 0.7045 | h3: 0.5570\n",
      "  val   AUC per head: h0: 0.7003 | h1: 0.6955 | h2: 0.7107 | h3: 0.5573\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7003', '0.6955', '0.7107', '0.5573']\n",
      "  [EdgeMLP] best mean val AUC = 0.6659\n",
      "Epoch 031 | train_loss(step) = 0.4380 | train_loss(eval) = 0.4350 | train_mean_auc = 0.6695 | val_mean_auc = 0.6715\n",
      "  train AUC per head: h0: 0.7058 | h1: 0.6984 | h2: 0.7098 | h3: 0.5641\n",
      "  val   AUC per head: h0: 0.7050 | h1: 0.7005 | h2: 0.7160 | h3: 0.5645\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7050', '0.7005', '0.7160', '0.5645']\n",
      "  [EdgeMLP] best mean val AUC = 0.6715\n",
      "Epoch 032 | train_loss(step) = 0.4450 | train_loss(eval) = 0.4329 | train_mean_auc = 0.6745 | val_mean_auc = 0.6765\n",
      "  train AUC per head: h0: 0.7094 | h1: 0.7030 | h2: 0.7144 | h3: 0.5711\n",
      "  val   AUC per head: h0: 0.7085 | h1: 0.7051 | h2: 0.7206 | h3: 0.5717\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7085', '0.7051', '0.7206', '0.5717']\n",
      "  [EdgeMLP] best mean val AUC = 0.6765\n",
      "Epoch 033 | train_loss(step) = 0.4332 | train_loss(eval) = 0.4311 | train_mean_auc = 0.6789 | val_mean_auc = 0.6809\n",
      "  train AUC per head: h0: 0.7122 | h1: 0.7072 | h2: 0.7184 | h3: 0.5778\n",
      "  val   AUC per head: h0: 0.7110 | h1: 0.7092 | h2: 0.7246 | h3: 0.5786\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7110', '0.7092', '0.7246', '0.5786']\n",
      "  [EdgeMLP] best mean val AUC = 0.6809\n",
      "Epoch 034 | train_loss(step) = 0.4325 | train_loss(eval) = 0.4296 | train_mean_auc = 0.6829 | val_mean_auc = 0.6848\n",
      "  train AUC per head: h0: 0.7141 | h1: 0.7110 | h2: 0.7220 | h3: 0.5845\n",
      "  val   AUC per head: h0: 0.7128 | h1: 0.7129 | h2: 0.7281 | h3: 0.5855\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7128', '0.7129', '0.7281', '0.5855']\n",
      "  [EdgeMLP] best mean val AUC = 0.6848\n",
      "Epoch 035 | train_loss(step) = 0.4341 | train_loss(eval) = 0.4284 | train_mean_auc = 0.6866 | val_mean_auc = 0.6884\n",
      "  train AUC per head: h0: 0.7155 | h1: 0.7144 | h2: 0.7251 | h3: 0.5911\n",
      "  val   AUC per head: h0: 0.7141 | h1: 0.7162 | h2: 0.7310 | h3: 0.5924\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7141', '0.7162', '0.7310', '0.5924']\n",
      "  [EdgeMLP] best mean val AUC = 0.6884\n",
      "Epoch 036 | train_loss(step) = 0.4275 | train_loss(eval) = 0.4272 | train_mean_auc = 0.6899 | val_mean_auc = 0.6918\n",
      "  train AUC per head: h0: 0.7165 | h1: 0.7175 | h2: 0.7279 | h3: 0.5978\n",
      "  val   AUC per head: h0: 0.7150 | h1: 0.7192 | h2: 0.7337 | h3: 0.5992\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7150', '0.7192', '0.7337', '0.5992']\n",
      "  [EdgeMLP] best mean val AUC = 0.6918\n",
      "Epoch 037 | train_loss(step) = 0.4285 | train_loss(eval) = 0.4262 | train_mean_auc = 0.6930 | val_mean_auc = 0.6949\n",
      "  train AUC per head: h0: 0.7173 | h1: 0.7202 | h2: 0.7303 | h3: 0.6044\n",
      "  val   AUC per head: h0: 0.7157 | h1: 0.7217 | h2: 0.7359 | h3: 0.6061\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7157', '0.7217', '0.7359', '0.6061']\n",
      "  [EdgeMLP] best mean val AUC = 0.6949\n",
      "Epoch 038 | train_loss(step) = 0.4196 | train_loss(eval) = 0.4251 | train_mean_auc = 0.6959 | val_mean_auc = 0.6977\n",
      "  train AUC per head: h0: 0.7178 | h1: 0.7225 | h2: 0.7324 | h3: 0.6110\n",
      "  val   AUC per head: h0: 0.7161 | h1: 0.7239 | h2: 0.7379 | h3: 0.6128\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7161', '0.7239', '0.7379', '0.6128']\n",
      "  [EdgeMLP] best mean val AUC = 0.6977\n",
      "Epoch 039 | train_loss(step) = 0.4282 | train_loss(eval) = 0.4240 | train_mean_auc = 0.6987 | val_mean_auc = 0.7004\n",
      "  train AUC per head: h0: 0.7183 | h1: 0.7245 | h2: 0.7343 | h3: 0.6176\n",
      "  val   AUC per head: h0: 0.7165 | h1: 0.7258 | h2: 0.7396 | h3: 0.6196\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7165', '0.7258', '0.7396', '0.6196']\n",
      "  [EdgeMLP] best mean val AUC = 0.7004\n",
      "Epoch 040 | train_loss(step) = 0.4241 | train_loss(eval) = 0.4228 | train_mean_auc = 0.7013 | val_mean_auc = 0.7029\n",
      "  train AUC per head: h0: 0.7189 | h1: 0.7263 | h2: 0.7359 | h3: 0.6241\n",
      "  val   AUC per head: h0: 0.7170 | h1: 0.7275 | h2: 0.7410 | h3: 0.6262\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7170', '0.7275', '0.7410', '0.6262']\n",
      "  [EdgeMLP] best mean val AUC = 0.7029\n",
      "Epoch 041 | train_loss(step) = 0.4240 | train_loss(eval) = 0.4217 | train_mean_auc = 0.7038 | val_mean_auc = 0.7054\n",
      "  train AUC per head: h0: 0.7196 | h1: 0.7279 | h2: 0.7374 | h3: 0.6304\n",
      "  val   AUC per head: h0: 0.7176 | h1: 0.7290 | h2: 0.7423 | h3: 0.6327\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7176', '0.7290', '0.7423', '0.6327']\n",
      "  [EdgeMLP] best mean val AUC = 0.7054\n",
      "Epoch 042 | train_loss(step) = 0.4256 | train_loss(eval) = 0.4204 | train_mean_auc = 0.7063 | val_mean_auc = 0.7077\n",
      "  train AUC per head: h0: 0.7203 | h1: 0.7294 | h2: 0.7388 | h3: 0.6366\n",
      "  val   AUC per head: h0: 0.7183 | h1: 0.7303 | h2: 0.7435 | h3: 0.6389\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7183', '0.7303', '0.7435', '0.6389']\n",
      "  [EdgeMLP] best mean val AUC = 0.7077\n",
      "Epoch 043 | train_loss(step) = 0.4264 | train_loss(eval) = 0.4192 | train_mean_auc = 0.7086 | val_mean_auc = 0.7100\n",
      "  train AUC per head: h0: 0.7213 | h1: 0.7308 | h2: 0.7400 | h3: 0.6424\n",
      "  val   AUC per head: h0: 0.7191 | h1: 0.7315 | h2: 0.7445 | h3: 0.6449\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7191', '0.7315', '0.7445', '0.6449']\n",
      "  [EdgeMLP] best mean val AUC = 0.7100\n",
      "Epoch 044 | train_loss(step) = 0.4231 | train_loss(eval) = 0.4179 | train_mean_auc = 0.7109 | val_mean_auc = 0.7122\n",
      "  train AUC per head: h0: 0.7224 | h1: 0.7320 | h2: 0.7411 | h3: 0.6482\n",
      "  val   AUC per head: h0: 0.7201 | h1: 0.7326 | h2: 0.7454 | h3: 0.6507\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7201', '0.7326', '0.7454', '0.6507']\n",
      "  [EdgeMLP] best mean val AUC = 0.7122\n",
      "Epoch 045 | train_loss(step) = 0.4225 | train_loss(eval) = 0.4166 | train_mean_auc = 0.7132 | val_mean_auc = 0.7144\n",
      "  train AUC per head: h0: 0.7237 | h1: 0.7332 | h2: 0.7421 | h3: 0.6539\n",
      "  val   AUC per head: h0: 0.7213 | h1: 0.7336 | h2: 0.7462 | h3: 0.6565\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7213', '0.7336', '0.7462', '0.6565']\n",
      "  [EdgeMLP] best mean val AUC = 0.7144\n",
      "Epoch 046 | train_loss(step) = 0.4130 | train_loss(eval) = 0.4153 | train_mean_auc = 0.7154 | val_mean_auc = 0.7166\n",
      "  train AUC per head: h0: 0.7251 | h1: 0.7342 | h2: 0.7429 | h3: 0.6594\n",
      "  val   AUC per head: h0: 0.7227 | h1: 0.7345 | h2: 0.7469 | h3: 0.6621\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7227', '0.7345', '0.7469', '0.6621']\n",
      "  [EdgeMLP] best mean val AUC = 0.7166\n",
      "Epoch 047 | train_loss(step) = 0.4087 | train_loss(eval) = 0.4139 | train_mean_auc = 0.7176 | val_mean_auc = 0.7186\n",
      "  train AUC per head: h0: 0.7266 | h1: 0.7351 | h2: 0.7436 | h3: 0.6649\n",
      "  val   AUC per head: h0: 0.7241 | h1: 0.7352 | h2: 0.7474 | h3: 0.6676\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7241', '0.7352', '0.7474', '0.6676']\n",
      "  [EdgeMLP] best mean val AUC = 0.7186\n",
      "Epoch 048 | train_loss(step) = 0.4130 | train_loss(eval) = 0.4125 | train_mean_auc = 0.7197 | val_mean_auc = 0.7206\n",
      "  train AUC per head: h0: 0.7282 | h1: 0.7359 | h2: 0.7443 | h3: 0.6703\n",
      "  val   AUC per head: h0: 0.7255 | h1: 0.7359 | h2: 0.7479 | h3: 0.6730\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7255', '0.7359', '0.7479', '0.6730']\n",
      "  [EdgeMLP] best mean val AUC = 0.7206\n",
      "Epoch 049 | train_loss(step) = 0.4171 | train_loss(eval) = 0.4112 | train_mean_auc = 0.7218 | val_mean_auc = 0.7226\n",
      "  train AUC per head: h0: 0.7297 | h1: 0.7366 | h2: 0.7449 | h3: 0.6760\n",
      "  val   AUC per head: h0: 0.7270 | h1: 0.7365 | h2: 0.7483 | h3: 0.6787\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7270', '0.7365', '0.7483', '0.6787']\n",
      "  [EdgeMLP] best mean val AUC = 0.7226\n",
      "Epoch 050 | train_loss(step) = 0.4174 | train_loss(eval) = 0.4099 | train_mean_auc = 0.7240 | val_mean_auc = 0.7247\n",
      "  train AUC per head: h0: 0.7312 | h1: 0.7373 | h2: 0.7454 | h3: 0.6821\n",
      "  val   AUC per head: h0: 0.7283 | h1: 0.7370 | h2: 0.7487 | h3: 0.6848\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7283', '0.7370', '0.7487', '0.6848']\n",
      "  [EdgeMLP] best mean val AUC = 0.7247\n",
      "Epoch 051 | train_loss(step) = 0.4063 | train_loss(eval) = 0.4086 | train_mean_auc = 0.7261 | val_mean_auc = 0.7267\n",
      "  train AUC per head: h0: 0.7325 | h1: 0.7378 | h2: 0.7458 | h3: 0.6882\n",
      "  val   AUC per head: h0: 0.7296 | h1: 0.7374 | h2: 0.7490 | h3: 0.6909\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7296', '0.7374', '0.7490', '0.6909']\n",
      "  [EdgeMLP] best mean val AUC = 0.7267\n",
      "Epoch 052 | train_loss(step) = 0.4105 | train_loss(eval) = 0.4074 | train_mean_auc = 0.7283 | val_mean_auc = 0.7289\n",
      "  train AUC per head: h0: 0.7337 | h1: 0.7382 | h2: 0.7462 | h3: 0.6949\n",
      "  val   AUC per head: h0: 0.7308 | h1: 0.7377 | h2: 0.7493 | h3: 0.6976\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7308', '0.7377', '0.7493', '0.6976']\n",
      "  [EdgeMLP] best mean val AUC = 0.7289\n",
      "Epoch 053 | train_loss(step) = 0.4123 | train_loss(eval) = 0.4062 | train_mean_auc = 0.7305 | val_mean_auc = 0.7310\n",
      "  train AUC per head: h0: 0.7348 | h1: 0.7386 | h2: 0.7466 | h3: 0.7021\n",
      "  val   AUC per head: h0: 0.7318 | h1: 0.7380 | h2: 0.7495 | h3: 0.7048\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7318', '0.7380', '0.7495', '0.7048']\n",
      "  [EdgeMLP] best mean val AUC = 0.7310\n",
      "Epoch 054 | train_loss(step) = 0.4154 | train_loss(eval) = 0.4051 | train_mean_auc = 0.7329 | val_mean_auc = 0.7333\n",
      "  train AUC per head: h0: 0.7357 | h1: 0.7389 | h2: 0.7470 | h3: 0.7099\n",
      "  val   AUC per head: h0: 0.7327 | h1: 0.7382 | h2: 0.7498 | h3: 0.7125\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7327', '0.7382', '0.7498', '0.7125']\n",
      "  [EdgeMLP] best mean val AUC = 0.7333\n",
      "Epoch 055 | train_loss(step) = 0.4000 | train_loss(eval) = 0.4040 | train_mean_auc = 0.7352 | val_mean_auc = 0.7356\n",
      "  train AUC per head: h0: 0.7365 | h1: 0.7392 | h2: 0.7473 | h3: 0.7179\n",
      "  val   AUC per head: h0: 0.7334 | h1: 0.7384 | h2: 0.7500 | h3: 0.7204\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7334', '0.7384', '0.7500', '0.7204']\n",
      "  [EdgeMLP] best mean val AUC = 0.7356\n",
      "Epoch 056 | train_loss(step) = 0.3976 | train_loss(eval) = 0.4030 | train_mean_auc = 0.7376 | val_mean_auc = 0.7378\n",
      "  train AUC per head: h0: 0.7372 | h1: 0.7395 | h2: 0.7476 | h3: 0.7260\n",
      "  val   AUC per head: h0: 0.7341 | h1: 0.7386 | h2: 0.7502 | h3: 0.7284\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7341', '0.7386', '0.7502', '0.7284']\n",
      "  [EdgeMLP] best mean val AUC = 0.7378\n",
      "Epoch 057 | train_loss(step) = 0.3997 | train_loss(eval) = 0.4019 | train_mean_auc = 0.7400 | val_mean_auc = 0.7401\n",
      "  train AUC per head: h0: 0.7378 | h1: 0.7398 | h2: 0.7479 | h3: 0.7344\n",
      "  val   AUC per head: h0: 0.7346 | h1: 0.7388 | h2: 0.7504 | h3: 0.7367\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7346', '0.7388', '0.7504', '0.7367']\n",
      "  [EdgeMLP] best mean val AUC = 0.7401\n",
      "Epoch 058 | train_loss(step) = 0.4089 | train_loss(eval) = 0.4008 | train_mean_auc = 0.7424 | val_mean_auc = 0.7425\n",
      "  train AUC per head: h0: 0.7383 | h1: 0.7402 | h2: 0.7482 | h3: 0.7429\n",
      "  val   AUC per head: h0: 0.7352 | h1: 0.7391 | h2: 0.7506 | h3: 0.7450\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7352', '0.7391', '0.7506', '0.7450']\n",
      "  [EdgeMLP] best mean val AUC = 0.7425\n",
      "Epoch 059 | train_loss(step) = 0.4011 | train_loss(eval) = 0.3997 | train_mean_auc = 0.7449 | val_mean_auc = 0.7448\n",
      "  train AUC per head: h0: 0.7389 | h1: 0.7405 | h2: 0.7485 | h3: 0.7516\n",
      "  val   AUC per head: h0: 0.7357 | h1: 0.7394 | h2: 0.7509 | h3: 0.7535\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7357', '0.7394', '0.7509', '0.7535']\n",
      "  [EdgeMLP] best mean val AUC = 0.7448\n",
      "Epoch 060 | train_loss(step) = 0.4008 | train_loss(eval) = 0.3985 | train_mean_auc = 0.7473 | val_mean_auc = 0.7472\n",
      "  train AUC per head: h0: 0.7394 | h1: 0.7410 | h2: 0.7489 | h3: 0.7599\n",
      "  val   AUC per head: h0: 0.7362 | h1: 0.7397 | h2: 0.7511 | h3: 0.7616\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7362', '0.7397', '0.7511', '0.7616']\n",
      "  [EdgeMLP] best mean val AUC = 0.7472\n",
      "Epoch 061 | train_loss(step) = 0.4043 | train_loss(eval) = 0.3974 | train_mean_auc = 0.7495 | val_mean_auc = 0.7493\n",
      "  train AUC per head: h0: 0.7400 | h1: 0.7414 | h2: 0.7492 | h3: 0.7674\n",
      "  val   AUC per head: h0: 0.7368 | h1: 0.7402 | h2: 0.7514 | h3: 0.7688\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7368', '0.7402', '0.7514', '0.7688']\n",
      "  [EdgeMLP] best mean val AUC = 0.7493\n",
      "Epoch 062 | train_loss(step) = 0.3947 | train_loss(eval) = 0.3963 | train_mean_auc = 0.7515 | val_mean_auc = 0.7512\n",
      "  train AUC per head: h0: 0.7406 | h1: 0.7419 | h2: 0.7496 | h3: 0.7740\n",
      "  val   AUC per head: h0: 0.7374 | h1: 0.7406 | h2: 0.7517 | h3: 0.7751\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7374', '0.7406', '0.7517', '0.7751']\n",
      "  [EdgeMLP] best mean val AUC = 0.7512\n",
      "Epoch 063 | train_loss(step) = 0.3999 | train_loss(eval) = 0.3954 | train_mean_auc = 0.7533 | val_mean_auc = 0.7529\n",
      "  train AUC per head: h0: 0.7412 | h1: 0.7423 | h2: 0.7500 | h3: 0.7797\n",
      "  val   AUC per head: h0: 0.7380 | h1: 0.7410 | h2: 0.7521 | h3: 0.7806\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7380', '0.7410', '0.7521', '0.7806']\n",
      "  [EdgeMLP] best mean val AUC = 0.7529\n",
      "Epoch 064 | train_loss(step) = 0.3971 | train_loss(eval) = 0.3945 | train_mean_auc = 0.7548 | val_mean_auc = 0.7544\n",
      "  train AUC per head: h0: 0.7418 | h1: 0.7428 | h2: 0.7504 | h3: 0.7844\n",
      "  val   AUC per head: h0: 0.7387 | h1: 0.7414 | h2: 0.7524 | h3: 0.7851\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7387', '0.7414', '0.7524', '0.7851']\n",
      "  [EdgeMLP] best mean val AUC = 0.7544\n",
      "Epoch 065 | train_loss(step) = 0.4025 | train_loss(eval) = 0.3936 | train_mean_auc = 0.7562 | val_mean_auc = 0.7557\n",
      "  train AUC per head: h0: 0.7424 | h1: 0.7432 | h2: 0.7507 | h3: 0.7884\n",
      "  val   AUC per head: h0: 0.7393 | h1: 0.7418 | h2: 0.7527 | h3: 0.7889\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7393', '0.7418', '0.7527', '0.7889']\n",
      "  [EdgeMLP] best mean val AUC = 0.7557\n",
      "Epoch 066 | train_loss(step) = 0.3915 | train_loss(eval) = 0.3928 | train_mean_auc = 0.7573 | val_mean_auc = 0.7568\n",
      "  train AUC per head: h0: 0.7429 | h1: 0.7436 | h2: 0.7510 | h3: 0.7918\n",
      "  val   AUC per head: h0: 0.7399 | h1: 0.7423 | h2: 0.7530 | h3: 0.7921\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7399', '0.7423', '0.7530', '0.7921']\n",
      "  [EdgeMLP] best mean val AUC = 0.7568\n",
      "Epoch 067 | train_loss(step) = 0.3919 | train_loss(eval) = 0.3921 | train_mean_auc = 0.7583 | val_mean_auc = 0.7578\n",
      "  train AUC per head: h0: 0.7435 | h1: 0.7440 | h2: 0.7513 | h3: 0.7945\n",
      "  val   AUC per head: h0: 0.7405 | h1: 0.7427 | h2: 0.7532 | h3: 0.7947\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7405', '0.7427', '0.7532', '0.7947']\n",
      "  [EdgeMLP] best mean val AUC = 0.7578\n",
      "Epoch 068 | train_loss(step) = 0.3835 | train_loss(eval) = 0.3914 | train_mean_auc = 0.7592 | val_mean_auc = 0.7586\n",
      "  train AUC per head: h0: 0.7440 | h1: 0.7444 | h2: 0.7515 | h3: 0.7968\n",
      "  val   AUC per head: h0: 0.7410 | h1: 0.7431 | h2: 0.7534 | h3: 0.7968\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7410', '0.7431', '0.7534', '0.7968']\n",
      "  [EdgeMLP] best mean val AUC = 0.7586\n",
      "Epoch 069 | train_loss(step) = 0.3846 | train_loss(eval) = 0.3908 | train_mean_auc = 0.7600 | val_mean_auc = 0.7594\n",
      "  train AUC per head: h0: 0.7445 | h1: 0.7449 | h2: 0.7517 | h3: 0.7989\n",
      "  val   AUC per head: h0: 0.7415 | h1: 0.7435 | h2: 0.7536 | h3: 0.7988\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7415', '0.7435', '0.7536', '0.7988']\n",
      "  [EdgeMLP] best mean val AUC = 0.7594\n",
      "Epoch 070 | train_loss(step) = 0.3885 | train_loss(eval) = 0.3901 | train_mean_auc = 0.7607 | val_mean_auc = 0.7601\n",
      "  train AUC per head: h0: 0.7449 | h1: 0.7452 | h2: 0.7519 | h3: 0.8008\n",
      "  val   AUC per head: h0: 0.7420 | h1: 0.7439 | h2: 0.7538 | h3: 0.8006\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7420', '0.7439', '0.7538', '0.8006']\n",
      "  [EdgeMLP] best mean val AUC = 0.7601\n",
      "Epoch 071 | train_loss(step) = 0.3966 | train_loss(eval) = 0.3895 | train_mean_auc = 0.7614 | val_mean_auc = 0.7608\n",
      "  train AUC per head: h0: 0.7454 | h1: 0.7456 | h2: 0.7521 | h3: 0.8026\n",
      "  val   AUC per head: h0: 0.7425 | h1: 0.7442 | h2: 0.7539 | h3: 0.8024\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7425', '0.7442', '0.7539', '0.8024']\n",
      "  [EdgeMLP] best mean val AUC = 0.7608\n",
      "Epoch 072 | train_loss(step) = 0.3896 | train_loss(eval) = 0.3889 | train_mean_auc = 0.7621 | val_mean_auc = 0.7615\n",
      "  train AUC per head: h0: 0.7458 | h1: 0.7459 | h2: 0.7523 | h3: 0.8043\n",
      "  val   AUC per head: h0: 0.7430 | h1: 0.7446 | h2: 0.7541 | h3: 0.8041\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7430', '0.7446', '0.7541', '0.8041']\n",
      "  [EdgeMLP] best mean val AUC = 0.7615\n",
      "Epoch 073 | train_loss(step) = 0.3873 | train_loss(eval) = 0.3883 | train_mean_auc = 0.7628 | val_mean_auc = 0.7622\n",
      "  train AUC per head: h0: 0.7463 | h1: 0.7462 | h2: 0.7526 | h3: 0.8061\n",
      "  val   AUC per head: h0: 0.7436 | h1: 0.7449 | h2: 0.7544 | h3: 0.8058\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7436', '0.7449', '0.7544', '0.8058']\n",
      "  [EdgeMLP] best mean val AUC = 0.7622\n",
      "Epoch 074 | train_loss(step) = 0.3846 | train_loss(eval) = 0.3878 | train_mean_auc = 0.7636 | val_mean_auc = 0.7629\n",
      "  train AUC per head: h0: 0.7470 | h1: 0.7465 | h2: 0.7529 | h3: 0.8079\n",
      "  val   AUC per head: h0: 0.7443 | h1: 0.7452 | h2: 0.7547 | h3: 0.8076\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7443', '0.7452', '0.7547', '0.8076']\n",
      "  [EdgeMLP] best mean val AUC = 0.7629\n",
      "Epoch 075 | train_loss(step) = 0.3942 | train_loss(eval) = 0.3872 | train_mean_auc = 0.7643 | val_mean_auc = 0.7637\n",
      "  train AUC per head: h0: 0.7477 | h1: 0.7468 | h2: 0.7532 | h3: 0.8096\n",
      "  val   AUC per head: h0: 0.7450 | h1: 0.7455 | h2: 0.7549 | h3: 0.8093\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7450', '0.7455', '0.7549', '0.8093']\n",
      "  [EdgeMLP] best mean val AUC = 0.7637\n",
      "Epoch 076 | train_loss(step) = 0.3822 | train_loss(eval) = 0.3867 | train_mean_auc = 0.7652 | val_mean_auc = 0.7645\n",
      "  train AUC per head: h0: 0.7485 | h1: 0.7471 | h2: 0.7536 | h3: 0.8114\n",
      "  val   AUC per head: h0: 0.7458 | h1: 0.7458 | h2: 0.7553 | h3: 0.8110\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7458', '0.7458', '0.7553', '0.8110']\n",
      "  [EdgeMLP] best mean val AUC = 0.7645\n",
      "Epoch 077 | train_loss(step) = 0.3868 | train_loss(eval) = 0.3862 | train_mean_auc = 0.7660 | val_mean_auc = 0.7652\n",
      "  train AUC per head: h0: 0.7492 | h1: 0.7475 | h2: 0.7540 | h3: 0.8131\n",
      "  val   AUC per head: h0: 0.7465 | h1: 0.7461 | h2: 0.7557 | h3: 0.8127\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7465', '0.7461', '0.7557', '0.8127']\n",
      "  [EdgeMLP] best mean val AUC = 0.7652\n",
      "Epoch 078 | train_loss(step) = 0.3803 | train_loss(eval) = 0.3856 | train_mean_auc = 0.7668 | val_mean_auc = 0.7660\n",
      "  train AUC per head: h0: 0.7499 | h1: 0.7479 | h2: 0.7546 | h3: 0.8148\n",
      "  val   AUC per head: h0: 0.7472 | h1: 0.7464 | h2: 0.7563 | h3: 0.8143\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7472', '0.7464', '0.7563', '0.8143']\n",
      "  [EdgeMLP] best mean val AUC = 0.7660\n",
      "Epoch 079 | train_loss(step) = 0.3688 | train_loss(eval) = 0.3850 | train_mean_auc = 0.7676 | val_mean_auc = 0.7668\n",
      "  train AUC per head: h0: 0.7505 | h1: 0.7483 | h2: 0.7552 | h3: 0.8163\n",
      "  val   AUC per head: h0: 0.7478 | h1: 0.7467 | h2: 0.7569 | h3: 0.8158\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7478', '0.7467', '0.7569', '0.8158']\n",
      "  [EdgeMLP] best mean val AUC = 0.7668\n",
      "Epoch 080 | train_loss(step) = 0.3896 | train_loss(eval) = 0.3845 | train_mean_auc = 0.7684 | val_mean_auc = 0.7676\n",
      "  train AUC per head: h0: 0.7512 | h1: 0.7486 | h2: 0.7558 | h3: 0.8180\n",
      "  val   AUC per head: h0: 0.7485 | h1: 0.7471 | h2: 0.7574 | h3: 0.8174\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7485', '0.7471', '0.7574', '0.8174']\n",
      "  [EdgeMLP] best mean val AUC = 0.7676\n",
      "Epoch 081 | train_loss(step) = 0.3945 | train_loss(eval) = 0.3840 | train_mean_auc = 0.7692 | val_mean_auc = 0.7684\n",
      "  train AUC per head: h0: 0.7518 | h1: 0.7490 | h2: 0.7564 | h3: 0.8198\n",
      "  val   AUC per head: h0: 0.7493 | h1: 0.7474 | h2: 0.7580 | h3: 0.8191\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7493', '0.7474', '0.7580', '0.8191']\n",
      "  [EdgeMLP] best mean val AUC = 0.7684\n",
      "Epoch 082 | train_loss(step) = 0.3986 | train_loss(eval) = 0.3835 | train_mean_auc = 0.7701 | val_mean_auc = 0.7693\n",
      "  train AUC per head: h0: 0.7525 | h1: 0.7493 | h2: 0.7569 | h3: 0.8215\n",
      "  val   AUC per head: h0: 0.7500 | h1: 0.7477 | h2: 0.7585 | h3: 0.8208\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7500', '0.7477', '0.7585', '0.8208']\n",
      "  [EdgeMLP] best mean val AUC = 0.7693\n",
      "Epoch 083 | train_loss(step) = 0.3839 | train_loss(eval) = 0.3829 | train_mean_auc = 0.7708 | val_mean_auc = 0.7700\n",
      "  train AUC per head: h0: 0.7532 | h1: 0.7496 | h2: 0.7575 | h3: 0.8229\n",
      "  val   AUC per head: h0: 0.7507 | h1: 0.7480 | h2: 0.7591 | h3: 0.8223\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7507', '0.7480', '0.7591', '0.8223']\n",
      "  [EdgeMLP] best mean val AUC = 0.7700\n",
      "Epoch 084 | train_loss(step) = 0.3903 | train_loss(eval) = 0.3824 | train_mean_auc = 0.7716 | val_mean_auc = 0.7707\n",
      "  train AUC per head: h0: 0.7540 | h1: 0.7499 | h2: 0.7580 | h3: 0.8244\n",
      "  val   AUC per head: h0: 0.7515 | h1: 0.7482 | h2: 0.7596 | h3: 0.8237\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7515', '0.7482', '0.7596', '0.8237']\n",
      "  [EdgeMLP] best mean val AUC = 0.7707\n",
      "Epoch 085 | train_loss(step) = 0.3855 | train_loss(eval) = 0.3819 | train_mean_auc = 0.7723 | val_mean_auc = 0.7715\n",
      "  train AUC per head: h0: 0.7546 | h1: 0.7503 | h2: 0.7586 | h3: 0.8257\n",
      "  val   AUC per head: h0: 0.7521 | h1: 0.7486 | h2: 0.7601 | h3: 0.8250\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7521', '0.7486', '0.7601', '0.8250']\n",
      "  [EdgeMLP] best mean val AUC = 0.7715\n",
      "Epoch 086 | train_loss(step) = 0.3752 | train_loss(eval) = 0.3815 | train_mean_auc = 0.7731 | val_mean_auc = 0.7722\n",
      "  train AUC per head: h0: 0.7552 | h1: 0.7507 | h2: 0.7591 | h3: 0.8272\n",
      "  val   AUC per head: h0: 0.7527 | h1: 0.7489 | h2: 0.7606 | h3: 0.8265\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7527', '0.7489', '0.7606', '0.8265']\n",
      "  [EdgeMLP] best mean val AUC = 0.7722\n",
      "Epoch 087 | train_loss(step) = 0.3803 | train_loss(eval) = 0.3810 | train_mean_auc = 0.7738 | val_mean_auc = 0.7729\n",
      "  train AUC per head: h0: 0.7558 | h1: 0.7511 | h2: 0.7597 | h3: 0.8287\n",
      "  val   AUC per head: h0: 0.7533 | h1: 0.7493 | h2: 0.7611 | h3: 0.8279\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7533', '0.7493', '0.7611', '0.8279']\n",
      "  [EdgeMLP] best mean val AUC = 0.7729\n",
      "Epoch 088 | train_loss(step) = 0.3829 | train_loss(eval) = 0.3806 | train_mean_auc = 0.7745 | val_mean_auc = 0.7736\n",
      "  train AUC per head: h0: 0.7563 | h1: 0.7514 | h2: 0.7602 | h3: 0.8300\n",
      "  val   AUC per head: h0: 0.7539 | h1: 0.7497 | h2: 0.7617 | h3: 0.8292\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7539', '0.7497', '0.7617', '0.8292']\n",
      "  [EdgeMLP] best mean val AUC = 0.7736\n",
      "Epoch 089 | train_loss(step) = 0.3796 | train_loss(eval) = 0.3802 | train_mean_auc = 0.7752 | val_mean_auc = 0.7743\n",
      "  train AUC per head: h0: 0.7569 | h1: 0.7518 | h2: 0.7607 | h3: 0.8314\n",
      "  val   AUC per head: h0: 0.7545 | h1: 0.7500 | h2: 0.7622 | h3: 0.8305\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7545', '0.7500', '0.7622', '0.8305']\n",
      "  [EdgeMLP] best mean val AUC = 0.7743\n",
      "Epoch 090 | train_loss(step) = 0.3775 | train_loss(eval) = 0.3798 | train_mean_auc = 0.7759 | val_mean_auc = 0.7750\n",
      "  train AUC per head: h0: 0.7575 | h1: 0.7521 | h2: 0.7613 | h3: 0.8328\n",
      "  val   AUC per head: h0: 0.7551 | h1: 0.7504 | h2: 0.7627 | h3: 0.8319\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7551', '0.7504', '0.7627', '0.8319']\n",
      "  [EdgeMLP] best mean val AUC = 0.7750\n",
      "Epoch 091 | train_loss(step) = 0.3769 | train_loss(eval) = 0.3794 | train_mean_auc = 0.7766 | val_mean_auc = 0.7757\n",
      "  train AUC per head: h0: 0.7581 | h1: 0.7525 | h2: 0.7618 | h3: 0.8342\n",
      "  val   AUC per head: h0: 0.7557 | h1: 0.7507 | h2: 0.7632 | h3: 0.8332\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7557', '0.7507', '0.7632', '0.8332']\n",
      "  [EdgeMLP] best mean val AUC = 0.7757\n",
      "Epoch 092 | train_loss(step) = 0.3823 | train_loss(eval) = 0.3790 | train_mean_auc = 0.7773 | val_mean_auc = 0.7764\n",
      "  train AUC per head: h0: 0.7587 | h1: 0.7528 | h2: 0.7622 | h3: 0.8355\n",
      "  val   AUC per head: h0: 0.7563 | h1: 0.7511 | h2: 0.7637 | h3: 0.8345\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7563', '0.7511', '0.7637', '0.8345']\n",
      "  [EdgeMLP] best mean val AUC = 0.7764\n",
      "Epoch 093 | train_loss(step) = 0.3885 | train_loss(eval) = 0.3786 | train_mean_auc = 0.7779 | val_mean_auc = 0.7770\n",
      "  train AUC per head: h0: 0.7593 | h1: 0.7531 | h2: 0.7627 | h3: 0.8367\n",
      "  val   AUC per head: h0: 0.7569 | h1: 0.7514 | h2: 0.7641 | h3: 0.8357\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7569', '0.7514', '0.7641', '0.8357']\n",
      "  [EdgeMLP] best mean val AUC = 0.7770\n",
      "Epoch 094 | train_loss(step) = 0.3823 | train_loss(eval) = 0.3783 | train_mean_auc = 0.7785 | val_mean_auc = 0.7776\n",
      "  train AUC per head: h0: 0.7598 | h1: 0.7534 | h2: 0.7631 | h3: 0.8377\n",
      "  val   AUC per head: h0: 0.7575 | h1: 0.7517 | h2: 0.7646 | h3: 0.8368\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7575', '0.7517', '0.7646', '0.8368']\n",
      "  [EdgeMLP] best mean val AUC = 0.7776\n",
      "Epoch 095 | train_loss(step) = 0.3741 | train_loss(eval) = 0.3779 | train_mean_auc = 0.7790 | val_mean_auc = 0.7782\n",
      "  train AUC per head: h0: 0.7603 | h1: 0.7536 | h2: 0.7636 | h3: 0.8386\n",
      "  val   AUC per head: h0: 0.7580 | h1: 0.7520 | h2: 0.7651 | h3: 0.8375\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7580', '0.7520', '0.7651', '0.8375']\n",
      "  [EdgeMLP] best mean val AUC = 0.7782\n",
      "Epoch 096 | train_loss(step) = 0.3817 | train_loss(eval) = 0.3776 | train_mean_auc = 0.7795 | val_mean_auc = 0.7787\n",
      "  train AUC per head: h0: 0.7609 | h1: 0.7539 | h2: 0.7640 | h3: 0.8393\n",
      "  val   AUC per head: h0: 0.7585 | h1: 0.7522 | h2: 0.7656 | h3: 0.8383\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7585', '0.7522', '0.7656', '0.8383']\n",
      "  [EdgeMLP] best mean val AUC = 0.7787\n",
      "Epoch 097 | train_loss(step) = 0.3846 | train_loss(eval) = 0.3773 | train_mean_auc = 0.7800 | val_mean_auc = 0.7791\n",
      "  train AUC per head: h0: 0.7614 | h1: 0.7541 | h2: 0.7645 | h3: 0.8399\n",
      "  val   AUC per head: h0: 0.7591 | h1: 0.7525 | h2: 0.7660 | h3: 0.8389\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7591', '0.7525', '0.7660', '0.8389']\n",
      "  [EdgeMLP] best mean val AUC = 0.7791\n",
      "Epoch 098 | train_loss(step) = 0.3792 | train_loss(eval) = 0.3770 | train_mean_auc = 0.7804 | val_mean_auc = 0.7796\n",
      "  train AUC per head: h0: 0.7619 | h1: 0.7543 | h2: 0.7649 | h3: 0.8406\n",
      "  val   AUC per head: h0: 0.7596 | h1: 0.7527 | h2: 0.7664 | h3: 0.8395\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7596', '0.7527', '0.7664', '0.8395']\n",
      "  [EdgeMLP] best mean val AUC = 0.7796\n",
      "Epoch 099 | train_loss(step) = 0.3787 | train_loss(eval) = 0.3767 | train_mean_auc = 0.7808 | val_mean_auc = 0.7800\n",
      "  train AUC per head: h0: 0.7624 | h1: 0.7545 | h2: 0.7652 | h3: 0.8412\n",
      "  val   AUC per head: h0: 0.7601 | h1: 0.7530 | h2: 0.7668 | h3: 0.8401\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7601', '0.7530', '0.7668', '0.8401']\n",
      "  [EdgeMLP] best mean val AUC = 0.7800\n",
      "Epoch 100 | train_loss(step) = 0.3780 | train_loss(eval) = 0.3764 | train_mean_auc = 0.7812 | val_mean_auc = 0.7804\n",
      "  train AUC per head: h0: 0.7629 | h1: 0.7547 | h2: 0.7656 | h3: 0.8416\n",
      "  val   AUC per head: h0: 0.7607 | h1: 0.7532 | h2: 0.7672 | h3: 0.8405\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7607', '0.7532', '0.7672', '0.8405']\n",
      "  [EdgeMLP] best mean val AUC = 0.7804\n",
      "Epoch 101 | train_loss(step) = 0.3788 | train_loss(eval) = 0.3761 | train_mean_auc = 0.7816 | val_mean_auc = 0.7807\n",
      "  train AUC per head: h0: 0.7635 | h1: 0.7550 | h2: 0.7659 | h3: 0.8420\n",
      "  val   AUC per head: h0: 0.7612 | h1: 0.7534 | h2: 0.7675 | h3: 0.8408\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7612', '0.7534', '0.7675', '0.8408']\n",
      "  [EdgeMLP] best mean val AUC = 0.7807\n",
      "Epoch 102 | train_loss(step) = 0.3764 | train_loss(eval) = 0.3758 | train_mean_auc = 0.7819 | val_mean_auc = 0.7811\n",
      "  train AUC per head: h0: 0.7639 | h1: 0.7552 | h2: 0.7662 | h3: 0.8424\n",
      "  val   AUC per head: h0: 0.7618 | h1: 0.7536 | h2: 0.7677 | h3: 0.8411\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7618', '0.7536', '0.7677', '0.8411']\n",
      "  [EdgeMLP] best mean val AUC = 0.7811\n",
      "Epoch 103 | train_loss(step) = 0.3747 | train_loss(eval) = 0.3755 | train_mean_auc = 0.7823 | val_mean_auc = 0.7814\n",
      "  train AUC per head: h0: 0.7644 | h1: 0.7555 | h2: 0.7665 | h3: 0.8427\n",
      "  val   AUC per head: h0: 0.7622 | h1: 0.7539 | h2: 0.7680 | h3: 0.8415\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7622', '0.7539', '0.7680', '0.8415']\n",
      "  [EdgeMLP] best mean val AUC = 0.7814\n",
      "Epoch 104 | train_loss(step) = 0.3700 | train_loss(eval) = 0.3753 | train_mean_auc = 0.7825 | val_mean_auc = 0.7817\n",
      "  train AUC per head: h0: 0.7647 | h1: 0.7557 | h2: 0.7667 | h3: 0.8430\n",
      "  val   AUC per head: h0: 0.7626 | h1: 0.7541 | h2: 0.7682 | h3: 0.8418\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7626', '0.7541', '0.7682', '0.8418']\n",
      "  [EdgeMLP] best mean val AUC = 0.7817\n",
      "Epoch 105 | train_loss(step) = 0.3819 | train_loss(eval) = 0.3750 | train_mean_auc = 0.7829 | val_mean_auc = 0.7820\n",
      "  train AUC per head: h0: 0.7652 | h1: 0.7559 | h2: 0.7670 | h3: 0.8434\n",
      "  val   AUC per head: h0: 0.7630 | h1: 0.7543 | h2: 0.7684 | h3: 0.8421\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7630', '0.7543', '0.7684', '0.8421']\n",
      "  [EdgeMLP] best mean val AUC = 0.7820\n",
      "Epoch 106 | train_loss(step) = 0.3799 | train_loss(eval) = 0.3748 | train_mean_auc = 0.7832 | val_mean_auc = 0.7823\n",
      "  train AUC per head: h0: 0.7657 | h1: 0.7562 | h2: 0.7672 | h3: 0.8438\n",
      "  val   AUC per head: h0: 0.7635 | h1: 0.7545 | h2: 0.7686 | h3: 0.8425\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7635', '0.7545', '0.7686', '0.8425']\n",
      "  [EdgeMLP] best mean val AUC = 0.7823\n",
      "Epoch 107 | train_loss(step) = 0.3713 | train_loss(eval) = 0.3745 | train_mean_auc = 0.7836 | val_mean_auc = 0.7827\n",
      "  train AUC per head: h0: 0.7663 | h1: 0.7564 | h2: 0.7675 | h3: 0.8443\n",
      "  val   AUC per head: h0: 0.7641 | h1: 0.7547 | h2: 0.7689 | h3: 0.8430\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7641', '0.7547', '0.7689', '0.8430']\n",
      "  [EdgeMLP] best mean val AUC = 0.7827\n",
      "Epoch 108 | train_loss(step) = 0.3764 | train_loss(eval) = 0.3742 | train_mean_auc = 0.7840 | val_mean_auc = 0.7831\n",
      "  train AUC per head: h0: 0.7670 | h1: 0.7566 | h2: 0.7677 | h3: 0.8449\n",
      "  val   AUC per head: h0: 0.7647 | h1: 0.7549 | h2: 0.7691 | h3: 0.8435\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7647', '0.7549', '0.7691', '0.8435']\n",
      "  [EdgeMLP] best mean val AUC = 0.7831\n",
      "Epoch 109 | train_loss(step) = 0.3778 | train_loss(eval) = 0.3739 | train_mean_auc = 0.7844 | val_mean_auc = 0.7834\n",
      "  train AUC per head: h0: 0.7676 | h1: 0.7568 | h2: 0.7679 | h3: 0.8453\n",
      "  val   AUC per head: h0: 0.7653 | h1: 0.7551 | h2: 0.7692 | h3: 0.8438\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7653', '0.7551', '0.7692', '0.8438']\n",
      "  [EdgeMLP] best mean val AUC = 0.7834\n",
      "Epoch 110 | train_loss(step) = 0.3760 | train_loss(eval) = 0.3736 | train_mean_auc = 0.7847 | val_mean_auc = 0.7837\n",
      "  train AUC per head: h0: 0.7682 | h1: 0.7570 | h2: 0.7681 | h3: 0.8457\n",
      "  val   AUC per head: h0: 0.7659 | h1: 0.7553 | h2: 0.7693 | h3: 0.8442\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7659', '0.7553', '0.7693', '0.8442']\n",
      "  [EdgeMLP] best mean val AUC = 0.7837\n",
      "Epoch 111 | train_loss(step) = 0.3787 | train_loss(eval) = 0.3734 | train_mean_auc = 0.7851 | val_mean_auc = 0.7839\n",
      "  train AUC per head: h0: 0.7688 | h1: 0.7572 | h2: 0.7682 | h3: 0.8460\n",
      "  val   AUC per head: h0: 0.7664 | h1: 0.7555 | h2: 0.7694 | h3: 0.8445\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7664', '0.7555', '0.7694', '0.8445']\n",
      "  [EdgeMLP] best mean val AUC = 0.7839\n",
      "Epoch 112 | train_loss(step) = 0.3739 | train_loss(eval) = 0.3731 | train_mean_auc = 0.7854 | val_mean_auc = 0.7842\n",
      "  train AUC per head: h0: 0.7694 | h1: 0.7575 | h2: 0.7684 | h3: 0.8464\n",
      "  val   AUC per head: h0: 0.7670 | h1: 0.7556 | h2: 0.7695 | h3: 0.8449\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7670', '0.7556', '0.7695', '0.8449']\n",
      "  [EdgeMLP] best mean val AUC = 0.7842\n",
      "Epoch 113 | train_loss(step) = 0.3784 | train_loss(eval) = 0.3729 | train_mean_auc = 0.7857 | val_mean_auc = 0.7845\n",
      "  train AUC per head: h0: 0.7699 | h1: 0.7577 | h2: 0.7686 | h3: 0.8467\n",
      "  val   AUC per head: h0: 0.7675 | h1: 0.7558 | h2: 0.7696 | h3: 0.8451\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7675', '0.7558', '0.7696', '0.8451']\n",
      "  [EdgeMLP] best mean val AUC = 0.7845\n",
      "Epoch 114 | train_loss(step) = 0.3759 | train_loss(eval) = 0.3727 | train_mean_auc = 0.7860 | val_mean_auc = 0.7847\n",
      "  train AUC per head: h0: 0.7705 | h1: 0.7579 | h2: 0.7686 | h3: 0.8469\n",
      "  val   AUC per head: h0: 0.7680 | h1: 0.7560 | h2: 0.7696 | h3: 0.8453\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7680', '0.7560', '0.7696', '0.8453']\n",
      "  [EdgeMLP] best mean val AUC = 0.7847\n",
      "Epoch 115 | train_loss(step) = 0.3677 | train_loss(eval) = 0.3724 | train_mean_auc = 0.7863 | val_mean_auc = 0.7850\n",
      "  train AUC per head: h0: 0.7711 | h1: 0.7581 | h2: 0.7687 | h3: 0.8471\n",
      "  val   AUC per head: h0: 0.7686 | h1: 0.7562 | h2: 0.7696 | h3: 0.8456\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7686', '0.7562', '0.7696', '0.8456']\n",
      "  [EdgeMLP] best mean val AUC = 0.7850\n",
      "Epoch 116 | train_loss(step) = 0.3784 | train_loss(eval) = 0.3722 | train_mean_auc = 0.7865 | val_mean_auc = 0.7852\n",
      "  train AUC per head: h0: 0.7717 | h1: 0.7583 | h2: 0.7690 | h3: 0.8472\n",
      "  val   AUC per head: h0: 0.7692 | h1: 0.7563 | h2: 0.7698 | h3: 0.8457\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7692', '0.7563', '0.7698', '0.8457']\n",
      "  [EdgeMLP] best mean val AUC = 0.7852\n",
      "Epoch 117 | train_loss(step) = 0.3796 | train_loss(eval) = 0.3720 | train_mean_auc = 0.7869 | val_mean_auc = 0.7856\n",
      "  train AUC per head: h0: 0.7724 | h1: 0.7585 | h2: 0.7693 | h3: 0.8472\n",
      "  val   AUC per head: h0: 0.7699 | h1: 0.7565 | h2: 0.7701 | h3: 0.8457\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7699', '0.7565', '0.7701', '0.8457']\n",
      "  [EdgeMLP] best mean val AUC = 0.7856\n",
      "Epoch 118 | train_loss(step) = 0.3755 | train_loss(eval) = 0.3718 | train_mean_auc = 0.7872 | val_mean_auc = 0.7859\n",
      "  train AUC per head: h0: 0.7730 | h1: 0.7586 | h2: 0.7697 | h3: 0.8473\n",
      "  val   AUC per head: h0: 0.7704 | h1: 0.7567 | h2: 0.7705 | h3: 0.8458\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7704', '0.7567', '0.7705', '0.8458']\n",
      "  [EdgeMLP] best mean val AUC = 0.7859\n",
      "Epoch 119 | train_loss(step) = 0.3748 | train_loss(eval) = 0.3716 | train_mean_auc = 0.7875 | val_mean_auc = 0.7862\n",
      "  train AUC per head: h0: 0.7736 | h1: 0.7588 | h2: 0.7702 | h3: 0.8475\n",
      "  val   AUC per head: h0: 0.7710 | h1: 0.7569 | h2: 0.7710 | h3: 0.8460\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7710', '0.7569', '0.7710', '0.8460']\n",
      "  [EdgeMLP] best mean val AUC = 0.7862\n",
      "Epoch 120 | train_loss(step) = 0.3713 | train_loss(eval) = 0.3713 | train_mean_auc = 0.7878 | val_mean_auc = 0.7865\n",
      "  train AUC per head: h0: 0.7740 | h1: 0.7589 | h2: 0.7706 | h3: 0.8476\n",
      "  val   AUC per head: h0: 0.7714 | h1: 0.7570 | h2: 0.7715 | h3: 0.8460\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7714', '0.7570', '0.7715', '0.8460']\n",
      "  [EdgeMLP] best mean val AUC = 0.7865\n",
      "Epoch 121 | train_loss(step) = 0.3697 | train_loss(eval) = 0.3711 | train_mean_auc = 0.7881 | val_mean_auc = 0.7868\n",
      "  train AUC per head: h0: 0.7745 | h1: 0.7590 | h2: 0.7710 | h3: 0.8478\n",
      "  val   AUC per head: h0: 0.7718 | h1: 0.7572 | h2: 0.7719 | h3: 0.8462\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7718', '0.7572', '0.7719', '0.8462']\n",
      "  [EdgeMLP] best mean val AUC = 0.7868\n",
      "Epoch 122 | train_loss(step) = 0.3838 | train_loss(eval) = 0.3709 | train_mean_auc = 0.7884 | val_mean_auc = 0.7871\n",
      "  train AUC per head: h0: 0.7749 | h1: 0.7592 | h2: 0.7715 | h3: 0.8480\n",
      "  val   AUC per head: h0: 0.7723 | h1: 0.7573 | h2: 0.7723 | h3: 0.8464\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7723', '0.7573', '0.7723', '0.8464']\n",
      "  [EdgeMLP] best mean val AUC = 0.7871\n",
      "Epoch 123 | train_loss(step) = 0.3741 | train_loss(eval) = 0.3707 | train_mean_auc = 0.7887 | val_mean_auc = 0.7874\n",
      "  train AUC per head: h0: 0.7753 | h1: 0.7593 | h2: 0.7718 | h3: 0.8483\n",
      "  val   AUC per head: h0: 0.7727 | h1: 0.7576 | h2: 0.7728 | h3: 0.8466\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7727', '0.7576', '0.7728', '0.8466']\n",
      "  [EdgeMLP] best mean val AUC = 0.7874\n",
      "Epoch 124 | train_loss(step) = 0.3695 | train_loss(eval) = 0.3705 | train_mean_auc = 0.7890 | val_mean_auc = 0.7878\n",
      "  train AUC per head: h0: 0.7758 | h1: 0.7595 | h2: 0.7722 | h3: 0.8486\n",
      "  val   AUC per head: h0: 0.7733 | h1: 0.7577 | h2: 0.7731 | h3: 0.8470\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7733', '0.7577', '0.7731', '0.8470']\n",
      "  [EdgeMLP] best mean val AUC = 0.7878\n",
      "Epoch 125 | train_loss(step) = 0.3686 | train_loss(eval) = 0.3702 | train_mean_auc = 0.7894 | val_mean_auc = 0.7881\n",
      "  train AUC per head: h0: 0.7765 | h1: 0.7596 | h2: 0.7725 | h3: 0.8489\n",
      "  val   AUC per head: h0: 0.7739 | h1: 0.7579 | h2: 0.7735 | h3: 0.8472\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7739', '0.7579', '0.7735', '0.8472']\n",
      "  [EdgeMLP] best mean val AUC = 0.7881\n",
      "Epoch 126 | train_loss(step) = 0.3569 | train_loss(eval) = 0.3699 | train_mean_auc = 0.7897 | val_mean_auc = 0.7884\n",
      "  train AUC per head: h0: 0.7772 | h1: 0.7597 | h2: 0.7727 | h3: 0.8490\n",
      "  val   AUC per head: h0: 0.7746 | h1: 0.7580 | h2: 0.7737 | h3: 0.8474\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7746', '0.7580', '0.7737', '0.8474']\n",
      "  [EdgeMLP] best mean val AUC = 0.7884\n",
      "Epoch 127 | train_loss(step) = 0.3734 | train_loss(eval) = 0.3697 | train_mean_auc = 0.7900 | val_mean_auc = 0.7887\n",
      "  train AUC per head: h0: 0.7779 | h1: 0.7599 | h2: 0.7729 | h3: 0.8491\n",
      "  val   AUC per head: h0: 0.7753 | h1: 0.7582 | h2: 0.7739 | h3: 0.8475\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7753', '0.7582', '0.7739', '0.8475']\n",
      "  [EdgeMLP] best mean val AUC = 0.7887\n",
      "Epoch 128 | train_loss(step) = 0.3693 | train_loss(eval) = 0.3695 | train_mean_auc = 0.7902 | val_mean_auc = 0.7890\n",
      "  train AUC per head: h0: 0.7785 | h1: 0.7602 | h2: 0.7731 | h3: 0.8491\n",
      "  val   AUC per head: h0: 0.7759 | h1: 0.7584 | h2: 0.7741 | h3: 0.8475\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7759', '0.7584', '0.7741', '0.8475']\n",
      "  [EdgeMLP] best mean val AUC = 0.7890\n",
      "Epoch 129 | train_loss(step) = 0.3684 | train_loss(eval) = 0.3693 | train_mean_auc = 0.7905 | val_mean_auc = 0.7893\n",
      "  train AUC per head: h0: 0.7791 | h1: 0.7605 | h2: 0.7733 | h3: 0.8490\n",
      "  val   AUC per head: h0: 0.7765 | h1: 0.7588 | h2: 0.7744 | h3: 0.8474\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7765', '0.7588', '0.7744', '0.8475']\n",
      "  [EdgeMLP] best mean val AUC = 0.7893\n",
      "Epoch 130 | train_loss(step) = 0.3618 | train_loss(eval) = 0.3691 | train_mean_auc = 0.7908 | val_mean_auc = 0.7896\n",
      "  train AUC per head: h0: 0.7796 | h1: 0.7608 | h2: 0.7736 | h3: 0.8490\n",
      "  val   AUC per head: h0: 0.7771 | h1: 0.7591 | h2: 0.7747 | h3: 0.8474\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7771', '0.7591', '0.7747', '0.8475']\n",
      "  [EdgeMLP] best mean val AUC = 0.7896\n",
      "Epoch 131 | train_loss(step) = 0.3803 | train_loss(eval) = 0.3688 | train_mean_auc = 0.7911 | val_mean_auc = 0.7899\n",
      "  train AUC per head: h0: 0.7802 | h1: 0.7610 | h2: 0.7740 | h3: 0.8491\n",
      "  val   AUC per head: h0: 0.7777 | h1: 0.7593 | h2: 0.7751 | h3: 0.8476\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7777', '0.7593', '0.7751', '0.8476']\n",
      "  [EdgeMLP] best mean val AUC = 0.7899\n",
      "Epoch 132 | train_loss(step) = 0.3702 | train_loss(eval) = 0.3686 | train_mean_auc = 0.7914 | val_mean_auc = 0.7903\n",
      "  train AUC per head: h0: 0.7808 | h1: 0.7611 | h2: 0.7744 | h3: 0.8492\n",
      "  val   AUC per head: h0: 0.7784 | h1: 0.7595 | h2: 0.7756 | h3: 0.8477\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7784', '0.7595', '0.7756', '0.8477']\n",
      "  [EdgeMLP] best mean val AUC = 0.7903\n",
      "Epoch 133 | train_loss(step) = 0.3672 | train_loss(eval) = 0.3684 | train_mean_auc = 0.7917 | val_mean_auc = 0.7906\n",
      "  train AUC per head: h0: 0.7814 | h1: 0.7613 | h2: 0.7749 | h3: 0.8492\n",
      "  val   AUC per head: h0: 0.7790 | h1: 0.7597 | h2: 0.7761 | h3: 0.8477\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7790', '0.7597', '0.7761', '0.8477']\n",
      "  [EdgeMLP] best mean val AUC = 0.7906\n",
      "Epoch 134 | train_loss(step) = 0.3727 | train_loss(eval) = 0.3682 | train_mean_auc = 0.7920 | val_mean_auc = 0.7910\n",
      "  train AUC per head: h0: 0.7819 | h1: 0.7615 | h2: 0.7753 | h3: 0.8494\n",
      "  val   AUC per head: h0: 0.7795 | h1: 0.7599 | h2: 0.7766 | h3: 0.8479\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7795', '0.7599', '0.7766', '0.8479']\n",
      "  [EdgeMLP] best mean val AUC = 0.7910\n",
      "Epoch 135 | train_loss(step) = 0.3745 | train_loss(eval) = 0.3681 | train_mean_auc = 0.7923 | val_mean_auc = 0.7913\n",
      "  train AUC per head: h0: 0.7823 | h1: 0.7617 | h2: 0.7758 | h3: 0.8495\n",
      "  val   AUC per head: h0: 0.7800 | h1: 0.7602 | h2: 0.7771 | h3: 0.8480\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7800', '0.7602', '0.7771', '0.8480']\n",
      "  [EdgeMLP] best mean val AUC = 0.7913\n",
      "Epoch 136 | train_loss(step) = 0.3658 | train_loss(eval) = 0.3680 | train_mean_auc = 0.7926 | val_mean_auc = 0.7916\n",
      "  train AUC per head: h0: 0.7828 | h1: 0.7619 | h2: 0.7762 | h3: 0.8496\n",
      "  val   AUC per head: h0: 0.7805 | h1: 0.7604 | h2: 0.7775 | h3: 0.8481\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7805', '0.7604', '0.7775', '0.8481']\n",
      "  [EdgeMLP] best mean val AUC = 0.7916\n",
      "Epoch 137 | train_loss(step) = 0.3670 | train_loss(eval) = 0.3677 | train_mean_auc = 0.7929 | val_mean_auc = 0.7919\n",
      "  train AUC per head: h0: 0.7833 | h1: 0.7620 | h2: 0.7765 | h3: 0.8497\n",
      "  val   AUC per head: h0: 0.7810 | h1: 0.7605 | h2: 0.7779 | h3: 0.8482\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7810', '0.7605', '0.7779', '0.8482']\n",
      "  [EdgeMLP] best mean val AUC = 0.7919\n",
      "Epoch 138 | train_loss(step) = 0.3623 | train_loss(eval) = 0.3675 | train_mean_auc = 0.7932 | val_mean_auc = 0.7922\n",
      "  train AUC per head: h0: 0.7840 | h1: 0.7621 | h2: 0.7768 | h3: 0.8498\n",
      "  val   AUC per head: h0: 0.7817 | h1: 0.7605 | h2: 0.7782 | h3: 0.8482\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7817', '0.7605', '0.7782', '0.8482']\n",
      "  [EdgeMLP] best mean val AUC = 0.7922\n",
      "Epoch 139 | train_loss(step) = 0.3655 | train_loss(eval) = 0.3672 | train_mean_auc = 0.7935 | val_mean_auc = 0.7924\n",
      "  train AUC per head: h0: 0.7848 | h1: 0.7621 | h2: 0.7771 | h3: 0.8500\n",
      "  val   AUC per head: h0: 0.7824 | h1: 0.7604 | h2: 0.7785 | h3: 0.8484\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7824', '0.7605', '0.7785', '0.8484']\n",
      "  [EdgeMLP] best mean val AUC = 0.7924\n",
      "Epoch 140 | train_loss(step) = 0.3606 | train_loss(eval) = 0.3671 | train_mean_auc = 0.7938 | val_mean_auc = 0.7927\n",
      "  train AUC per head: h0: 0.7856 | h1: 0.7620 | h2: 0.7775 | h3: 0.8502\n",
      "  val   AUC per head: h0: 0.7832 | h1: 0.7604 | h2: 0.7788 | h3: 0.8485\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7832', '0.7605', '0.7788', '0.8485']\n",
      "  [EdgeMLP] best mean val AUC = 0.7927\n",
      "Epoch 141 | train_loss(step) = 0.3652 | train_loss(eval) = 0.3670 | train_mean_auc = 0.7942 | val_mean_auc = 0.7931\n",
      "  train AUC per head: h0: 0.7864 | h1: 0.7622 | h2: 0.7778 | h3: 0.8504\n",
      "  val   AUC per head: h0: 0.7840 | h1: 0.7605 | h2: 0.7792 | h3: 0.8487\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7840', '0.7605', '0.7792', '0.8487']\n",
      "  [EdgeMLP] best mean val AUC = 0.7931\n",
      "Epoch 142 | train_loss(step) = 0.3679 | train_loss(eval) = 0.3666 | train_mean_auc = 0.7947 | val_mean_auc = 0.7935\n",
      "  train AUC per head: h0: 0.7872 | h1: 0.7627 | h2: 0.7782 | h3: 0.8505\n",
      "  val   AUC per head: h0: 0.7848 | h1: 0.7610 | h2: 0.7795 | h3: 0.8488\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7848', '0.7610', '0.7795', '0.8488']\n",
      "  [EdgeMLP] best mean val AUC = 0.7935\n",
      "Epoch 143 | train_loss(step) = 0.3688 | train_loss(eval) = 0.3662 | train_mean_auc = 0.7951 | val_mean_auc = 0.7940\n",
      "  train AUC per head: h0: 0.7880 | h1: 0.7632 | h2: 0.7787 | h3: 0.8507\n",
      "  val   AUC per head: h0: 0.7855 | h1: 0.7614 | h2: 0.7800 | h3: 0.8490\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7855', '0.7614', '0.7800', '0.8490']\n",
      "  [EdgeMLP] best mean val AUC = 0.7940\n",
      "Epoch 144 | train_loss(step) = 0.3684 | train_loss(eval) = 0.3659 | train_mean_auc = 0.7956 | val_mean_auc = 0.7944\n",
      "  train AUC per head: h0: 0.7887 | h1: 0.7638 | h2: 0.7791 | h3: 0.8508\n",
      "  val   AUC per head: h0: 0.7862 | h1: 0.7620 | h2: 0.7804 | h3: 0.8490\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7862', '0.7620', '0.7804', '0.8490']\n",
      "  [EdgeMLP] best mean val AUC = 0.7944\n",
      "Epoch 145 | train_loss(step) = 0.3663 | train_loss(eval) = 0.3658 | train_mean_auc = 0.7960 | val_mean_auc = 0.7948\n",
      "  train AUC per head: h0: 0.7892 | h1: 0.7642 | h2: 0.7795 | h3: 0.8509\n",
      "  val   AUC per head: h0: 0.7867 | h1: 0.7624 | h2: 0.7808 | h3: 0.8491\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7867', '0.7624', '0.7808', '0.8491']\n",
      "  [EdgeMLP] best mean val AUC = 0.7948\n",
      "Epoch 146 | train_loss(step) = 0.3674 | train_loss(eval) = 0.3657 | train_mean_auc = 0.7963 | val_mean_auc = 0.7951\n",
      "  train AUC per head: h0: 0.7898 | h1: 0.7646 | h2: 0.7799 | h3: 0.8510\n",
      "  val   AUC per head: h0: 0.7873 | h1: 0.7627 | h2: 0.7811 | h3: 0.8492\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7873', '0.7627', '0.7811', '0.8492']\n",
      "  [EdgeMLP] best mean val AUC = 0.7951\n",
      "Epoch 147 | train_loss(step) = 0.3604 | train_loss(eval) = 0.3654 | train_mean_auc = 0.7967 | val_mean_auc = 0.7954\n",
      "  train AUC per head: h0: 0.7905 | h1: 0.7648 | h2: 0.7802 | h3: 0.8512\n",
      "  val   AUC per head: h0: 0.7879 | h1: 0.7629 | h2: 0.7815 | h3: 0.8494\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7879', '0.7629', '0.7815', '0.8494']\n",
      "  [EdgeMLP] best mean val AUC = 0.7954\n",
      "Epoch 148 | train_loss(step) = 0.3676 | train_loss(eval) = 0.3650 | train_mean_auc = 0.7970 | val_mean_auc = 0.7958\n",
      "  train AUC per head: h0: 0.7912 | h1: 0.7650 | h2: 0.7806 | h3: 0.8513\n",
      "  val   AUC per head: h0: 0.7886 | h1: 0.7631 | h2: 0.7819 | h3: 0.8495\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7886', '0.7631', '0.7819', '0.8495']\n",
      "  [EdgeMLP] best mean val AUC = 0.7958\n",
      "Epoch 149 | train_loss(step) = 0.3614 | train_loss(eval) = 0.3648 | train_mean_auc = 0.7974 | val_mean_auc = 0.7960\n",
      "  train AUC per head: h0: 0.7919 | h1: 0.7650 | h2: 0.7810 | h3: 0.8515\n",
      "  val   AUC per head: h0: 0.7891 | h1: 0.7631 | h2: 0.7823 | h3: 0.8496\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7891', '0.7631', '0.7823', '0.8496']\n",
      "  [EdgeMLP] best mean val AUC = 0.7960\n",
      "Epoch 150 | train_loss(step) = 0.3684 | train_loss(eval) = 0.3647 | train_mean_auc = 0.7976 | val_mean_auc = 0.7963\n",
      "  train AUC per head: h0: 0.7925 | h1: 0.7650 | h2: 0.7814 | h3: 0.8515\n",
      "  val   AUC per head: h0: 0.7896 | h1: 0.7631 | h2: 0.7827 | h3: 0.8497\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7896', '0.7631', '0.7827', '0.8497']\n",
      "  [EdgeMLP] best mean val AUC = 0.7963\n",
      "Epoch 151 | train_loss(step) = 0.3608 | train_loss(eval) = 0.3646 | train_mean_auc = 0.7978 | val_mean_auc = 0.7965\n",
      "  train AUC per head: h0: 0.7929 | h1: 0.7649 | h2: 0.7817 | h3: 0.8517\n",
      "  val   AUC per head: h0: 0.7900 | h1: 0.7630 | h2: 0.7831 | h3: 0.8499\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7900', '0.7631', '0.7831', '0.8499']\n",
      "  [EdgeMLP] best mean val AUC = 0.7965\n",
      "Epoch 152 | train_loss(step) = 0.3734 | train_loss(eval) = 0.3643 | train_mean_auc = 0.7981 | val_mean_auc = 0.7968\n",
      "  train AUC per head: h0: 0.7935 | h1: 0.7651 | h2: 0.7822 | h3: 0.8517\n",
      "  val   AUC per head: h0: 0.7905 | h1: 0.7632 | h2: 0.7835 | h3: 0.8499\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7905', '0.7632', '0.7835', '0.8499']\n",
      "  [EdgeMLP] best mean val AUC = 0.7968\n",
      "Epoch 153 | train_loss(step) = 0.3707 | train_loss(eval) = 0.3640 | train_mean_auc = 0.7985 | val_mean_auc = 0.7971\n",
      "  train AUC per head: h0: 0.7940 | h1: 0.7656 | h2: 0.7827 | h3: 0.8516\n",
      "  val   AUC per head: h0: 0.7911 | h1: 0.7637 | h2: 0.7840 | h3: 0.8498\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7911', '0.7637', '0.7840', '0.8499']\n",
      "  [EdgeMLP] best mean val AUC = 0.7971\n",
      "Epoch 154 | train_loss(step) = 0.3642 | train_loss(eval) = 0.3640 | train_mean_auc = 0.7988 | val_mean_auc = 0.7975\n",
      "  train AUC per head: h0: 0.7945 | h1: 0.7662 | h2: 0.7832 | h3: 0.8514\n",
      "  val   AUC per head: h0: 0.7915 | h1: 0.7642 | h2: 0.7845 | h3: 0.8496\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7915', '0.7642', '0.7845', '0.8499']\n",
      "  [EdgeMLP] best mean val AUC = 0.7975\n",
      "Epoch 155 | train_loss(step) = 0.3632 | train_loss(eval) = 0.3640 | train_mean_auc = 0.7991 | val_mean_auc = 0.7978\n",
      "  train AUC per head: h0: 0.7950 | h1: 0.7666 | h2: 0.7837 | h3: 0.8512\n",
      "  val   AUC per head: h0: 0.7920 | h1: 0.7647 | h2: 0.7849 | h3: 0.8494\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7920', '0.7647', '0.7849', '0.8499']\n",
      "  [EdgeMLP] best mean val AUC = 0.7978\n",
      "Epoch 156 | train_loss(step) = 0.3660 | train_loss(eval) = 0.3636 | train_mean_auc = 0.7996 | val_mean_auc = 0.7981\n",
      "  train AUC per head: h0: 0.7957 | h1: 0.7670 | h2: 0.7841 | h3: 0.8514\n",
      "  val   AUC per head: h0: 0.7926 | h1: 0.7651 | h2: 0.7853 | h3: 0.8495\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7926', '0.7651', '0.7853', '0.8499']\n",
      "  [EdgeMLP] best mean val AUC = 0.7981\n",
      "Epoch 157 | train_loss(step) = 0.3509 | train_loss(eval) = 0.3631 | train_mean_auc = 0.7999 | val_mean_auc = 0.7985\n",
      "  train AUC per head: h0: 0.7964 | h1: 0.7671 | h2: 0.7845 | h3: 0.8517\n",
      "  val   AUC per head: h0: 0.7932 | h1: 0.7652 | h2: 0.7858 | h3: 0.8499\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7932', '0.7652', '0.7858', '0.8499']\n",
      "  [EdgeMLP] best mean val AUC = 0.7985\n",
      "Epoch 158 | train_loss(step) = 0.3557 | train_loss(eval) = 0.3629 | train_mean_auc = 0.8003 | val_mean_auc = 0.7988\n",
      "  train AUC per head: h0: 0.7969 | h1: 0.7671 | h2: 0.7849 | h3: 0.8522\n",
      "  val   AUC per head: h0: 0.7937 | h1: 0.7651 | h2: 0.7861 | h3: 0.8503\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7937', '0.7652', '0.7861', '0.8503']\n",
      "  [EdgeMLP] best mean val AUC = 0.7988\n",
      "Epoch 159 | train_loss(step) = 0.3652 | train_loss(eval) = 0.3630 | train_mean_auc = 0.8006 | val_mean_auc = 0.7991\n",
      "  train AUC per head: h0: 0.7976 | h1: 0.7671 | h2: 0.7853 | h3: 0.8525\n",
      "  val   AUC per head: h0: 0.7944 | h1: 0.7651 | h2: 0.7865 | h3: 0.8506\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7944', '0.7652', '0.7865', '0.8506']\n",
      "  [EdgeMLP] best mean val AUC = 0.7991\n",
      "Epoch 160 | train_loss(step) = 0.3611 | train_loss(eval) = 0.3627 | train_mean_auc = 0.8010 | val_mean_auc = 0.7995\n",
      "  train AUC per head: h0: 0.7984 | h1: 0.7672 | h2: 0.7858 | h3: 0.8527\n",
      "  val   AUC per head: h0: 0.7952 | h1: 0.7651 | h2: 0.7870 | h3: 0.8508\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7952', '0.7652', '0.7870', '0.8508']\n",
      "  [EdgeMLP] best mean val AUC = 0.7995\n",
      "Epoch 161 | train_loss(step) = 0.3569 | train_loss(eval) = 0.3624 | train_mean_auc = 0.8014 | val_mean_auc = 0.7999\n",
      "  train AUC per head: h0: 0.7991 | h1: 0.7674 | h2: 0.7862 | h3: 0.8527\n",
      "  val   AUC per head: h0: 0.7959 | h1: 0.7654 | h2: 0.7875 | h3: 0.8508\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7959', '0.7654', '0.7875', '0.8508']\n",
      "  [EdgeMLP] best mean val AUC = 0.7999\n",
      "Epoch 162 | train_loss(step) = 0.3632 | train_loss(eval) = 0.3620 | train_mean_auc = 0.8017 | val_mean_auc = 0.8003\n",
      "  train AUC per head: h0: 0.7997 | h1: 0.7678 | h2: 0.7868 | h3: 0.8527\n",
      "  val   AUC per head: h0: 0.7966 | h1: 0.7658 | h2: 0.7881 | h3: 0.8507\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7966', '0.7658', '0.7881', '0.8508']\n",
      "  [EdgeMLP] best mean val AUC = 0.8003\n",
      "Epoch 163 | train_loss(step) = 0.3600 | train_loss(eval) = 0.3618 | train_mean_auc = 0.8020 | val_mean_auc = 0.8007\n",
      "  train AUC per head: h0: 0.8001 | h1: 0.7682 | h2: 0.7873 | h3: 0.8525\n",
      "  val   AUC per head: h0: 0.7971 | h1: 0.7663 | h2: 0.7886 | h3: 0.8506\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7971', '0.7663', '0.7886', '0.8508']\n",
      "  [EdgeMLP] best mean val AUC = 0.8007\n",
      "Epoch 164 | train_loss(step) = 0.3679 | train_loss(eval) = 0.3618 | train_mean_auc = 0.8023 | val_mean_auc = 0.8010\n",
      "  train AUC per head: h0: 0.8004 | h1: 0.7688 | h2: 0.7878 | h3: 0.8523\n",
      "  val   AUC per head: h0: 0.7975 | h1: 0.7669 | h2: 0.7892 | h3: 0.8504\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7975', '0.7669', '0.7892', '0.8508']\n",
      "  [EdgeMLP] best mean val AUC = 0.8010\n",
      "Epoch 165 | train_loss(step) = 0.3625 | train_loss(eval) = 0.3618 | train_mean_auc = 0.8026 | val_mean_auc = 0.8013\n",
      "  train AUC per head: h0: 0.8008 | h1: 0.7692 | h2: 0.7883 | h3: 0.8520\n",
      "  val   AUC per head: h0: 0.7979 | h1: 0.7674 | h2: 0.7898 | h3: 0.8501\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7979', '0.7674', '0.7898', '0.8508']\n",
      "  [EdgeMLP] best mean val AUC = 0.8013\n",
      "Epoch 166 | train_loss(step) = 0.3597 | train_loss(eval) = 0.3614 | train_mean_auc = 0.8030 | val_mean_auc = 0.8017\n",
      "  train AUC per head: h0: 0.8015 | h1: 0.7696 | h2: 0.7888 | h3: 0.8520\n",
      "  val   AUC per head: h0: 0.7986 | h1: 0.7678 | h2: 0.7903 | h3: 0.8501\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7986', '0.7678', '0.7903', '0.8508']\n",
      "  [EdgeMLP] best mean val AUC = 0.8017\n",
      "Epoch 167 | train_loss(step) = 0.3638 | train_loss(eval) = 0.3611 | train_mean_auc = 0.8033 | val_mean_auc = 0.8021\n",
      "  train AUC per head: h0: 0.8021 | h1: 0.7698 | h2: 0.7893 | h3: 0.8521\n",
      "  val   AUC per head: h0: 0.7992 | h1: 0.7681 | h2: 0.7909 | h3: 0.8502\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7992', '0.7681', '0.7909', '0.8508']\n",
      "  [EdgeMLP] best mean val AUC = 0.8021\n",
      "Epoch 168 | train_loss(step) = 0.3542 | train_loss(eval) = 0.3610 | train_mean_auc = 0.8036 | val_mean_auc = 0.8024\n",
      "  train AUC per head: h0: 0.8024 | h1: 0.7699 | h2: 0.7898 | h3: 0.8523\n",
      "  val   AUC per head: h0: 0.7996 | h1: 0.7682 | h2: 0.7914 | h3: 0.8504\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.7996', '0.7682', '0.7914', '0.8508']\n",
      "  [EdgeMLP] best mean val AUC = 0.8024\n",
      "Epoch 169 | train_loss(step) = 0.3571 | train_loss(eval) = 0.3607 | train_mean_auc = 0.8039 | val_mean_auc = 0.8027\n",
      "  train AUC per head: h0: 0.8029 | h1: 0.7701 | h2: 0.7902 | h3: 0.8525\n",
      "  val   AUC per head: h0: 0.8001 | h1: 0.7684 | h2: 0.7919 | h3: 0.8505\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8001', '0.7684', '0.7919', '0.8508']\n",
      "  [EdgeMLP] best mean val AUC = 0.8027\n",
      "Epoch 170 | train_loss(step) = 0.3562 | train_loss(eval) = 0.3603 | train_mean_auc = 0.8043 | val_mean_auc = 0.8031\n",
      "  train AUC per head: h0: 0.8035 | h1: 0.7700 | h2: 0.7908 | h3: 0.8528\n",
      "  val   AUC per head: h0: 0.8007 | h1: 0.7683 | h2: 0.7924 | h3: 0.8508\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8007', '0.7684', '0.7924', '0.8508']\n",
      "  [EdgeMLP] best mean val AUC = 0.8031\n",
      "Epoch 171 | train_loss(step) = 0.3644 | train_loss(eval) = 0.3600 | train_mean_auc = 0.8047 | val_mean_auc = 0.8035\n",
      "  train AUC per head: h0: 0.8042 | h1: 0.7700 | h2: 0.7913 | h3: 0.8532\n",
      "  val   AUC per head: h0: 0.8014 | h1: 0.7683 | h2: 0.7930 | h3: 0.8512\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8014', '0.7684', '0.7930', '0.8512']\n",
      "  [EdgeMLP] best mean val AUC = 0.8035\n",
      "Epoch 172 | train_loss(step) = 0.3609 | train_loss(eval) = 0.3599 | train_mean_auc = 0.8051 | val_mean_auc = 0.8038\n",
      "  train AUC per head: h0: 0.8048 | h1: 0.7700 | h2: 0.7920 | h3: 0.8535\n",
      "  val   AUC per head: h0: 0.8020 | h1: 0.7683 | h2: 0.7937 | h3: 0.8514\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8020', '0.7684', '0.7937', '0.8514']\n",
      "  [EdgeMLP] best mean val AUC = 0.8038\n",
      "Epoch 173 | train_loss(step) = 0.3627 | train_loss(eval) = 0.3598 | train_mean_auc = 0.8055 | val_mean_auc = 0.8042\n",
      "  train AUC per head: h0: 0.8054 | h1: 0.7702 | h2: 0.7926 | h3: 0.8537\n",
      "  val   AUC per head: h0: 0.8026 | h1: 0.7685 | h2: 0.7942 | h3: 0.8516\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8026', '0.7685', '0.7942', '0.8516']\n",
      "  [EdgeMLP] best mean val AUC = 0.8042\n",
      "Epoch 174 | train_loss(step) = 0.3626 | train_loss(eval) = 0.3595 | train_mean_auc = 0.8059 | val_mean_auc = 0.8046\n",
      "  train AUC per head: h0: 0.8059 | h1: 0.7705 | h2: 0.7932 | h3: 0.8539\n",
      "  val   AUC per head: h0: 0.8030 | h1: 0.7689 | h2: 0.7947 | h3: 0.8517\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8030', '0.7689', '0.7947', '0.8517']\n",
      "  [EdgeMLP] best mean val AUC = 0.8046\n",
      "Epoch 175 | train_loss(step) = 0.3650 | train_loss(eval) = 0.3592 | train_mean_auc = 0.8063 | val_mean_auc = 0.8050\n",
      "  train AUC per head: h0: 0.8064 | h1: 0.7711 | h2: 0.7937 | h3: 0.8540\n",
      "  val   AUC per head: h0: 0.8034 | h1: 0.7695 | h2: 0.7952 | h3: 0.8518\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8034', '0.7695', '0.7952', '0.8518']\n",
      "  [EdgeMLP] best mean val AUC = 0.8050\n",
      "Epoch 176 | train_loss(step) = 0.3673 | train_loss(eval) = 0.3590 | train_mean_auc = 0.8068 | val_mean_auc = 0.8054\n",
      "  train AUC per head: h0: 0.8071 | h1: 0.7717 | h2: 0.7944 | h3: 0.8540\n",
      "  val   AUC per head: h0: 0.8039 | h1: 0.7702 | h2: 0.7958 | h3: 0.8517\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8039', '0.7702', '0.7958', '0.8518']\n",
      "  [EdgeMLP] best mean val AUC = 0.8054\n",
      "Epoch 177 | train_loss(step) = 0.3599 | train_loss(eval) = 0.3589 | train_mean_auc = 0.8072 | val_mean_auc = 0.8057\n",
      "  train AUC per head: h0: 0.8077 | h1: 0.7722 | h2: 0.7949 | h3: 0.8539\n",
      "  val   AUC per head: h0: 0.8044 | h1: 0.7707 | h2: 0.7963 | h3: 0.8516\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8044', '0.7707', '0.7963', '0.8518']\n",
      "  [EdgeMLP] best mean val AUC = 0.8057\n",
      "Epoch 178 | train_loss(step) = 0.3582 | train_loss(eval) = 0.3587 | train_mean_auc = 0.8075 | val_mean_auc = 0.8061\n",
      "  train AUC per head: h0: 0.8084 | h1: 0.7726 | h2: 0.7955 | h3: 0.8538\n",
      "  val   AUC per head: h0: 0.8051 | h1: 0.7711 | h2: 0.7967 | h3: 0.8515\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8051', '0.7711', '0.7967', '0.8518']\n",
      "  [EdgeMLP] best mean val AUC = 0.8061\n",
      "Epoch 179 | train_loss(step) = 0.3649 | train_loss(eval) = 0.3583 | train_mean_auc = 0.8079 | val_mean_auc = 0.8063\n",
      "  train AUC per head: h0: 0.8091 | h1: 0.7728 | h2: 0.7960 | h3: 0.8537\n",
      "  val   AUC per head: h0: 0.8057 | h1: 0.7713 | h2: 0.7971 | h3: 0.8514\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8057', '0.7713', '0.7971', '0.8518']\n",
      "  [EdgeMLP] best mean val AUC = 0.8063\n",
      "Epoch 180 | train_loss(step) = 0.3620 | train_loss(eval) = 0.3580 | train_mean_auc = 0.8082 | val_mean_auc = 0.8066\n",
      "  train AUC per head: h0: 0.8098 | h1: 0.7731 | h2: 0.7965 | h3: 0.8535\n",
      "  val   AUC per head: h0: 0.8063 | h1: 0.7715 | h2: 0.7975 | h3: 0.8513\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8063', '0.7715', '0.7975', '0.8518']\n",
      "  [EdgeMLP] best mean val AUC = 0.8066\n",
      "Epoch 181 | train_loss(step) = 0.3628 | train_loss(eval) = 0.3577 | train_mean_auc = 0.8085 | val_mean_auc = 0.8069\n",
      "  train AUC per head: h0: 0.8104 | h1: 0.7732 | h2: 0.7970 | h3: 0.8535\n",
      "  val   AUC per head: h0: 0.8069 | h1: 0.7716 | h2: 0.7980 | h3: 0.8512\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8069', '0.7716', '0.7980', '0.8518']\n",
      "  [EdgeMLP] best mean val AUC = 0.8069\n",
      "Epoch 182 | train_loss(step) = 0.3538 | train_loss(eval) = 0.3576 | train_mean_auc = 0.8088 | val_mean_auc = 0.8072\n",
      "  train AUC per head: h0: 0.8111 | h1: 0.7732 | h2: 0.7975 | h3: 0.8535\n",
      "  val   AUC per head: h0: 0.8074 | h1: 0.7716 | h2: 0.7985 | h3: 0.8512\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8074', '0.7716', '0.7985', '0.8518']\n",
      "  [EdgeMLP] best mean val AUC = 0.8072\n",
      "Epoch 183 | train_loss(step) = 0.3535 | train_loss(eval) = 0.3574 | train_mean_auc = 0.8091 | val_mean_auc = 0.8074\n",
      "  train AUC per head: h0: 0.8116 | h1: 0.7732 | h2: 0.7981 | h3: 0.8536\n",
      "  val   AUC per head: h0: 0.8079 | h1: 0.7715 | h2: 0.7990 | h3: 0.8514\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8079', '0.7716', '0.7990', '0.8518']\n",
      "  [EdgeMLP] best mean val AUC = 0.8074\n",
      "Epoch 184 | train_loss(step) = 0.3553 | train_loss(eval) = 0.3574 | train_mean_auc = 0.8093 | val_mean_auc = 0.8077\n",
      "  train AUC per head: h0: 0.8118 | h1: 0.7732 | h2: 0.7985 | h3: 0.8538\n",
      "  val   AUC per head: h0: 0.8080 | h1: 0.7716 | h2: 0.7995 | h3: 0.8516\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8080', '0.7716', '0.7995', '0.8518']\n",
      "  [EdgeMLP] best mean val AUC = 0.8077\n",
      "Epoch 185 | train_loss(step) = 0.3561 | train_loss(eval) = 0.3572 | train_mean_auc = 0.8097 | val_mean_auc = 0.8080\n",
      "  train AUC per head: h0: 0.8120 | h1: 0.7736 | h2: 0.7990 | h3: 0.8541\n",
      "  val   AUC per head: h0: 0.8082 | h1: 0.7719 | h2: 0.8000 | h3: 0.8518\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8082', '0.7719', '0.8000', '0.8518']\n",
      "  [EdgeMLP] best mean val AUC = 0.8080\n",
      "Epoch 186 | train_loss(step) = 0.3558 | train_loss(eval) = 0.3568 | train_mean_auc = 0.8101 | val_mean_auc = 0.8084\n",
      "  train AUC per head: h0: 0.8122 | h1: 0.7741 | h2: 0.7996 | h3: 0.8543\n",
      "  val   AUC per head: h0: 0.8084 | h1: 0.7724 | h2: 0.8006 | h3: 0.8521\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8084', '0.7724', '0.8006', '0.8521']\n",
      "  [EdgeMLP] best mean val AUC = 0.8084\n",
      "Epoch 187 | train_loss(step) = 0.3593 | train_loss(eval) = 0.3565 | train_mean_auc = 0.8105 | val_mean_auc = 0.8088\n",
      "  train AUC per head: h0: 0.8127 | h1: 0.7745 | h2: 0.8003 | h3: 0.8545\n",
      "  val   AUC per head: h0: 0.8088 | h1: 0.7729 | h2: 0.8014 | h3: 0.8522\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8088', '0.7729', '0.8014', '0.8522']\n",
      "  [EdgeMLP] best mean val AUC = 0.8088\n",
      "Epoch 188 | train_loss(step) = 0.3586 | train_loss(eval) = 0.3562 | train_mean_auc = 0.8109 | val_mean_auc = 0.8093\n",
      "  train AUC per head: h0: 0.8133 | h1: 0.7749 | h2: 0.8010 | h3: 0.8546\n",
      "  val   AUC per head: h0: 0.8095 | h1: 0.7734 | h2: 0.8022 | h3: 0.8523\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8095', '0.7734', '0.8022', '0.8523']\n",
      "  [EdgeMLP] best mean val AUC = 0.8093\n",
      "Epoch 189 | train_loss(step) = 0.3486 | train_loss(eval) = 0.3561 | train_mean_auc = 0.8114 | val_mean_auc = 0.8098\n",
      "  train AUC per head: h0: 0.8140 | h1: 0.7753 | h2: 0.8017 | h3: 0.8545\n",
      "  val   AUC per head: h0: 0.8103 | h1: 0.7737 | h2: 0.8030 | h3: 0.8522\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8103', '0.7737', '0.8030', '0.8523']\n",
      "  [EdgeMLP] best mean val AUC = 0.8098\n",
      "Epoch 190 | train_loss(step) = 0.3663 | train_loss(eval) = 0.3559 | train_mean_auc = 0.8118 | val_mean_auc = 0.8103\n",
      "  train AUC per head: h0: 0.8147 | h1: 0.7756 | h2: 0.8025 | h3: 0.8545\n",
      "  val   AUC per head: h0: 0.8109 | h1: 0.7741 | h2: 0.8038 | h3: 0.8522\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8109', '0.7741', '0.8038', '0.8523']\n",
      "  [EdgeMLP] best mean val AUC = 0.8103\n",
      "Epoch 191 | train_loss(step) = 0.3611 | train_loss(eval) = 0.3556 | train_mean_auc = 0.8122 | val_mean_auc = 0.8107\n",
      "  train AUC per head: h0: 0.8154 | h1: 0.7759 | h2: 0.8032 | h3: 0.8545\n",
      "  val   AUC per head: h0: 0.8116 | h1: 0.7743 | h2: 0.8046 | h3: 0.8521\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8116', '0.7743', '0.8046', '0.8523']\n",
      "  [EdgeMLP] best mean val AUC = 0.8107\n",
      "Epoch 192 | train_loss(step) = 0.3579 | train_loss(eval) = 0.3554 | train_mean_auc = 0.8126 | val_mean_auc = 0.8110\n",
      "  train AUC per head: h0: 0.8161 | h1: 0.7762 | h2: 0.8039 | h3: 0.8544\n",
      "  val   AUC per head: h0: 0.8122 | h1: 0.7745 | h2: 0.8053 | h3: 0.8521\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8122', '0.7745', '0.8053', '0.8523']\n",
      "  [EdgeMLP] best mean val AUC = 0.8110\n",
      "Epoch 193 | train_loss(step) = 0.3537 | train_loss(eval) = 0.3553 | train_mean_auc = 0.8130 | val_mean_auc = 0.8113\n",
      "  train AUC per head: h0: 0.8166 | h1: 0.7764 | h2: 0.8045 | h3: 0.8544\n",
      "  val   AUC per head: h0: 0.8126 | h1: 0.7747 | h2: 0.8059 | h3: 0.8520\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8126', '0.7747', '0.8059', '0.8523']\n",
      "  [EdgeMLP] best mean val AUC = 0.8113\n",
      "Epoch 194 | train_loss(step) = 0.3542 | train_loss(eval) = 0.3552 | train_mean_auc = 0.8132 | val_mean_auc = 0.8115\n",
      "  train AUC per head: h0: 0.8171 | h1: 0.7765 | h2: 0.8050 | h3: 0.8543\n",
      "  val   AUC per head: h0: 0.8130 | h1: 0.7748 | h2: 0.8064 | h3: 0.8519\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8130', '0.7748', '0.8064', '0.8523']\n",
      "  [EdgeMLP] best mean val AUC = 0.8115\n",
      "Epoch 195 | train_loss(step) = 0.3657 | train_loss(eval) = 0.3549 | train_mean_auc = 0.8135 | val_mean_auc = 0.8118\n",
      "  train AUC per head: h0: 0.8174 | h1: 0.7770 | h2: 0.8055 | h3: 0.8541\n",
      "  val   AUC per head: h0: 0.8133 | h1: 0.7751 | h2: 0.8069 | h3: 0.8517\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8133', '0.7751', '0.8069', '0.8523']\n",
      "  [EdgeMLP] best mean val AUC = 0.8118\n",
      "Epoch 196 | train_loss(step) = 0.3581 | train_loss(eval) = 0.3547 | train_mean_auc = 0.8138 | val_mean_auc = 0.8120\n",
      "  train AUC per head: h0: 0.8177 | h1: 0.7774 | h2: 0.8061 | h3: 0.8538\n",
      "  val   AUC per head: h0: 0.8135 | h1: 0.7756 | h2: 0.8074 | h3: 0.8514\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8135', '0.7756', '0.8074', '0.8523']\n",
      "  [EdgeMLP] best mean val AUC = 0.8120\n",
      "Epoch 197 | train_loss(step) = 0.3560 | train_loss(eval) = 0.3547 | train_mean_auc = 0.8140 | val_mean_auc = 0.8122\n",
      "  train AUC per head: h0: 0.8180 | h1: 0.7778 | h2: 0.8066 | h3: 0.8536\n",
      "  val   AUC per head: h0: 0.8139 | h1: 0.7759 | h2: 0.8078 | h3: 0.8512\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8139', '0.7759', '0.8078', '0.8523']\n",
      "  [EdgeMLP] best mean val AUC = 0.8122\n",
      "Epoch 198 | train_loss(step) = 0.3542 | train_loss(eval) = 0.3544 | train_mean_auc = 0.8143 | val_mean_auc = 0.8124\n",
      "  train AUC per head: h0: 0.8185 | h1: 0.7780 | h2: 0.8070 | h3: 0.8536\n",
      "  val   AUC per head: h0: 0.8144 | h1: 0.7761 | h2: 0.8081 | h3: 0.8512\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8144', '0.7761', '0.8081', '0.8523']\n",
      "  [EdgeMLP] best mean val AUC = 0.8124\n",
      "Epoch 199 | train_loss(step) = 0.3620 | train_loss(eval) = 0.3541 | train_mean_auc = 0.8146 | val_mean_auc = 0.8128\n",
      "  train AUC per head: h0: 0.8191 | h1: 0.7782 | h2: 0.8075 | h3: 0.8536\n",
      "  val   AUC per head: h0: 0.8150 | h1: 0.7763 | h2: 0.8086 | h3: 0.8512\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8150', '0.7763', '0.8086', '0.8523']\n",
      "  [EdgeMLP] best mean val AUC = 0.8128\n",
      "Epoch 200 | train_loss(step) = 0.3472 | train_loss(eval) = 0.3538 | train_mean_auc = 0.8150 | val_mean_auc = 0.8131\n",
      "  train AUC per head: h0: 0.8197 | h1: 0.7784 | h2: 0.8079 | h3: 0.8538\n",
      "  val   AUC per head: h0: 0.8155 | h1: 0.7765 | h2: 0.8091 | h3: 0.8514\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8155', '0.7765', '0.8091', '0.8523']\n",
      "  [EdgeMLP] best mean val AUC = 0.8131\n",
      "Epoch 201 | train_loss(step) = 0.3572 | train_loss(eval) = 0.3535 | train_mean_auc = 0.8152 | val_mean_auc = 0.8134\n",
      "  train AUC per head: h0: 0.8200 | h1: 0.7787 | h2: 0.8083 | h3: 0.8538\n",
      "  val   AUC per head: h0: 0.8159 | h1: 0.7768 | h2: 0.8094 | h3: 0.8514\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8159', '0.7768', '0.8094', '0.8523']\n",
      "  [EdgeMLP] best mean val AUC = 0.8134\n",
      "Epoch 202 | train_loss(step) = 0.3591 | train_loss(eval) = 0.3533 | train_mean_auc = 0.8154 | val_mean_auc = 0.8135\n",
      "  train AUC per head: h0: 0.8201 | h1: 0.7791 | h2: 0.8086 | h3: 0.8538\n",
      "  val   AUC per head: h0: 0.8160 | h1: 0.7771 | h2: 0.8097 | h3: 0.8514\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8160', '0.7771', '0.8097', '0.8523']\n",
      "  [EdgeMLP] best mean val AUC = 0.8135\n",
      "Epoch 203 | train_loss(step) = 0.3592 | train_loss(eval) = 0.3535 | train_mean_auc = 0.8154 | val_mean_auc = 0.8135\n",
      "  train AUC per head: h0: 0.8198 | h1: 0.7794 | h2: 0.8087 | h3: 0.8537\n",
      "  val   AUC per head: h0: 0.8157 | h1: 0.7774 | h2: 0.8098 | h3: 0.8513\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8160', '0.7774', '0.8098', '0.8523']\n",
      "  [EdgeMLP] best mean val AUC = 0.8135\n",
      "Epoch 204 | train_loss(step) = 0.3600 | train_loss(eval) = 0.3535 | train_mean_auc = 0.8155 | val_mean_auc = 0.8136\n",
      "  train AUC per head: h0: 0.8198 | h1: 0.7797 | h2: 0.8089 | h3: 0.8537\n",
      "  val   AUC per head: h0: 0.8156 | h1: 0.7776 | h2: 0.8099 | h3: 0.8513\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8160', '0.7776', '0.8099', '0.8523']\n",
      "  [EdgeMLP] best mean val AUC = 0.8136\n",
      "Epoch 205 | train_loss(step) = 0.3568 | train_loss(eval) = 0.3530 | train_mean_auc = 0.8160 | val_mean_auc = 0.8140\n",
      "  train AUC per head: h0: 0.8206 | h1: 0.7800 | h2: 0.8094 | h3: 0.8540\n",
      "  val   AUC per head: h0: 0.8163 | h1: 0.7779 | h2: 0.8104 | h3: 0.8516\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8163', '0.7779', '0.8104', '0.8523']\n",
      "  [EdgeMLP] best mean val AUC = 0.8140\n",
      "Epoch 206 | train_loss(step) = 0.3532 | train_loss(eval) = 0.3528 | train_mean_auc = 0.8163 | val_mean_auc = 0.8144\n",
      "  train AUC per head: h0: 0.8210 | h1: 0.7802 | h2: 0.8099 | h3: 0.8541\n",
      "  val   AUC per head: h0: 0.8167 | h1: 0.7781 | h2: 0.8109 | h3: 0.8518\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8167', '0.7781', '0.8109', '0.8523']\n",
      "  [EdgeMLP] best mean val AUC = 0.8144\n",
      "Epoch 207 | train_loss(step) = 0.3560 | train_loss(eval) = 0.3526 | train_mean_auc = 0.8167 | val_mean_auc = 0.8148\n",
      "  train AUC per head: h0: 0.8217 | h1: 0.7804 | h2: 0.8104 | h3: 0.8542\n",
      "  val   AUC per head: h0: 0.8174 | h1: 0.7784 | h2: 0.8115 | h3: 0.8519\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8174', '0.7784', '0.8115', '0.8523']\n",
      "  [EdgeMLP] best mean val AUC = 0.8148\n",
      "Epoch 208 | train_loss(step) = 0.3513 | train_loss(eval) = 0.3523 | train_mean_auc = 0.8171 | val_mean_auc = 0.8151\n",
      "  train AUC per head: h0: 0.8224 | h1: 0.7806 | h2: 0.8110 | h3: 0.8543\n",
      "  val   AUC per head: h0: 0.8181 | h1: 0.7785 | h2: 0.8120 | h3: 0.8520\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8181', '0.7785', '0.8120', '0.8523']\n",
      "  [EdgeMLP] best mean val AUC = 0.8151\n",
      "Epoch 209 | train_loss(step) = 0.3461 | train_loss(eval) = 0.3522 | train_mean_auc = 0.8173 | val_mean_auc = 0.8154\n",
      "  train AUC per head: h0: 0.8229 | h1: 0.7806 | h2: 0.8116 | h3: 0.8543\n",
      "  val   AUC per head: h0: 0.8186 | h1: 0.7785 | h2: 0.8125 | h3: 0.8520\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8186', '0.7785', '0.8125', '0.8523']\n",
      "  [EdgeMLP] best mean val AUC = 0.8154\n",
      "Epoch 210 | train_loss(step) = 0.3569 | train_loss(eval) = 0.3521 | train_mean_auc = 0.8177 | val_mean_auc = 0.8157\n",
      "  train AUC per head: h0: 0.8232 | h1: 0.7810 | h2: 0.8121 | h3: 0.8543\n",
      "  val   AUC per head: h0: 0.8190 | h1: 0.7789 | h2: 0.8130 | h3: 0.8519\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8190', '0.7789', '0.8130', '0.8523']\n",
      "  [EdgeMLP] best mean val AUC = 0.8157\n",
      "Epoch 211 | train_loss(step) = 0.3510 | train_loss(eval) = 0.3520 | train_mean_auc = 0.8180 | val_mean_auc = 0.8160\n",
      "  train AUC per head: h0: 0.8235 | h1: 0.7815 | h2: 0.8126 | h3: 0.8542\n",
      "  val   AUC per head: h0: 0.8192 | h1: 0.7795 | h2: 0.8134 | h3: 0.8519\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8192', '0.7795', '0.8134', '0.8523']\n",
      "  [EdgeMLP] best mean val AUC = 0.8160\n",
      "Epoch 212 | train_loss(step) = 0.3511 | train_loss(eval) = 0.3515 | train_mean_auc = 0.8182 | val_mean_auc = 0.8162\n",
      "  train AUC per head: h0: 0.8239 | h1: 0.7818 | h2: 0.8129 | h3: 0.8543\n",
      "  val   AUC per head: h0: 0.8196 | h1: 0.7798 | h2: 0.8136 | h3: 0.8520\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8196', '0.7798', '0.8136', '0.8523']\n",
      "  [EdgeMLP] best mean val AUC = 0.8162\n",
      "Epoch 213 | train_loss(step) = 0.3490 | train_loss(eval) = 0.3514 | train_mean_auc = 0.8184 | val_mean_auc = 0.8164\n",
      "  train AUC per head: h0: 0.8241 | h1: 0.7821 | h2: 0.8130 | h3: 0.8545\n",
      "  val   AUC per head: h0: 0.8197 | h1: 0.7801 | h2: 0.8137 | h3: 0.8522\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8197', '0.7801', '0.8137', '0.8523']\n",
      "  [EdgeMLP] best mean val AUC = 0.8164\n",
      "Epoch 214 | train_loss(step) = 0.3518 | train_loss(eval) = 0.3513 | train_mean_auc = 0.8186 | val_mean_auc = 0.8166\n",
      "  train AUC per head: h0: 0.8243 | h1: 0.7824 | h2: 0.8132 | h3: 0.8546\n",
      "  val   AUC per head: h0: 0.8199 | h1: 0.7804 | h2: 0.8139 | h3: 0.8523\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8199', '0.7804', '0.8139', '0.8523']\n",
      "  [EdgeMLP] best mean val AUC = 0.8166\n",
      "Epoch 215 | train_loss(step) = 0.3515 | train_loss(eval) = 0.3511 | train_mean_auc = 0.8188 | val_mean_auc = 0.8168\n",
      "  train AUC per head: h0: 0.8244 | h1: 0.7827 | h2: 0.8134 | h3: 0.8547\n",
      "  val   AUC per head: h0: 0.8199 | h1: 0.7807 | h2: 0.8141 | h3: 0.8524\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8199', '0.7807', '0.8141', '0.8524']\n",
      "  [EdgeMLP] best mean val AUC = 0.8168\n",
      "Epoch 216 | train_loss(step) = 0.3567 | train_loss(eval) = 0.3509 | train_mean_auc = 0.8191 | val_mean_auc = 0.8170\n",
      "  train AUC per head: h0: 0.8245 | h1: 0.7831 | h2: 0.8137 | h3: 0.8549\n",
      "  val   AUC per head: h0: 0.8201 | h1: 0.7811 | h2: 0.8143 | h3: 0.8526\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8201', '0.7811', '0.8143', '0.8526']\n",
      "  [EdgeMLP] best mean val AUC = 0.8170\n",
      "Epoch 217 | train_loss(step) = 0.3484 | train_loss(eval) = 0.3506 | train_mean_auc = 0.8194 | val_mean_auc = 0.8174\n",
      "  train AUC per head: h0: 0.8248 | h1: 0.7834 | h2: 0.8142 | h3: 0.8551\n",
      "  val   AUC per head: h0: 0.8205 | h1: 0.7814 | h2: 0.8148 | h3: 0.8528\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8205', '0.7814', '0.8148', '0.8528']\n",
      "  [EdgeMLP] best mean val AUC = 0.8174\n",
      "Epoch 218 | train_loss(step) = 0.3539 | train_loss(eval) = 0.3505 | train_mean_auc = 0.8197 | val_mean_auc = 0.8178\n",
      "  train AUC per head: h0: 0.8251 | h1: 0.7835 | h2: 0.8147 | h3: 0.8554\n",
      "  val   AUC per head: h0: 0.8209 | h1: 0.7817 | h2: 0.8154 | h3: 0.8531\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8209', '0.7817', '0.8154', '0.8531']\n",
      "  [EdgeMLP] best mean val AUC = 0.8178\n",
      "Epoch 219 | train_loss(step) = 0.3578 | train_loss(eval) = 0.3505 | train_mean_auc = 0.8199 | val_mean_auc = 0.8180\n",
      "  train AUC per head: h0: 0.8251 | h1: 0.7837 | h2: 0.8152 | h3: 0.8556\n",
      "  val   AUC per head: h0: 0.8210 | h1: 0.7819 | h2: 0.8159 | h3: 0.8533\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8210', '0.7819', '0.8159', '0.8533']\n",
      "  [EdgeMLP] best mean val AUC = 0.8180\n",
      "Epoch 220 | train_loss(step) = 0.3514 | train_loss(eval) = 0.3504 | train_mean_auc = 0.8200 | val_mean_auc = 0.8182\n",
      "  train AUC per head: h0: 0.8250 | h1: 0.7836 | h2: 0.8155 | h3: 0.8558\n",
      "  val   AUC per head: h0: 0.8209 | h1: 0.7819 | h2: 0.8163 | h3: 0.8535\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8210', '0.7819', '0.8163', '0.8535']\n",
      "  [EdgeMLP] best mean val AUC = 0.8182\n",
      "Epoch 221 | train_loss(step) = 0.3486 | train_loss(eval) = 0.3503 | train_mean_auc = 0.8201 | val_mean_auc = 0.8183\n",
      "  train AUC per head: h0: 0.8251 | h1: 0.7836 | h2: 0.8159 | h3: 0.8559\n",
      "  val   AUC per head: h0: 0.8211 | h1: 0.7819 | h2: 0.8168 | h3: 0.8536\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8211', '0.7819', '0.8168', '0.8536']\n",
      "  [EdgeMLP] best mean val AUC = 0.8183\n",
      "Epoch 222 | train_loss(step) = 0.3472 | train_loss(eval) = 0.3502 | train_mean_auc = 0.8203 | val_mean_auc = 0.8185\n",
      "  train AUC per head: h0: 0.8254 | h1: 0.7836 | h2: 0.8163 | h3: 0.8560\n",
      "  val   AUC per head: h0: 0.8212 | h1: 0.7820 | h2: 0.8172 | h3: 0.8537\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8212', '0.7820', '0.8172', '0.8537']\n",
      "  [EdgeMLP] best mean val AUC = 0.8185\n",
      "Epoch 223 | train_loss(step) = 0.3454 | train_loss(eval) = 0.3499 | train_mean_auc = 0.8207 | val_mean_auc = 0.8189\n",
      "  train AUC per head: h0: 0.8258 | h1: 0.7841 | h2: 0.8169 | h3: 0.8559\n",
      "  val   AUC per head: h0: 0.8217 | h1: 0.7824 | h2: 0.8177 | h3: 0.8537\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8217', '0.7824', '0.8177', '0.8537']\n",
      "  [EdgeMLP] best mean val AUC = 0.8189\n",
      "Epoch 224 | train_loss(step) = 0.3548 | train_loss(eval) = 0.3497 | train_mean_auc = 0.8211 | val_mean_auc = 0.8193\n",
      "  train AUC per head: h0: 0.8261 | h1: 0.7849 | h2: 0.8177 | h3: 0.8558\n",
      "  val   AUC per head: h0: 0.8220 | h1: 0.7831 | h2: 0.8183 | h3: 0.8536\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8220', '0.7831', '0.8183', '0.8537']\n",
      "  [EdgeMLP] best mean val AUC = 0.8193\n",
      "Epoch 225 | train_loss(step) = 0.3568 | train_loss(eval) = 0.3497 | train_mean_auc = 0.8214 | val_mean_auc = 0.8194\n",
      "  train AUC per head: h0: 0.8260 | h1: 0.7855 | h2: 0.8182 | h3: 0.8558\n",
      "  val   AUC per head: h0: 0.8218 | h1: 0.7836 | h2: 0.8186 | h3: 0.8536\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8220', '0.7836', '0.8186', '0.8537']\n",
      "  [EdgeMLP] best mean val AUC = 0.8194\n",
      "Epoch 226 | train_loss(step) = 0.3526 | train_loss(eval) = 0.3495 | train_mean_auc = 0.8216 | val_mean_auc = 0.8195\n",
      "  train AUC per head: h0: 0.8264 | h1: 0.7858 | h2: 0.8184 | h3: 0.8559\n",
      "  val   AUC per head: h0: 0.8220 | h1: 0.7837 | h2: 0.8188 | h3: 0.8536\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8220', '0.7837', '0.8188', '0.8537']\n",
      "  [EdgeMLP] best mean val AUC = 0.8195\n",
      "Epoch 227 | train_loss(step) = 0.3509 | train_loss(eval) = 0.3491 | train_mean_auc = 0.8220 | val_mean_auc = 0.8198\n",
      "  train AUC per head: h0: 0.8272 | h1: 0.7860 | h2: 0.8189 | h3: 0.8560\n",
      "  val   AUC per head: h0: 0.8226 | h1: 0.7838 | h2: 0.8192 | h3: 0.8537\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8226', '0.7838', '0.8192', '0.8537']\n",
      "  [EdgeMLP] best mean val AUC = 0.8198\n",
      "Epoch 228 | train_loss(step) = 0.3486 | train_loss(eval) = 0.3491 | train_mean_auc = 0.8223 | val_mean_auc = 0.8201\n",
      "  train AUC per head: h0: 0.8279 | h1: 0.7859 | h2: 0.8194 | h3: 0.8561\n",
      "  val   AUC per head: h0: 0.8231 | h1: 0.7837 | h2: 0.8196 | h3: 0.8538\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8231', '0.7838', '0.8196', '0.8538']\n",
      "  [EdgeMLP] best mean val AUC = 0.8201\n",
      "Epoch 229 | train_loss(step) = 0.3482 | train_loss(eval) = 0.3495 | train_mean_auc = 0.8224 | val_mean_auc = 0.8201\n",
      "  train AUC per head: h0: 0.8279 | h1: 0.7856 | h2: 0.8199 | h3: 0.8562\n",
      "  val   AUC per head: h0: 0.8229 | h1: 0.7833 | h2: 0.8202 | h3: 0.8539\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8231', '0.7838', '0.8202', '0.8539']\n",
      "  [EdgeMLP] best mean val AUC = 0.8201\n",
      "Epoch 230 | train_loss(step) = 0.3498 | train_loss(eval) = 0.3491 | train_mean_auc = 0.8225 | val_mean_auc = 0.8202\n",
      "  train AUC per head: h0: 0.8280 | h1: 0.7856 | h2: 0.8204 | h3: 0.8562\n",
      "  val   AUC per head: h0: 0.8229 | h1: 0.7832 | h2: 0.8207 | h3: 0.8539\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8231', '0.7838', '0.8207', '0.8539']\n",
      "  [EdgeMLP] best mean val AUC = 0.8202\n",
      "Epoch 231 | train_loss(step) = 0.3494 | train_loss(eval) = 0.3488 | train_mean_auc = 0.8227 | val_mean_auc = 0.8204\n",
      "  train AUC per head: h0: 0.8279 | h1: 0.7859 | h2: 0.8209 | h3: 0.8562\n",
      "  val   AUC per head: h0: 0.8229 | h1: 0.7835 | h2: 0.8212 | h3: 0.8538\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8231', '0.7838', '0.8212', '0.8539']\n",
      "  [EdgeMLP] best mean val AUC = 0.8204\n",
      "Epoch 232 | train_loss(step) = 0.3477 | train_loss(eval) = 0.3492 | train_mean_auc = 0.8229 | val_mean_auc = 0.8206\n",
      "  train AUC per head: h0: 0.8276 | h1: 0.7862 | h2: 0.8215 | h3: 0.8562\n",
      "  val   AUC per head: h0: 0.8227 | h1: 0.7839 | h2: 0.8219 | h3: 0.8538\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8231', '0.7839', '0.8219', '0.8539']\n",
      "  [EdgeMLP] best mean val AUC = 0.8206\n",
      "Epoch 233 | train_loss(step) = 0.3441 | train_loss(eval) = 0.3486 | train_mean_auc = 0.8233 | val_mean_auc = 0.8211\n",
      "  train AUC per head: h0: 0.8281 | h1: 0.7868 | h2: 0.8222 | h3: 0.8563\n",
      "  val   AUC per head: h0: 0.8232 | h1: 0.7845 | h2: 0.8226 | h3: 0.8539\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8232', '0.7845', '0.8226', '0.8539']\n",
      "  [EdgeMLP] best mean val AUC = 0.8211\n",
      "Epoch 234 | train_loss(step) = 0.3530 | train_loss(eval) = 0.3481 | train_mean_auc = 0.8239 | val_mean_auc = 0.8216\n",
      "  train AUC per head: h0: 0.8289 | h1: 0.7875 | h2: 0.8228 | h3: 0.8564\n",
      "  val   AUC per head: h0: 0.8241 | h1: 0.7852 | h2: 0.8233 | h3: 0.8539\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8241', '0.7852', '0.8233', '0.8539']\n",
      "  [EdgeMLP] best mean val AUC = 0.8216\n",
      "Epoch 235 | train_loss(step) = 0.3490 | train_loss(eval) = 0.3482 | train_mean_auc = 0.8242 | val_mean_auc = 0.8219\n",
      "  train AUC per head: h0: 0.8291 | h1: 0.7881 | h2: 0.8230 | h3: 0.8565\n",
      "  val   AUC per head: h0: 0.8244 | h1: 0.7859 | h2: 0.8235 | h3: 0.8539\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8244', '0.7859', '0.8235', '0.8539']\n",
      "  [EdgeMLP] best mean val AUC = 0.8219\n",
      "Epoch 236 | train_loss(step) = 0.3430 | train_loss(eval) = 0.3483 | train_mean_auc = 0.8242 | val_mean_auc = 0.8220\n",
      "  train AUC per head: h0: 0.8289 | h1: 0.7884 | h2: 0.8231 | h3: 0.8564\n",
      "  val   AUC per head: h0: 0.8244 | h1: 0.7863 | h2: 0.8236 | h3: 0.8538\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8244', '0.7863', '0.8236', '0.8539']\n",
      "  [EdgeMLP] best mean val AUC = 0.8220\n",
      "Epoch 237 | train_loss(step) = 0.3521 | train_loss(eval) = 0.3482 | train_mean_auc = 0.8242 | val_mean_auc = 0.8220\n",
      "  train AUC per head: h0: 0.8287 | h1: 0.7887 | h2: 0.8232 | h3: 0.8563\n",
      "  val   AUC per head: h0: 0.8243 | h1: 0.7867 | h2: 0.8236 | h3: 0.8536\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8244', '0.7867', '0.8236', '0.8539']\n",
      "  [EdgeMLP] best mean val AUC = 0.8220\n",
      "Epoch 238 | train_loss(step) = 0.3540 | train_loss(eval) = 0.3482 | train_mean_auc = 0.8241 | val_mean_auc = 0.8219\n",
      "  train AUC per head: h0: 0.8281 | h1: 0.7889 | h2: 0.8232 | h3: 0.8561\n",
      "  val   AUC per head: h0: 0.8239 | h1: 0.7869 | h2: 0.8235 | h3: 0.8534\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8244', '0.7869', '0.8236', '0.8539']\n",
      "  [EdgeMLP] best mean val AUC = 0.8220\n",
      "Epoch 239 | train_loss(step) = 0.3364 | train_loss(eval) = 0.3483 | train_mean_auc = 0.8241 | val_mean_auc = 0.8220\n",
      "  train AUC per head: h0: 0.8282 | h1: 0.7892 | h2: 0.8232 | h3: 0.8560\n",
      "  val   AUC per head: h0: 0.8241 | h1: 0.7873 | h2: 0.8235 | h3: 0.8532\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8244', '0.7873', '0.8236', '0.8539']\n",
      "  [EdgeMLP] best mean val AUC = 0.8220\n",
      "Epoch 240 | train_loss(step) = 0.3441 | train_loss(eval) = 0.3476 | train_mean_auc = 0.8245 | val_mean_auc = 0.8224\n",
      "  train AUC per head: h0: 0.8292 | h1: 0.7894 | h2: 0.8233 | h3: 0.8561\n",
      "  val   AUC per head: h0: 0.8250 | h1: 0.7876 | h2: 0.8236 | h3: 0.8533\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8250', '0.7876', '0.8236', '0.8539']\n",
      "  [EdgeMLP] best mean val AUC = 0.8224\n",
      "Epoch 241 | train_loss(step) = 0.3415 | train_loss(eval) = 0.3475 | train_mean_auc = 0.8244 | val_mean_auc = 0.8223\n",
      "  train AUC per head: h0: 0.8290 | h1: 0.7893 | h2: 0.8230 | h3: 0.8563\n",
      "  val   AUC per head: h0: 0.8247 | h1: 0.7875 | h2: 0.8234 | h3: 0.8535\n",
      "  no improvement this epoch. no_improve_heads = [1, 1, 1, 7]\n",
      "Epoch 242 | train_loss(step) = 0.3466 | train_loss(eval) = 0.3477 | train_mean_auc = 0.8241 | val_mean_auc = 0.8220\n",
      "  train AUC per head: h0: 0.8282 | h1: 0.7891 | h2: 0.8226 | h3: 0.8565\n",
      "  val   AUC per head: h0: 0.8239 | h1: 0.7874 | h2: 0.8230 | h3: 0.8537\n",
      "  no improvement this epoch. no_improve_heads = [2, 2, 2, 8]\n",
      "Epoch 243 | train_loss(step) = 0.3372 | train_loss(eval) = 0.3478 | train_mean_auc = 0.8241 | val_mean_auc = 0.8220\n",
      "  train AUC per head: h0: 0.8282 | h1: 0.7891 | h2: 0.8226 | h3: 0.8566\n",
      "  val   AUC per head: h0: 0.8239 | h1: 0.7874 | h2: 0.8230 | h3: 0.8538\n",
      "  no improvement this epoch. no_improve_heads = [3, 3, 3, 9]\n",
      "Epoch 244 | train_loss(step) = 0.3512 | train_loss(eval) = 0.3474 | train_mean_auc = 0.8245 | val_mean_auc = 0.8224\n",
      "  train AUC per head: h0: 0.8290 | h1: 0.7894 | h2: 0.8230 | h3: 0.8565\n",
      "  val   AUC per head: h0: 0.8247 | h1: 0.7877 | h2: 0.8234 | h3: 0.8537\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8250', '0.7877', '0.8236', '0.8539']\n",
      "  [EdgeMLP] best mean val AUC = 0.8224\n",
      "Epoch 245 | train_loss(step) = 0.3516 | train_loss(eval) = 0.3468 | train_mean_auc = 0.8252 | val_mean_auc = 0.8230\n",
      "  train AUC per head: h0: 0.8303 | h1: 0.7902 | h2: 0.8240 | h3: 0.8564\n",
      "  val   AUC per head: h0: 0.8260 | h1: 0.7884 | h2: 0.8242 | h3: 0.8536\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8260', '0.7884', '0.8242', '0.8539']\n",
      "  [EdgeMLP] best mean val AUC = 0.8230\n",
      "Epoch 246 | train_loss(step) = 0.3409 | train_loss(eval) = 0.3466 | train_mean_auc = 0.8256 | val_mean_auc = 0.8234\n",
      "  train AUC per head: h0: 0.8307 | h1: 0.7907 | h2: 0.8246 | h3: 0.8564\n",
      "  val   AUC per head: h0: 0.8264 | h1: 0.7889 | h2: 0.8246 | h3: 0.8536\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8264', '0.7889', '0.8246', '0.8539']\n",
      "  [EdgeMLP] best mean val AUC = 0.8234\n",
      "Epoch 247 | train_loss(step) = 0.3385 | train_loss(eval) = 0.3465 | train_mean_auc = 0.8258 | val_mean_auc = 0.8235\n",
      "  train AUC per head: h0: 0.8307 | h1: 0.7911 | h2: 0.8248 | h3: 0.8564\n",
      "  val   AUC per head: h0: 0.8263 | h1: 0.7892 | h2: 0.8247 | h3: 0.8536\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8264', '0.7892', '0.8247', '0.8539']\n",
      "  [EdgeMLP] best mean val AUC = 0.8235\n",
      "Epoch 248 | train_loss(step) = 0.3466 | train_loss(eval) = 0.3464 | train_mean_auc = 0.8260 | val_mean_auc = 0.8236\n",
      "  train AUC per head: h0: 0.8308 | h1: 0.7914 | h2: 0.8251 | h3: 0.8565\n",
      "  val   AUC per head: h0: 0.8262 | h1: 0.7895 | h2: 0.8248 | h3: 0.8538\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8264', '0.7895', '0.8248', '0.8539']\n",
      "  [EdgeMLP] best mean val AUC = 0.8236\n",
      "Epoch 249 | train_loss(step) = 0.3436 | train_loss(eval) = 0.3464 | train_mean_auc = 0.8262 | val_mean_auc = 0.8237\n",
      "  train AUC per head: h0: 0.8309 | h1: 0.7915 | h2: 0.8255 | h3: 0.8567\n",
      "  val   AUC per head: h0: 0.8262 | h1: 0.7896 | h2: 0.8250 | h3: 0.8540\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8264', '0.7896', '0.8250', '0.8540']\n",
      "  [EdgeMLP] best mean val AUC = 0.8237\n",
      "Epoch 250 | train_loss(step) = 0.3561 | train_loss(eval) = 0.3464 | train_mean_auc = 0.8265 | val_mean_auc = 0.8240\n",
      "  train AUC per head: h0: 0.8312 | h1: 0.7916 | h2: 0.8260 | h3: 0.8570\n",
      "  val   AUC per head: h0: 0.8264 | h1: 0.7897 | h2: 0.8255 | h3: 0.8543\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8264', '0.7897', '0.8255', '0.8543']\n",
      "  [EdgeMLP] best mean val AUC = 0.8240\n",
      "Epoch 251 | train_loss(step) = 0.3456 | train_loss(eval) = 0.3462 | train_mean_auc = 0.8266 | val_mean_auc = 0.8241\n",
      "  train AUC per head: h0: 0.8312 | h1: 0.7918 | h2: 0.8264 | h3: 0.8571\n",
      "  val   AUC per head: h0: 0.8263 | h1: 0.7899 | h2: 0.8258 | h3: 0.8544\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8264', '0.7899', '0.8258', '0.8544']\n",
      "  [EdgeMLP] best mean val AUC = 0.8241\n",
      "Epoch 252 | train_loss(step) = 0.3552 | train_loss(eval) = 0.3460 | train_mean_auc = 0.8268 | val_mean_auc = 0.8243\n",
      "  train AUC per head: h0: 0.8314 | h1: 0.7920 | h2: 0.8267 | h3: 0.8573\n",
      "  val   AUC per head: h0: 0.8265 | h1: 0.7901 | h2: 0.8261 | h3: 0.8546\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8265', '0.7901', '0.8261', '0.8546']\n",
      "  [EdgeMLP] best mean val AUC = 0.8243\n",
      "Epoch 253 | train_loss(step) = 0.3468 | train_loss(eval) = 0.3458 | train_mean_auc = 0.8269 | val_mean_auc = 0.8245\n",
      "  train AUC per head: h0: 0.8318 | h1: 0.7919 | h2: 0.8267 | h3: 0.8574\n",
      "  val   AUC per head: h0: 0.8268 | h1: 0.7901 | h2: 0.8263 | h3: 0.8548\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8268', '0.7901', '0.8263', '0.8548']\n",
      "  [EdgeMLP] best mean val AUC = 0.8245\n",
      "Epoch 254 | train_loss(step) = 0.3416 | train_loss(eval) = 0.3457 | train_mean_auc = 0.8269 | val_mean_auc = 0.8245\n",
      "  train AUC per head: h0: 0.8318 | h1: 0.7916 | h2: 0.8266 | h3: 0.8575\n",
      "  val   AUC per head: h0: 0.8269 | h1: 0.7898 | h2: 0.8263 | h3: 0.8550\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8269', '0.7901', '0.8263', '0.8550']\n",
      "  [EdgeMLP] best mean val AUC = 0.8245\n",
      "Epoch 255 | train_loss(step) = 0.3428 | train_loss(eval) = 0.3458 | train_mean_auc = 0.8267 | val_mean_auc = 0.8243\n",
      "  train AUC per head: h0: 0.8315 | h1: 0.7914 | h2: 0.8263 | h3: 0.8575\n",
      "  val   AUC per head: h0: 0.8266 | h1: 0.7895 | h2: 0.8260 | h3: 0.8550\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8269', '0.7901', '0.8263', '0.8550']\n",
      "  [EdgeMLP] best mean val AUC = 0.8245\n",
      "Epoch 256 | train_loss(step) = 0.3467 | train_loss(eval) = 0.3458 | train_mean_auc = 0.8267 | val_mean_auc = 0.8244\n",
      "  train AUC per head: h0: 0.8315 | h1: 0.7916 | h2: 0.8263 | h3: 0.8575\n",
      "  val   AUC per head: h0: 0.8268 | h1: 0.7896 | h2: 0.8260 | h3: 0.8550\n",
      "  no improvement this epoch. no_improve_heads = [2, 4, 3, 1]\n",
      "Epoch 257 | train_loss(step) = 0.3439 | train_loss(eval) = 0.3456 | train_mean_auc = 0.8269 | val_mean_auc = 0.8245\n",
      "  train AUC per head: h0: 0.8316 | h1: 0.7920 | h2: 0.8265 | h3: 0.8575\n",
      "  val   AUC per head: h0: 0.8269 | h1: 0.7901 | h2: 0.8262 | h3: 0.8550\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8269', '0.7901', '0.8263', '0.8550']\n",
      "  [EdgeMLP] best mean val AUC = 0.8245\n",
      "Epoch 258 | train_loss(step) = 0.3442 | train_loss(eval) = 0.3453 | train_mean_auc = 0.8273 | val_mean_auc = 0.8249\n",
      "  train AUC per head: h0: 0.8320 | h1: 0.7927 | h2: 0.8270 | h3: 0.8574\n",
      "  val   AUC per head: h0: 0.8273 | h1: 0.7907 | h2: 0.8266 | h3: 0.8549\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8273', '0.7907', '0.8266', '0.8550']\n",
      "  [EdgeMLP] best mean val AUC = 0.8249\n",
      "Epoch 259 | train_loss(step) = 0.3464 | train_loss(eval) = 0.3450 | train_mean_auc = 0.8277 | val_mean_auc = 0.8253\n",
      "  train AUC per head: h0: 0.8326 | h1: 0.7933 | h2: 0.8276 | h3: 0.8574\n",
      "  val   AUC per head: h0: 0.8278 | h1: 0.7913 | h2: 0.8271 | h3: 0.8549\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8278', '0.7913', '0.8271', '0.8550']\n",
      "  [EdgeMLP] best mean val AUC = 0.8253\n",
      "Epoch 260 | train_loss(step) = 0.3538 | train_loss(eval) = 0.3448 | train_mean_auc = 0.8282 | val_mean_auc = 0.8258\n",
      "  train AUC per head: h0: 0.8331 | h1: 0.7939 | h2: 0.8285 | h3: 0.8574\n",
      "  val   AUC per head: h0: 0.8284 | h1: 0.7919 | h2: 0.8279 | h3: 0.8548\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8284', '0.7919', '0.8279', '0.8550']\n",
      "  [EdgeMLP] best mean val AUC = 0.8258\n",
      "Epoch 261 | train_loss(step) = 0.3505 | train_loss(eval) = 0.3447 | train_mean_auc = 0.8287 | val_mean_auc = 0.8262\n",
      "  train AUC per head: h0: 0.8335 | h1: 0.7944 | h2: 0.8293 | h3: 0.8575\n",
      "  val   AUC per head: h0: 0.8288 | h1: 0.7924 | h2: 0.8286 | h3: 0.8548\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8288', '0.7924', '0.8286', '0.8550']\n",
      "  [EdgeMLP] best mean val AUC = 0.8262\n",
      "Epoch 262 | train_loss(step) = 0.3376 | train_loss(eval) = 0.3448 | train_mean_auc = 0.8289 | val_mean_auc = 0.8264\n",
      "  train AUC per head: h0: 0.8337 | h1: 0.7946 | h2: 0.8299 | h3: 0.8576\n",
      "  val   AUC per head: h0: 0.8289 | h1: 0.7926 | h2: 0.8291 | h3: 0.8549\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8289', '0.7926', '0.8291', '0.8550']\n",
      "  [EdgeMLP] best mean val AUC = 0.8264\n",
      "Epoch 263 | train_loss(step) = 0.3389 | train_loss(eval) = 0.3448 | train_mean_auc = 0.8292 | val_mean_auc = 0.8266\n",
      "  train AUC per head: h0: 0.8338 | h1: 0.7948 | h2: 0.8304 | h3: 0.8577\n",
      "  val   AUC per head: h0: 0.8290 | h1: 0.7927 | h2: 0.8296 | h3: 0.8549\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8290', '0.7927', '0.8296', '0.8550']\n",
      "  [EdgeMLP] best mean val AUC = 0.8266\n",
      "Epoch 264 | train_loss(step) = 0.3472 | train_loss(eval) = 0.3447 | train_mean_auc = 0.8292 | val_mean_auc = 0.8266\n",
      "  train AUC per head: h0: 0.8334 | h1: 0.7950 | h2: 0.8308 | h3: 0.8578\n",
      "  val   AUC per head: h0: 0.8287 | h1: 0.7929 | h2: 0.8298 | h3: 0.8550\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8290', '0.7929', '0.8298', '0.8550']\n",
      "  [EdgeMLP] best mean val AUC = 0.8266\n",
      "Epoch 265 | train_loss(step) = 0.3463 | train_loss(eval) = 0.3448 | train_mean_auc = 0.8291 | val_mean_auc = 0.8265\n",
      "  train AUC per head: h0: 0.8329 | h1: 0.7950 | h2: 0.8308 | h3: 0.8578\n",
      "  val   AUC per head: h0: 0.8282 | h1: 0.7930 | h2: 0.8298 | h3: 0.8550\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8290', '0.7930', '0.8298', '0.8550']\n",
      "  [EdgeMLP] best mean val AUC = 0.8266\n",
      "Epoch 266 | train_loss(step) = 0.3374 | train_loss(eval) = 0.3447 | train_mean_auc = 0.8291 | val_mean_auc = 0.8266\n",
      "  train AUC per head: h0: 0.8331 | h1: 0.7950 | h2: 0.8305 | h3: 0.8580\n",
      "  val   AUC per head: h0: 0.8285 | h1: 0.7930 | h2: 0.8296 | h3: 0.8551\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8290', '0.7930', '0.8298', '0.8551']\n",
      "  [EdgeMLP] best mean val AUC = 0.8266\n",
      "Epoch 267 | train_loss(step) = 0.3468 | train_loss(eval) = 0.3444 | train_mean_auc = 0.8292 | val_mean_auc = 0.8267\n",
      "  train AUC per head: h0: 0.8338 | h1: 0.7950 | h2: 0.8301 | h3: 0.8581\n",
      "  val   AUC per head: h0: 0.8290 | h1: 0.7931 | h2: 0.8294 | h3: 0.8552\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8290', '0.7931', '0.8298', '0.8552']\n",
      "  [EdgeMLP] best mean val AUC = 0.8267\n",
      "Epoch 268 | train_loss(step) = 0.3440 | train_loss(eval) = 0.3442 | train_mean_auc = 0.8294 | val_mean_auc = 0.8268\n",
      "  train AUC per head: h0: 0.8342 | h1: 0.7952 | h2: 0.8299 | h3: 0.8582\n",
      "  val   AUC per head: h0: 0.8294 | h1: 0.7934 | h2: 0.8293 | h3: 0.8553\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8294', '0.7934', '0.8298', '0.8553']\n",
      "  [EdgeMLP] best mean val AUC = 0.8268\n",
      "Epoch 269 | train_loss(step) = 0.3405 | train_loss(eval) = 0.3438 | train_mean_auc = 0.8295 | val_mean_auc = 0.8270\n",
      "  train AUC per head: h0: 0.8346 | h1: 0.7955 | h2: 0.8299 | h3: 0.8581\n",
      "  val   AUC per head: h0: 0.8297 | h1: 0.7938 | h2: 0.8293 | h3: 0.8552\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8297', '0.7938', '0.8298', '0.8553']\n",
      "  [EdgeMLP] best mean val AUC = 0.8270\n",
      "Epoch 270 | train_loss(step) = 0.3368 | train_loss(eval) = 0.3438 | train_mean_auc = 0.8294 | val_mean_auc = 0.8269\n",
      "  train AUC per head: h0: 0.8344 | h1: 0.7957 | h2: 0.8297 | h3: 0.8579\n",
      "  val   AUC per head: h0: 0.8295 | h1: 0.7939 | h2: 0.8291 | h3: 0.8550\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8297', '0.7939', '0.8298', '0.8553']\n",
      "  [EdgeMLP] best mean val AUC = 0.8270\n",
      "Epoch 271 | train_loss(step) = 0.3419 | train_loss(eval) = 0.3440 | train_mean_auc = 0.8292 | val_mean_auc = 0.8266\n",
      "  train AUC per head: h0: 0.8339 | h1: 0.7957 | h2: 0.8295 | h3: 0.8577\n",
      "  val   AUC per head: h0: 0.8290 | h1: 0.7940 | h2: 0.8287 | h3: 0.8549\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8297', '0.7940', '0.8298', '0.8553']\n",
      "  [EdgeMLP] best mean val AUC = 0.8270\n",
      "Epoch 272 | train_loss(step) = 0.3502 | train_loss(eval) = 0.3442 | train_mean_auc = 0.8291 | val_mean_auc = 0.8264\n",
      "  train AUC per head: h0: 0.8335 | h1: 0.7957 | h2: 0.8293 | h3: 0.8577\n",
      "  val   AUC per head: h0: 0.8286 | h1: 0.7939 | h2: 0.8284 | h3: 0.8549\n",
      "  no improvement this epoch. no_improve_heads = [3, 1, 8, 4]\n",
      "Epoch 273 | train_loss(step) = 0.3435 | train_loss(eval) = 0.3439 | train_mean_auc = 0.8291 | val_mean_auc = 0.8265\n",
      "  train AUC per head: h0: 0.8333 | h1: 0.7958 | h2: 0.8295 | h3: 0.8578\n",
      "  val   AUC per head: h0: 0.8285 | h1: 0.7939 | h2: 0.8285 | h3: 0.8550\n",
      "  no improvement this epoch. no_improve_heads = [4, 2, 9, 5]\n",
      "Epoch 274 | train_loss(step) = 0.3281 | train_loss(eval) = 0.3441 | train_mean_auc = 0.8291 | val_mean_auc = 0.8263\n",
      "  train AUC per head: h0: 0.8331 | h1: 0.7957 | h2: 0.8296 | h3: 0.8579\n",
      "  val   AUC per head: h0: 0.8281 | h1: 0.7937 | h2: 0.8284 | h3: 0.8551\n",
      "  no improvement this epoch. no_improve_heads = [5, 3, 10, 6]\n",
      "Epoch 275 | train_loss(step) = 0.3477 | train_loss(eval) = 0.3443 | train_mean_auc = 0.8293 | val_mean_auc = 0.8264\n",
      "  train AUC per head: h0: 0.8332 | h1: 0.7958 | h2: 0.8300 | h3: 0.8580\n",
      "  val   AUC per head: h0: 0.8282 | h1: 0.7937 | h2: 0.8287 | h3: 0.8552\n",
      "  no improvement this epoch. no_improve_heads = [6, 4, 11, 7]\n",
      "Epoch 276 | train_loss(step) = 0.3582 | train_loss(eval) = 0.3437 | train_mean_auc = 0.8297 | val_mean_auc = 0.8268\n",
      "  train AUC per head: h0: 0.8337 | h1: 0.7962 | h2: 0.8306 | h3: 0.8582\n",
      "  val   AUC per head: h0: 0.8287 | h1: 0.7941 | h2: 0.8290 | h3: 0.8553\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8297', '0.7941', '0.8298', '0.8553']\n",
      "  [EdgeMLP] best mean val AUC = 0.8270\n",
      "Epoch 277 | train_loss(step) = 0.3381 | train_loss(eval) = 0.3431 | train_mean_auc = 0.8303 | val_mean_auc = 0.8273\n",
      "  train AUC per head: h0: 0.8346 | h1: 0.7968 | h2: 0.8313 | h3: 0.8583\n",
      "  val   AUC per head: h0: 0.8296 | h1: 0.7947 | h2: 0.8296 | h3: 0.8553\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8297', '0.7947', '0.8298', '0.8553']\n",
      "  [EdgeMLP] best mean val AUC = 0.8273\n",
      "Epoch 278 | train_loss(step) = 0.3421 | train_loss(eval) = 0.3432 | train_mean_auc = 0.8307 | val_mean_auc = 0.8276\n",
      "  train AUC per head: h0: 0.8353 | h1: 0.7972 | h2: 0.8319 | h3: 0.8583\n",
      "  val   AUC per head: h0: 0.8302 | h1: 0.7950 | h2: 0.8300 | h3: 0.8553\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8302', '0.7950', '0.8300', '0.8553']\n",
      "  [EdgeMLP] best mean val AUC = 0.8276\n",
      "Epoch 279 | train_loss(step) = 0.3422 | train_loss(eval) = 0.3434 | train_mean_auc = 0.8309 | val_mean_auc = 0.8279\n",
      "  train AUC per head: h0: 0.8357 | h1: 0.7975 | h2: 0.8321 | h3: 0.8583\n",
      "  val   AUC per head: h0: 0.8307 | h1: 0.7953 | h2: 0.8304 | h3: 0.8553\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8307', '0.7953', '0.8304', '0.8553']\n",
      "  [EdgeMLP] best mean val AUC = 0.8279\n",
      "Epoch 280 | train_loss(step) = 0.3392 | train_loss(eval) = 0.3426 | train_mean_auc = 0.8313 | val_mean_auc = 0.8283\n",
      "  train AUC per head: h0: 0.8361 | h1: 0.7981 | h2: 0.8325 | h3: 0.8584\n",
      "  val   AUC per head: h0: 0.8310 | h1: 0.7959 | h2: 0.8309 | h3: 0.8554\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8310', '0.7959', '0.8309', '0.8554']\n",
      "  [EdgeMLP] best mean val AUC = 0.8283\n",
      "Epoch 281 | train_loss(step) = 0.3492 | train_loss(eval) = 0.3426 | train_mean_auc = 0.8312 | val_mean_auc = 0.8283\n",
      "  train AUC per head: h0: 0.8358 | h1: 0.7981 | h2: 0.8325 | h3: 0.8585\n",
      "  val   AUC per head: h0: 0.8306 | h1: 0.7959 | h2: 0.8311 | h3: 0.8555\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8310', '0.7959', '0.8311', '0.8555']\n",
      "  [EdgeMLP] best mean val AUC = 0.8283\n",
      "Epoch 282 | train_loss(step) = 0.3495 | train_loss(eval) = 0.3430 | train_mean_auc = 0.8311 | val_mean_auc = 0.8281\n",
      "  train AUC per head: h0: 0.8353 | h1: 0.7980 | h2: 0.8325 | h3: 0.8586\n",
      "  val   AUC per head: h0: 0.8300 | h1: 0.7957 | h2: 0.8311 | h3: 0.8556\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8310', '0.7959', '0.8311', '0.8556']\n",
      "  [EdgeMLP] best mean val AUC = 0.8283\n",
      "Epoch 283 | train_loss(step) = 0.3334 | train_loss(eval) = 0.3434 | train_mean_auc = 0.8309 | val_mean_auc = 0.8279\n",
      "  train AUC per head: h0: 0.8348 | h1: 0.7978 | h2: 0.8324 | h3: 0.8586\n",
      "  val   AUC per head: h0: 0.8295 | h1: 0.7954 | h2: 0.8312 | h3: 0.8556\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8310', '0.7959', '0.8312', '0.8556']\n",
      "  [EdgeMLP] best mean val AUC = 0.8283\n",
      "Epoch 284 | train_loss(step) = 0.3439 | train_loss(eval) = 0.3429 | train_mean_auc = 0.8310 | val_mean_auc = 0.8281\n",
      "  train AUC per head: h0: 0.8352 | h1: 0.7978 | h2: 0.8325 | h3: 0.8587\n",
      "  val   AUC per head: h0: 0.8299 | h1: 0.7955 | h2: 0.8314 | h3: 0.8557\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8310', '0.7959', '0.8314', '0.8557']\n",
      "  [EdgeMLP] best mean val AUC = 0.8283\n",
      "Epoch 285 | train_loss(step) = 0.3384 | train_loss(eval) = 0.3425 | train_mean_auc = 0.8313 | val_mean_auc = 0.8284\n",
      "  train AUC per head: h0: 0.8358 | h1: 0.7979 | h2: 0.8330 | h3: 0.8586\n",
      "  val   AUC per head: h0: 0.8306 | h1: 0.7955 | h2: 0.8318 | h3: 0.8557\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8310', '0.7959', '0.8318', '0.8557']\n",
      "  [EdgeMLP] best mean val AUC = 0.8284\n",
      "Epoch 286 | train_loss(step) = 0.3451 | train_loss(eval) = 0.3424 | train_mean_auc = 0.8316 | val_mean_auc = 0.8287\n",
      "  train AUC per head: h0: 0.8363 | h1: 0.7983 | h2: 0.8332 | h3: 0.8586\n",
      "  val   AUC per head: h0: 0.8311 | h1: 0.7959 | h2: 0.8320 | h3: 0.8556\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8311', '0.7959', '0.8320', '0.8557']\n",
      "  [EdgeMLP] best mean val AUC = 0.8287\n",
      "Epoch 287 | train_loss(step) = 0.3475 | train_loss(eval) = 0.3426 | train_mean_auc = 0.8319 | val_mean_auc = 0.8289\n",
      "  train AUC per head: h0: 0.8364 | h1: 0.7988 | h2: 0.8337 | h3: 0.8586\n",
      "  val   AUC per head: h0: 0.8312 | h1: 0.7965 | h2: 0.8324 | h3: 0.8556\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8312', '0.7965', '0.8324', '0.8557']\n",
      "  [EdgeMLP] best mean val AUC = 0.8289\n",
      "Epoch 288 | train_loss(step) = 0.3468 | train_loss(eval) = 0.3423 | train_mean_auc = 0.8322 | val_mean_auc = 0.8292\n",
      "  train AUC per head: h0: 0.8366 | h1: 0.7991 | h2: 0.8344 | h3: 0.8586\n",
      "  val   AUC per head: h0: 0.8314 | h1: 0.7968 | h2: 0.8330 | h3: 0.8557\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8314', '0.7968', '0.8330', '0.8557']\n",
      "  [EdgeMLP] best mean val AUC = 0.8292\n",
      "Epoch 289 | train_loss(step) = 0.3446 | train_loss(eval) = 0.3417 | train_mean_auc = 0.8324 | val_mean_auc = 0.8294\n",
      "  train AUC per head: h0: 0.8369 | h1: 0.7991 | h2: 0.8348 | h3: 0.8587\n",
      "  val   AUC per head: h0: 0.8315 | h1: 0.7968 | h2: 0.8334 | h3: 0.8558\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8315', '0.7968', '0.8334', '0.8558']\n",
      "  [EdgeMLP] best mean val AUC = 0.8294\n",
      "Epoch 290 | train_loss(step) = 0.3376 | train_loss(eval) = 0.3420 | train_mean_auc = 0.8322 | val_mean_auc = 0.8292\n",
      "  train AUC per head: h0: 0.8364 | h1: 0.7989 | h2: 0.8348 | h3: 0.8588\n",
      "  val   AUC per head: h0: 0.8309 | h1: 0.7967 | h2: 0.8334 | h3: 0.8559\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8315', '0.7968', '0.8334', '0.8559']\n",
      "  [EdgeMLP] best mean val AUC = 0.8294\n",
      "Epoch 291 | train_loss(step) = 0.3383 | train_loss(eval) = 0.3422 | train_mean_auc = 0.8323 | val_mean_auc = 0.8293\n",
      "  train AUC per head: h0: 0.8363 | h1: 0.7992 | h2: 0.8350 | h3: 0.8588\n",
      "  val   AUC per head: h0: 0.8308 | h1: 0.7971 | h2: 0.8335 | h3: 0.8559\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8315', '0.7971', '0.8335', '0.8559']\n",
      "  [EdgeMLP] best mean val AUC = 0.8294\n",
      "Epoch 292 | train_loss(step) = 0.3417 | train_loss(eval) = 0.3418 | train_mean_auc = 0.8327 | val_mean_auc = 0.8297\n",
      "  train AUC per head: h0: 0.8368 | h1: 0.7998 | h2: 0.8354 | h3: 0.8587\n",
      "  val   AUC per head: h0: 0.8314 | h1: 0.7977 | h2: 0.8338 | h3: 0.8558\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8315', '0.7977', '0.8338', '0.8559']\n",
      "  [EdgeMLP] best mean val AUC = 0.8297\n",
      "Epoch 293 | train_loss(step) = 0.3318 | train_loss(eval) = 0.3415 | train_mean_auc = 0.8328 | val_mean_auc = 0.8299\n",
      "  train AUC per head: h0: 0.8369 | h1: 0.8002 | h2: 0.8354 | h3: 0.8586\n",
      "  val   AUC per head: h0: 0.8317 | h1: 0.7982 | h2: 0.8338 | h3: 0.8557\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8317', '0.7982', '0.8338', '0.8559']\n",
      "  [EdgeMLP] best mean val AUC = 0.8299\n",
      "Epoch 294 | train_loss(step) = 0.3499 | train_loss(eval) = 0.3415 | train_mean_auc = 0.8328 | val_mean_auc = 0.8299\n",
      "  train AUC per head: h0: 0.8368 | h1: 0.8003 | h2: 0.8354 | h3: 0.8586\n",
      "  val   AUC per head: h0: 0.8317 | h1: 0.7983 | h2: 0.8337 | h3: 0.8557\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8317', '0.7983', '0.8338', '0.8559']\n",
      "  [EdgeMLP] best mean val AUC = 0.8299\n",
      "Epoch 295 | train_loss(step) = 0.3542 | train_loss(eval) = 0.3414 | train_mean_auc = 0.8328 | val_mean_auc = 0.8299\n",
      "  train AUC per head: h0: 0.8368 | h1: 0.8003 | h2: 0.8354 | h3: 0.8586\n",
      "  val   AUC per head: h0: 0.8318 | h1: 0.7984 | h2: 0.8337 | h3: 0.8558\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8318', '0.7984', '0.8338', '0.8559']\n",
      "  [EdgeMLP] best mean val AUC = 0.8299\n",
      "Epoch 296 | train_loss(step) = 0.3489 | train_loss(eval) = 0.3411 | train_mean_auc = 0.8330 | val_mean_auc = 0.8302\n",
      "  train AUC per head: h0: 0.8372 | h1: 0.8004 | h2: 0.8357 | h3: 0.8588\n",
      "  val   AUC per head: h0: 0.8323 | h1: 0.7984 | h2: 0.8341 | h3: 0.8559\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8323', '0.7984', '0.8341', '0.8559']\n",
      "  [EdgeMLP] best mean val AUC = 0.8302\n",
      "Epoch 297 | train_loss(step) = 0.3397 | train_loss(eval) = 0.3410 | train_mean_auc = 0.8331 | val_mean_auc = 0.8303\n",
      "  train AUC per head: h0: 0.8374 | h1: 0.8003 | h2: 0.8359 | h3: 0.8589\n",
      "  val   AUC per head: h0: 0.8324 | h1: 0.7984 | h2: 0.8343 | h3: 0.8559\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8324', '0.7984', '0.8343', '0.8559']\n",
      "  [EdgeMLP] best mean val AUC = 0.8303\n",
      "Epoch 298 | train_loss(step) = 0.3426 | train_loss(eval) = 0.3409 | train_mean_auc = 0.8332 | val_mean_auc = 0.8303\n",
      "  train AUC per head: h0: 0.8376 | h1: 0.8005 | h2: 0.8359 | h3: 0.8588\n",
      "  val   AUC per head: h0: 0.8325 | h1: 0.7986 | h2: 0.8344 | h3: 0.8558\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8325', '0.7986', '0.8344', '0.8559']\n",
      "  [EdgeMLP] best mean val AUC = 0.8303\n",
      "Epoch 299 | train_loss(step) = 0.3322 | train_loss(eval) = 0.3408 | train_mean_auc = 0.8333 | val_mean_auc = 0.8303\n",
      "  train AUC per head: h0: 0.8376 | h1: 0.8008 | h2: 0.8358 | h3: 0.8587\n",
      "  val   AUC per head: h0: 0.8325 | h1: 0.7990 | h2: 0.8342 | h3: 0.8557\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8325', '0.7990', '0.8344', '0.8559']\n",
      "  [EdgeMLP] best mean val AUC = 0.8303\n",
      "Epoch 300 | train_loss(step) = 0.3362 | train_loss(eval) = 0.3407 | train_mean_auc = 0.8334 | val_mean_auc = 0.8304\n",
      "  train AUC per head: h0: 0.8376 | h1: 0.8011 | h2: 0.8359 | h3: 0.8589\n",
      "  val   AUC per head: h0: 0.8323 | h1: 0.7993 | h2: 0.8340 | h3: 0.8558\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8325', '0.7993', '0.8344', '0.8559']\n",
      "  [EdgeMLP] best mean val AUC = 0.8304\n",
      "Epoch 301 | train_loss(step) = 0.3437 | train_loss(eval) = 0.3407 | train_mean_auc = 0.8334 | val_mean_auc = 0.8304\n",
      "  train AUC per head: h0: 0.8375 | h1: 0.8013 | h2: 0.8359 | h3: 0.8590\n",
      "  val   AUC per head: h0: 0.8322 | h1: 0.7994 | h2: 0.8339 | h3: 0.8560\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8325', '0.7994', '0.8344', '0.8560']\n",
      "  [EdgeMLP] best mean val AUC = 0.8304\n",
      "Epoch 302 | train_loss(step) = 0.3453 | train_loss(eval) = 0.3408 | train_mean_auc = 0.8335 | val_mean_auc = 0.8304\n",
      "  train AUC per head: h0: 0.8375 | h1: 0.8014 | h2: 0.8359 | h3: 0.8591\n",
      "  val   AUC per head: h0: 0.8321 | h1: 0.7996 | h2: 0.8337 | h3: 0.8560\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8325', '0.7996', '0.8344', '0.8560']\n",
      "  [EdgeMLP] best mean val AUC = 0.8304\n",
      "Epoch 303 | train_loss(step) = 0.3435 | train_loss(eval) = 0.3410 | train_mean_auc = 0.8334 | val_mean_auc = 0.8302\n",
      "  train AUC per head: h0: 0.8373 | h1: 0.8013 | h2: 0.8359 | h3: 0.8591\n",
      "  val   AUC per head: h0: 0.8319 | h1: 0.7995 | h2: 0.8335 | h3: 0.8561\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8325', '0.7996', '0.8344', '0.8561']\n",
      "  [EdgeMLP] best mean val AUC = 0.8304\n",
      "Epoch 304 | train_loss(step) = 0.3544 | train_loss(eval) = 0.3409 | train_mean_auc = 0.8334 | val_mean_auc = 0.8302\n",
      "  train AUC per head: h0: 0.8373 | h1: 0.8014 | h2: 0.8360 | h3: 0.8591\n",
      "  val   AUC per head: h0: 0.8318 | h1: 0.7995 | h2: 0.8335 | h3: 0.8561\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8325', '0.7996', '0.8344', '0.8561']\n",
      "  [EdgeMLP] best mean val AUC = 0.8304\n",
      "Epoch 305 | train_loss(step) = 0.3414 | train_loss(eval) = 0.3408 | train_mean_auc = 0.8336 | val_mean_auc = 0.8303\n",
      "  train AUC per head: h0: 0.8373 | h1: 0.8016 | h2: 0.8362 | h3: 0.8592\n",
      "  val   AUC per head: h0: 0.8317 | h1: 0.7997 | h2: 0.8336 | h3: 0.8562\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8325', '0.7997', '0.8344', '0.8562']\n",
      "  [EdgeMLP] best mean val AUC = 0.8304\n",
      "Epoch 306 | train_loss(step) = 0.3384 | train_loss(eval) = 0.3408 | train_mean_auc = 0.8338 | val_mean_auc = 0.8305\n",
      "  train AUC per head: h0: 0.8375 | h1: 0.8018 | h2: 0.8365 | h3: 0.8592\n",
      "  val   AUC per head: h0: 0.8320 | h1: 0.7998 | h2: 0.8340 | h3: 0.8563\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8325', '0.7998', '0.8344', '0.8563']\n",
      "  [EdgeMLP] best mean val AUC = 0.8305\n",
      "Epoch 307 | train_loss(step) = 0.3279 | train_loss(eval) = 0.3411 | train_mean_auc = 0.8339 | val_mean_auc = 0.8307\n",
      "  train AUC per head: h0: 0.8379 | h1: 0.8018 | h2: 0.8368 | h3: 0.8593\n",
      "  val   AUC per head: h0: 0.8323 | h1: 0.7997 | h2: 0.8342 | h3: 0.8564\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8325', '0.7998', '0.8344', '0.8564']\n",
      "  [EdgeMLP] best mean val AUC = 0.8307\n",
      "Epoch 308 | train_loss(step) = 0.3423 | train_loss(eval) = 0.3406 | train_mean_auc = 0.8342 | val_mean_auc = 0.8310\n",
      "  train AUC per head: h0: 0.8383 | h1: 0.8023 | h2: 0.8369 | h3: 0.8595\n",
      "  val   AUC per head: h0: 0.8329 | h1: 0.8001 | h2: 0.8344 | h3: 0.8565\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8329', '0.8001', '0.8344', '0.8565']\n",
      "  [EdgeMLP] best mean val AUC = 0.8310\n",
      "Epoch 309 | train_loss(step) = 0.3435 | train_loss(eval) = 0.3401 | train_mean_auc = 0.8344 | val_mean_auc = 0.8312\n",
      "  train AUC per head: h0: 0.8384 | h1: 0.8026 | h2: 0.8368 | h3: 0.8595\n",
      "  val   AUC per head: h0: 0.8333 | h1: 0.8005 | h2: 0.8344 | h3: 0.8565\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8333', '0.8005', '0.8344', '0.8565']\n",
      "  [EdgeMLP] best mean val AUC = 0.8312\n",
      "Epoch 310 | train_loss(step) = 0.3370 | train_loss(eval) = 0.3400 | train_mean_auc = 0.8345 | val_mean_auc = 0.8314\n",
      "  train AUC per head: h0: 0.8388 | h1: 0.8029 | h2: 0.8370 | h3: 0.8595\n",
      "  val   AUC per head: h0: 0.8337 | h1: 0.8007 | h2: 0.8346 | h3: 0.8564\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8337', '0.8007', '0.8346', '0.8565']\n",
      "  [EdgeMLP] best mean val AUC = 0.8314\n",
      "Epoch 311 | train_loss(step) = 0.3431 | train_loss(eval) = 0.3398 | train_mean_auc = 0.8349 | val_mean_auc = 0.8318\n",
      "  train AUC per head: h0: 0.8394 | h1: 0.8031 | h2: 0.8377 | h3: 0.8595\n",
      "  val   AUC per head: h0: 0.8343 | h1: 0.8010 | h2: 0.8355 | h3: 0.8564\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8343', '0.8010', '0.8355', '0.8565']\n",
      "  [EdgeMLP] best mean val AUC = 0.8318\n",
      "Epoch 312 | train_loss(step) = 0.3391 | train_loss(eval) = 0.3399 | train_mean_auc = 0.8351 | val_mean_auc = 0.8321\n",
      "  train AUC per head: h0: 0.8395 | h1: 0.8031 | h2: 0.8381 | h3: 0.8595\n",
      "  val   AUC per head: h0: 0.8345 | h1: 0.8012 | h2: 0.8361 | h3: 0.8565\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8345', '0.8012', '0.8361', '0.8565']\n",
      "  [EdgeMLP] best mean val AUC = 0.8321\n",
      "Epoch 313 | train_loss(step) = 0.3441 | train_loss(eval) = 0.3395 | train_mean_auc = 0.8351 | val_mean_auc = 0.8322\n",
      "  train AUC per head: h0: 0.8396 | h1: 0.8033 | h2: 0.8379 | h3: 0.8596\n",
      "  val   AUC per head: h0: 0.8346 | h1: 0.8015 | h2: 0.8362 | h3: 0.8566\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8346', '0.8015', '0.8362', '0.8566']\n",
      "  [EdgeMLP] best mean val AUC = 0.8322\n",
      "Epoch 314 | train_loss(step) = 0.3440 | train_loss(eval) = 0.3393 | train_mean_auc = 0.8350 | val_mean_auc = 0.8323\n",
      "  train AUC per head: h0: 0.8394 | h1: 0.8033 | h2: 0.8377 | h3: 0.8598\n",
      "  val   AUC per head: h0: 0.8346 | h1: 0.8017 | h2: 0.8360 | h3: 0.8568\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8346', '0.8017', '0.8362', '0.8568']\n",
      "  [EdgeMLP] best mean val AUC = 0.8323\n",
      "Epoch 315 | train_loss(step) = 0.3364 | train_loss(eval) = 0.3395 | train_mean_auc = 0.8348 | val_mean_auc = 0.8321\n",
      "  train AUC per head: h0: 0.8391 | h1: 0.8031 | h2: 0.8373 | h3: 0.8599\n",
      "  val   AUC per head: h0: 0.8343 | h1: 0.8016 | h2: 0.8358 | h3: 0.8569\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8346', '0.8017', '0.8362', '0.8569']\n",
      "  [EdgeMLP] best mean val AUC = 0.8323\n",
      "Epoch 316 | train_loss(step) = 0.3417 | train_loss(eval) = 0.3393 | train_mean_auc = 0.8349 | val_mean_auc = 0.8322\n",
      "  train AUC per head: h0: 0.8390 | h1: 0.8032 | h2: 0.8376 | h3: 0.8599\n",
      "  val   AUC per head: h0: 0.8343 | h1: 0.8017 | h2: 0.8360 | h3: 0.8569\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8346', '0.8017', '0.8362', '0.8569']\n",
      "  [EdgeMLP] best mean val AUC = 0.8323\n",
      "Epoch 317 | train_loss(step) = 0.3394 | train_loss(eval) = 0.3393 | train_mean_auc = 0.8351 | val_mean_auc = 0.8324\n",
      "  train AUC per head: h0: 0.8390 | h1: 0.8036 | h2: 0.8382 | h3: 0.8598\n",
      "  val   AUC per head: h0: 0.8342 | h1: 0.8020 | h2: 0.8366 | h3: 0.8569\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8346', '0.8020', '0.8366', '0.8569']\n",
      "  [EdgeMLP] best mean val AUC = 0.8324\n",
      "Epoch 318 | train_loss(step) = 0.3418 | train_loss(eval) = 0.3397 | train_mean_auc = 0.8353 | val_mean_auc = 0.8326\n",
      "  train AUC per head: h0: 0.8391 | h1: 0.8039 | h2: 0.8387 | h3: 0.8597\n",
      "  val   AUC per head: h0: 0.8342 | h1: 0.8023 | h2: 0.8371 | h3: 0.8569\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8346', '0.8023', '0.8371', '0.8569']\n",
      "  [EdgeMLP] best mean val AUC = 0.8326\n",
      "Epoch 319 | train_loss(step) = 0.3539 | train_loss(eval) = 0.3391 | train_mean_auc = 0.8356 | val_mean_auc = 0.8329\n",
      "  train AUC per head: h0: 0.8395 | h1: 0.8043 | h2: 0.8390 | h3: 0.8597\n",
      "  val   AUC per head: h0: 0.8348 | h1: 0.8027 | h2: 0.8374 | h3: 0.8569\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8348', '0.8027', '0.8374', '0.8569']\n",
      "  [EdgeMLP] best mean val AUC = 0.8329\n",
      "Epoch 320 | train_loss(step) = 0.3413 | train_loss(eval) = 0.3393 | train_mean_auc = 0.8353 | val_mean_auc = 0.8326\n",
      "  train AUC per head: h0: 0.8390 | h1: 0.8039 | h2: 0.8386 | h3: 0.8598\n",
      "  val   AUC per head: h0: 0.8344 | h1: 0.8022 | h2: 0.8369 | h3: 0.8570\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8348', '0.8027', '0.8374', '0.8570']\n",
      "  [EdgeMLP] best mean val AUC = 0.8329\n",
      "Epoch 321 | train_loss(step) = 0.3435 | train_loss(eval) = 0.3397 | train_mean_auc = 0.8352 | val_mean_auc = 0.8325\n",
      "  train AUC per head: h0: 0.8387 | h1: 0.8038 | h2: 0.8384 | h3: 0.8600\n",
      "  val   AUC per head: h0: 0.8341 | h1: 0.8020 | h2: 0.8367 | h3: 0.8571\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8348', '0.8027', '0.8374', '0.8571']\n",
      "  [EdgeMLP] best mean val AUC = 0.8329\n",
      "Epoch 322 | train_loss(step) = 0.3346 | train_loss(eval) = 0.3391 | train_mean_auc = 0.8358 | val_mean_auc = 0.8330\n",
      "  train AUC per head: h0: 0.8394 | h1: 0.8047 | h2: 0.8390 | h3: 0.8602\n",
      "  val   AUC per head: h0: 0.8347 | h1: 0.8029 | h2: 0.8372 | h3: 0.8573\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8348', '0.8029', '0.8374', '0.8573']\n",
      "  [EdgeMLP] best mean val AUC = 0.8330\n",
      "Epoch 323 | train_loss(step) = 0.3370 | train_loss(eval) = 0.3389 | train_mean_auc = 0.8362 | val_mean_auc = 0.8333\n",
      "  train AUC per head: h0: 0.8399 | h1: 0.8052 | h2: 0.8395 | h3: 0.8603\n",
      "  val   AUC per head: h0: 0.8349 | h1: 0.8034 | h2: 0.8377 | h3: 0.8573\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8349', '0.8034', '0.8377', '0.8573']\n",
      "  [EdgeMLP] best mean val AUC = 0.8333\n",
      "Epoch 324 | train_loss(step) = 0.3296 | train_loss(eval) = 0.3394 | train_mean_auc = 0.8361 | val_mean_auc = 0.8331\n",
      "  train AUC per head: h0: 0.8395 | h1: 0.8049 | h2: 0.8395 | h3: 0.8603\n",
      "  val   AUC per head: h0: 0.8343 | h1: 0.8031 | h2: 0.8376 | h3: 0.8574\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8349', '0.8034', '0.8377', '0.8574']\n",
      "  [EdgeMLP] best mean val AUC = 0.8333\n",
      "Epoch 325 | train_loss(step) = 0.3420 | train_loss(eval) = 0.3390 | train_mean_auc = 0.8361 | val_mean_auc = 0.8331\n",
      "  train AUC per head: h0: 0.8395 | h1: 0.8049 | h2: 0.8395 | h3: 0.8603\n",
      "  val   AUC per head: h0: 0.8342 | h1: 0.8031 | h2: 0.8376 | h3: 0.8574\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8349', '0.8034', '0.8377', '0.8574']\n",
      "  [EdgeMLP] best mean val AUC = 0.8333\n",
      "Epoch 326 | train_loss(step) = 0.3377 | train_loss(eval) = 0.3385 | train_mean_auc = 0.8362 | val_mean_auc = 0.8332\n",
      "  train AUC per head: h0: 0.8399 | h1: 0.8051 | h2: 0.8394 | h3: 0.8602\n",
      "  val   AUC per head: h0: 0.8346 | h1: 0.8034 | h2: 0.8374 | h3: 0.8573\n",
      "  no improvement this epoch. no_improve_heads = [3, 3, 3, 1]\n",
      "Epoch 327 | train_loss(step) = 0.3346 | train_loss(eval) = 0.3386 | train_mean_auc = 0.8361 | val_mean_auc = 0.8331\n",
      "  train AUC per head: h0: 0.8399 | h1: 0.8051 | h2: 0.8392 | h3: 0.8601\n",
      "  val   AUC per head: h0: 0.8346 | h1: 0.8034 | h2: 0.8371 | h3: 0.8572\n",
      "  no improvement this epoch. no_improve_heads = [4, 4, 4, 2]\n",
      "Epoch 328 | train_loss(step) = 0.3405 | train_loss(eval) = 0.3386 | train_mean_auc = 0.8360 | val_mean_auc = 0.8330\n",
      "  train AUC per head: h0: 0.8399 | h1: 0.8050 | h2: 0.8391 | h3: 0.8600\n",
      "  val   AUC per head: h0: 0.8346 | h1: 0.8034 | h2: 0.8370 | h3: 0.8571\n",
      "  no improvement this epoch. no_improve_heads = [5, 5, 5, 3]\n",
      "Epoch 329 | train_loss(step) = 0.3450 | train_loss(eval) = 0.3385 | train_mean_auc = 0.8360 | val_mean_auc = 0.8330\n",
      "  train AUC per head: h0: 0.8400 | h1: 0.8050 | h2: 0.8391 | h3: 0.8599\n",
      "  val   AUC per head: h0: 0.8346 | h1: 0.8033 | h2: 0.8370 | h3: 0.8571\n",
      "  no improvement this epoch. no_improve_heads = [6, 6, 6, 4]\n",
      "Epoch 330 | train_loss(step) = 0.3396 | train_loss(eval) = 0.3384 | train_mean_auc = 0.8360 | val_mean_auc = 0.8330\n",
      "  train AUC per head: h0: 0.8401 | h1: 0.8049 | h2: 0.8391 | h3: 0.8598\n",
      "  val   AUC per head: h0: 0.8347 | h1: 0.8033 | h2: 0.8370 | h3: 0.8570\n",
      "  no improvement this epoch. no_improve_heads = [7, 7, 7, 5]\n",
      "Epoch 331 | train_loss(step) = 0.3508 | train_loss(eval) = 0.3382 | train_mean_auc = 0.8361 | val_mean_auc = 0.8331\n",
      "  train AUC per head: h0: 0.8403 | h1: 0.8050 | h2: 0.8392 | h3: 0.8599\n",
      "  val   AUC per head: h0: 0.8349 | h1: 0.8033 | h2: 0.8371 | h3: 0.8571\n",
      "  no improvement this epoch. no_improve_heads = [8, 8, 8, 6]\n",
      "Epoch 332 | train_loss(step) = 0.3376 | train_loss(eval) = 0.3381 | train_mean_auc = 0.8363 | val_mean_auc = 0.8333\n",
      "  train AUC per head: h0: 0.8406 | h1: 0.8052 | h2: 0.8394 | h3: 0.8601\n",
      "  val   AUC per head: h0: 0.8351 | h1: 0.8036 | h2: 0.8374 | h3: 0.8572\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8351', '0.8036', '0.8377', '0.8574']\n",
      "  [EdgeMLP] best mean val AUC = 0.8333\n",
      "Epoch 333 | train_loss(step) = 0.3392 | train_loss(eval) = 0.3379 | train_mean_auc = 0.8366 | val_mean_auc = 0.8336\n",
      "  train AUC per head: h0: 0.8407 | h1: 0.8055 | h2: 0.8398 | h3: 0.8603\n",
      "  val   AUC per head: h0: 0.8353 | h1: 0.8039 | h2: 0.8379 | h3: 0.8574\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8353', '0.8039', '0.8379', '0.8574']\n",
      "  [EdgeMLP] best mean val AUC = 0.8336\n",
      "Epoch 334 | train_loss(step) = 0.3368 | train_loss(eval) = 0.3380 | train_mean_auc = 0.8368 | val_mean_auc = 0.8339\n",
      "  train AUC per head: h0: 0.8408 | h1: 0.8058 | h2: 0.8402 | h3: 0.8605\n",
      "  val   AUC per head: h0: 0.8354 | h1: 0.8042 | h2: 0.8384 | h3: 0.8575\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8354', '0.8042', '0.8384', '0.8575']\n",
      "  [EdgeMLP] best mean val AUC = 0.8339\n",
      "Epoch 335 | train_loss(step) = 0.3329 | train_loss(eval) = 0.3379 | train_mean_auc = 0.8369 | val_mean_auc = 0.8339\n",
      "  train AUC per head: h0: 0.8408 | h1: 0.8059 | h2: 0.8403 | h3: 0.8606\n",
      "  val   AUC per head: h0: 0.8354 | h1: 0.8043 | h2: 0.8385 | h3: 0.8575\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8354', '0.8043', '0.8385', '0.8575']\n",
      "  [EdgeMLP] best mean val AUC = 0.8339\n",
      "Epoch 336 | train_loss(step) = 0.3357 | train_loss(eval) = 0.3379 | train_mean_auc = 0.8368 | val_mean_auc = 0.8338\n",
      "  train AUC per head: h0: 0.8406 | h1: 0.8059 | h2: 0.8401 | h3: 0.8606\n",
      "  val   AUC per head: h0: 0.8353 | h1: 0.8043 | h2: 0.8383 | h3: 0.8574\n",
      "  no improvement this epoch. no_improve_heads = [1, 1, 1, 1]\n",
      "Epoch 337 | train_loss(step) = 0.3462 | train_loss(eval) = 0.3379 | train_mean_auc = 0.8368 | val_mean_auc = 0.8339\n",
      "  train AUC per head: h0: 0.8406 | h1: 0.8060 | h2: 0.8401 | h3: 0.8605\n",
      "  val   AUC per head: h0: 0.8354 | h1: 0.8044 | h2: 0.8383 | h3: 0.8573\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8354', '0.8044', '0.8385', '0.8575']\n",
      "  [EdgeMLP] best mean val AUC = 0.8339\n",
      "Epoch 338 | train_loss(step) = 0.3336 | train_loss(eval) = 0.3379 | train_mean_auc = 0.8369 | val_mean_auc = 0.8339\n",
      "  train AUC per head: h0: 0.8406 | h1: 0.8062 | h2: 0.8405 | h3: 0.8604\n",
      "  val   AUC per head: h0: 0.8353 | h1: 0.8045 | h2: 0.8386 | h3: 0.8573\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8354', '0.8045', '0.8386', '0.8575']\n",
      "  [EdgeMLP] best mean val AUC = 0.8339\n",
      "Epoch 339 | train_loss(step) = 0.3428 | train_loss(eval) = 0.3377 | train_mean_auc = 0.8371 | val_mean_auc = 0.8341\n",
      "  train AUC per head: h0: 0.8408 | h1: 0.8064 | h2: 0.8409 | h3: 0.8605\n",
      "  val   AUC per head: h0: 0.8356 | h1: 0.8046 | h2: 0.8388 | h3: 0.8573\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8356', '0.8046', '0.8388', '0.8575']\n",
      "  [EdgeMLP] best mean val AUC = 0.8341\n",
      "Epoch 340 | train_loss(step) = 0.3391 | train_loss(eval) = 0.3375 | train_mean_auc = 0.8375 | val_mean_auc = 0.8343\n",
      "  train AUC per head: h0: 0.8412 | h1: 0.8067 | h2: 0.8414 | h3: 0.8606\n",
      "  val   AUC per head: h0: 0.8359 | h1: 0.8047 | h2: 0.8391 | h3: 0.8574\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8359', '0.8047', '0.8391', '0.8575']\n",
      "  [EdgeMLP] best mean val AUC = 0.8343\n",
      "Epoch 341 | train_loss(step) = 0.3388 | train_loss(eval) = 0.3374 | train_mean_auc = 0.8376 | val_mean_auc = 0.8343\n",
      "  train AUC per head: h0: 0.8413 | h1: 0.8068 | h2: 0.8417 | h3: 0.8606\n",
      "  val   AUC per head: h0: 0.8360 | h1: 0.8047 | h2: 0.8392 | h3: 0.8574\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8360', '0.8047', '0.8392', '0.8575']\n",
      "  [EdgeMLP] best mean val AUC = 0.8343\n",
      "Epoch 342 | train_loss(step) = 0.3453 | train_loss(eval) = 0.3374 | train_mean_auc = 0.8375 | val_mean_auc = 0.8341\n",
      "  train AUC per head: h0: 0.8411 | h1: 0.8068 | h2: 0.8416 | h3: 0.8606\n",
      "  val   AUC per head: h0: 0.8357 | h1: 0.8044 | h2: 0.8389 | h3: 0.8574\n",
      "  no improvement this epoch. no_improve_heads = [1, 2, 1, 7]\n",
      "Epoch 343 | train_loss(step) = 0.3342 | train_loss(eval) = 0.3375 | train_mean_auc = 0.8373 | val_mean_auc = 0.8338\n",
      "  train AUC per head: h0: 0.8408 | h1: 0.8067 | h2: 0.8413 | h3: 0.8604\n",
      "  val   AUC per head: h0: 0.8353 | h1: 0.8042 | h2: 0.8384 | h3: 0.8573\n",
      "  no improvement this epoch. no_improve_heads = [2, 3, 2, 8]\n",
      "Epoch 344 | train_loss(step) = 0.3425 | train_loss(eval) = 0.3375 | train_mean_auc = 0.8373 | val_mean_auc = 0.8337\n",
      "  train AUC per head: h0: 0.8407 | h1: 0.8068 | h2: 0.8412 | h3: 0.8604\n",
      "  val   AUC per head: h0: 0.8351 | h1: 0.8042 | h2: 0.8382 | h3: 0.8573\n",
      "  no improvement this epoch. no_improve_heads = [3, 4, 3, 9]\n",
      "Epoch 345 | train_loss(step) = 0.3425 | train_loss(eval) = 0.3375 | train_mean_auc = 0.8372 | val_mean_auc = 0.8336\n",
      "  train AUC per head: h0: 0.8403 | h1: 0.8068 | h2: 0.8413 | h3: 0.8605\n",
      "  val   AUC per head: h0: 0.8345 | h1: 0.8042 | h2: 0.8383 | h3: 0.8574\n",
      "  no improvement this epoch. no_improve_heads = [4, 5, 4, 10]\n",
      "Epoch 346 | train_loss(step) = 0.3329 | train_loss(eval) = 0.3377 | train_mean_auc = 0.8371 | val_mean_auc = 0.8334\n",
      "  train AUC per head: h0: 0.8398 | h1: 0.8066 | h2: 0.8414 | h3: 0.8607\n",
      "  val   AUC per head: h0: 0.8338 | h1: 0.8040 | h2: 0.8383 | h3: 0.8576\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8360', '0.8047', '0.8392', '0.8576']\n",
      "  [EdgeMLP] best mean val AUC = 0.8343\n",
      "Epoch 347 | train_loss(step) = 0.3338 | train_loss(eval) = 0.3378 | train_mean_auc = 0.8373 | val_mean_auc = 0.8335\n",
      "  train AUC per head: h0: 0.8398 | h1: 0.8066 | h2: 0.8417 | h3: 0.8609\n",
      "  val   AUC per head: h0: 0.8338 | h1: 0.8040 | h2: 0.8386 | h3: 0.8577\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8360', '0.8047', '0.8392', '0.8577']\n",
      "  [EdgeMLP] best mean val AUC = 0.8343\n",
      "Epoch 348 | train_loss(step) = 0.3305 | train_loss(eval) = 0.3372 | train_mean_auc = 0.8378 | val_mean_auc = 0.8341\n",
      "  train AUC per head: h0: 0.8409 | h1: 0.8072 | h2: 0.8422 | h3: 0.8609\n",
      "  val   AUC per head: h0: 0.8349 | h1: 0.8046 | h2: 0.8393 | h3: 0.8577\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8360', '0.8047', '0.8393', '0.8577']\n",
      "  [EdgeMLP] best mean val AUC = 0.8343\n",
      "Epoch 349 | train_loss(step) = 0.3385 | train_loss(eval) = 0.3371 | train_mean_auc = 0.8380 | val_mean_auc = 0.8344\n",
      "  train AUC per head: h0: 0.8414 | h1: 0.8075 | h2: 0.8424 | h3: 0.8609\n",
      "  val   AUC per head: h0: 0.8355 | h1: 0.8050 | h2: 0.8394 | h3: 0.8577\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8360', '0.8050', '0.8394', '0.8577']\n",
      "  [EdgeMLP] best mean val AUC = 0.8344\n",
      "Epoch 350 | train_loss(step) = 0.3418 | train_loss(eval) = 0.3387 | train_mean_auc = 0.8374 | val_mean_auc = 0.8338\n",
      "  train AUC per head: h0: 0.8406 | h1: 0.8067 | h2: 0.8414 | h3: 0.8609\n",
      "  val   AUC per head: h0: 0.8348 | h1: 0.8043 | h2: 0.8384 | h3: 0.8576\n",
      "  no improvement this epoch. no_improve_heads = [9, 1, 1, 2]\n",
      "Epoch 351 | train_loss(step) = 0.3412 | train_loss(eval) = 0.3376 | train_mean_auc = 0.8379 | val_mean_auc = 0.8343\n",
      "  train AUC per head: h0: 0.8411 | h1: 0.8074 | h2: 0.8421 | h3: 0.8609\n",
      "  val   AUC per head: h0: 0.8352 | h1: 0.8052 | h2: 0.8392 | h3: 0.8576\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8360', '0.8052', '0.8394', '0.8577']\n",
      "  [EdgeMLP] best mean val AUC = 0.8344\n",
      "Epoch 352 | train_loss(step) = 0.3387 | train_loss(eval) = 0.3370 | train_mean_auc = 0.8383 | val_mean_auc = 0.8348\n",
      "  train AUC per head: h0: 0.8413 | h1: 0.8081 | h2: 0.8427 | h3: 0.8611\n",
      "  val   AUC per head: h0: 0.8352 | h1: 0.8061 | h2: 0.8400 | h3: 0.8577\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8360', '0.8061', '0.8400', '0.8577']\n",
      "  [EdgeMLP] best mean val AUC = 0.8348\n",
      "Epoch 353 | train_loss(step) = 0.3360 | train_loss(eval) = 0.3381 | train_mean_auc = 0.8379 | val_mean_auc = 0.8346\n",
      "  train AUC per head: h0: 0.8404 | h1: 0.8079 | h2: 0.8424 | h3: 0.8611\n",
      "  val   AUC per head: h0: 0.8343 | h1: 0.8060 | h2: 0.8401 | h3: 0.8578\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8360', '0.8061', '0.8401', '0.8578']\n",
      "  [EdgeMLP] best mean val AUC = 0.8348\n",
      "Epoch 354 | train_loss(step) = 0.3354 | train_loss(eval) = 0.3379 | train_mean_auc = 0.8380 | val_mean_auc = 0.8348\n",
      "  train AUC per head: h0: 0.8408 | h1: 0.8079 | h2: 0.8424 | h3: 0.8611\n",
      "  val   AUC per head: h0: 0.8349 | h1: 0.8061 | h2: 0.8402 | h3: 0.8578\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8360', '0.8061', '0.8402', '0.8578']\n",
      "  [EdgeMLP] best mean val AUC = 0.8348\n",
      "Epoch 355 | train_loss(step) = 0.3398 | train_loss(eval) = 0.3370 | train_mean_auc = 0.8382 | val_mean_auc = 0.8350\n",
      "  train AUC per head: h0: 0.8415 | h1: 0.8079 | h2: 0.8424 | h3: 0.8611\n",
      "  val   AUC per head: h0: 0.8360 | h1: 0.8062 | h2: 0.8403 | h3: 0.8578\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8360', '0.8062', '0.8403', '0.8578']\n",
      "  [EdgeMLP] best mean val AUC = 0.8350\n",
      "Epoch 356 | train_loss(step) = 0.3397 | train_loss(eval) = 0.3374 | train_mean_auc = 0.8378 | val_mean_auc = 0.8347\n",
      "  train AUC per head: h0: 0.8412 | h1: 0.8073 | h2: 0.8416 | h3: 0.8610\n",
      "  val   AUC per head: h0: 0.8360 | h1: 0.8056 | h2: 0.8394 | h3: 0.8578\n",
      "  no improvement this epoch. no_improve_heads = [15, 1, 1, 2]\n",
      "Epoch 357 | train_loss(step) = 0.3297 | train_loss(eval) = 0.3373 | train_mean_auc = 0.8379 | val_mean_auc = 0.8349\n",
      "  train AUC per head: h0: 0.8414 | h1: 0.8077 | h2: 0.8417 | h3: 0.8610\n",
      "  val   AUC per head: h0: 0.8363 | h1: 0.8059 | h2: 0.8395 | h3: 0.8578\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8363', '0.8062', '0.8403', '0.8578']\n",
      "  [EdgeMLP] best mean val AUC = 0.8350\n",
      "Epoch 358 | train_loss(step) = 0.3383 | train_loss(eval) = 0.3364 | train_mean_auc = 0.8386 | val_mean_auc = 0.8356\n",
      "  train AUC per head: h0: 0.8422 | h1: 0.8085 | h2: 0.8428 | h3: 0.8610\n",
      "  val   AUC per head: h0: 0.8371 | h1: 0.8066 | h2: 0.8407 | h3: 0.8578\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8371', '0.8066', '0.8407', '0.8578']\n",
      "  [EdgeMLP] best mean val AUC = 0.8356\n",
      "Epoch 359 | train_loss(step) = 0.3315 | train_loss(eval) = 0.3367 | train_mean_auc = 0.8387 | val_mean_auc = 0.8355\n",
      "  train AUC per head: h0: 0.8420 | h1: 0.8083 | h2: 0.8433 | h3: 0.8611\n",
      "  val   AUC per head: h0: 0.8369 | h1: 0.8062 | h2: 0.8412 | h3: 0.8579\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8371', '0.8066', '0.8412', '0.8579']\n",
      "  [EdgeMLP] best mean val AUC = 0.8356\n",
      "Epoch 360 | train_loss(step) = 0.3340 | train_loss(eval) = 0.3374 | train_mean_auc = 0.8383 | val_mean_auc = 0.8351\n",
      "  train AUC per head: h0: 0.8413 | h1: 0.8079 | h2: 0.8431 | h3: 0.8612\n",
      "  val   AUC per head: h0: 0.8360 | h1: 0.8057 | h2: 0.8408 | h3: 0.8580\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8371', '0.8066', '0.8412', '0.8580']\n",
      "  [EdgeMLP] best mean val AUC = 0.8356\n",
      "Epoch 361 | train_loss(step) = 0.3356 | train_loss(eval) = 0.3372 | train_mean_auc = 0.8383 | val_mean_auc = 0.8350\n",
      "  train AUC per head: h0: 0.8410 | h1: 0.8080 | h2: 0.8427 | h3: 0.8613\n",
      "  val   AUC per head: h0: 0.8358 | h1: 0.8057 | h2: 0.8403 | h3: 0.8580\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8371', '0.8066', '0.8412', '0.8580']\n",
      "  [EdgeMLP] best mean val AUC = 0.8356\n",
      "Epoch 362 | train_loss(step) = 0.3377 | train_loss(eval) = 0.3367 | train_mean_auc = 0.8384 | val_mean_auc = 0.8350\n",
      "  train AUC per head: h0: 0.8413 | h1: 0.8086 | h2: 0.8425 | h3: 0.8613\n",
      "  val   AUC per head: h0: 0.8361 | h1: 0.8062 | h2: 0.8399 | h3: 0.8580\n",
      "  no improvement this epoch. no_improve_heads = [4, 4, 3, 1]\n",
      "Epoch 363 | train_loss(step) = 0.3414 | train_loss(eval) = 0.3367 | train_mean_auc = 0.8385 | val_mean_auc = 0.8350\n",
      "  train AUC per head: h0: 0.8416 | h1: 0.8087 | h2: 0.8424 | h3: 0.8613\n",
      "  val   AUC per head: h0: 0.8363 | h1: 0.8061 | h2: 0.8395 | h3: 0.8580\n",
      "  no improvement this epoch. no_improve_heads = [5, 5, 4, 2]\n",
      "Epoch 364 | train_loss(step) = 0.3388 | train_loss(eval) = 0.3367 | train_mean_auc = 0.8387 | val_mean_auc = 0.8350\n",
      "  train AUC per head: h0: 0.8419 | h1: 0.8089 | h2: 0.8427 | h3: 0.8612\n",
      "  val   AUC per head: h0: 0.8365 | h1: 0.8062 | h2: 0.8395 | h3: 0.8579\n",
      "  no improvement this epoch. no_improve_heads = [6, 6, 5, 3]\n",
      "Epoch 365 | train_loss(step) = 0.3311 | train_loss(eval) = 0.3361 | train_mean_auc = 0.8391 | val_mean_auc = 0.8353\n",
      "  train AUC per head: h0: 0.8423 | h1: 0.8095 | h2: 0.8434 | h3: 0.8612\n",
      "  val   AUC per head: h0: 0.8366 | h1: 0.8066 | h2: 0.8400 | h3: 0.8579\n",
      "  no improvement this epoch. no_improve_heads = [7, 7, 6, 4]\n",
      "Epoch 366 | train_loss(step) = 0.3424 | train_loss(eval) = 0.3363 | train_mean_auc = 0.8392 | val_mean_auc = 0.8352\n",
      "  train AUC per head: h0: 0.8420 | h1: 0.8097 | h2: 0.8438 | h3: 0.8612\n",
      "  val   AUC per head: h0: 0.8361 | h1: 0.8068 | h2: 0.8402 | h3: 0.8578\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8371', '0.8068', '0.8412', '0.8580']\n",
      "  [EdgeMLP] best mean val AUC = 0.8356\n",
      "Epoch 367 | train_loss(step) = 0.3364 | train_loss(eval) = 0.3367 | train_mean_auc = 0.8391 | val_mean_auc = 0.8351\n",
      "  train AUC per head: h0: 0.8418 | h1: 0.8098 | h2: 0.8438 | h3: 0.8612\n",
      "  val   AUC per head: h0: 0.8357 | h1: 0.8068 | h2: 0.8401 | h3: 0.8578\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8371', '0.8068', '0.8412', '0.8580']\n",
      "  [EdgeMLP] best mean val AUC = 0.8356\n",
      "Epoch 368 | train_loss(step) = 0.3305 | train_loss(eval) = 0.3365 | train_mean_auc = 0.8392 | val_mean_auc = 0.8352\n",
      "  train AUC per head: h0: 0.8419 | h1: 0.8099 | h2: 0.8438 | h3: 0.8611\n",
      "  val   AUC per head: h0: 0.8359 | h1: 0.8070 | h2: 0.8401 | h3: 0.8577\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8371', '0.8070', '0.8412', '0.8580']\n",
      "  [EdgeMLP] best mean val AUC = 0.8356\n",
      "Epoch 369 | train_loss(step) = 0.3363 | train_loss(eval) = 0.3359 | train_mean_auc = 0.8392 | val_mean_auc = 0.8353\n",
      "  train AUC per head: h0: 0.8425 | h1: 0.8096 | h2: 0.8436 | h3: 0.8611\n",
      "  val   AUC per head: h0: 0.8366 | h1: 0.8068 | h2: 0.8400 | h3: 0.8576\n",
      "  no improvement this epoch. no_improve_heads = [11, 1, 10, 8]\n",
      "Epoch 370 | train_loss(step) = 0.3347 | train_loss(eval) = 0.3363 | train_mean_auc = 0.8388 | val_mean_auc = 0.8350\n",
      "  train AUC per head: h0: 0.8425 | h1: 0.8089 | h2: 0.8429 | h3: 0.8609\n",
      "  val   AUC per head: h0: 0.8368 | h1: 0.8063 | h2: 0.8394 | h3: 0.8575\n",
      "  no improvement this epoch. no_improve_heads = [12, 2, 11, 9]\n",
      "Epoch 371 | train_loss(step) = 0.3345 | train_loss(eval) = 0.3367 | train_mean_auc = 0.8385 | val_mean_auc = 0.8349\n",
      "  train AUC per head: h0: 0.8424 | h1: 0.8086 | h2: 0.8425 | h3: 0.8608\n",
      "  val   AUC per head: h0: 0.8368 | h1: 0.8061 | h2: 0.8392 | h3: 0.8574\n",
      "  no improvement this epoch. no_improve_heads = [13, 3, 12, 10]\n",
      "Epoch 372 | train_loss(step) = 0.3446 | train_loss(eval) = 0.3363 | train_mean_auc = 0.8388 | val_mean_auc = 0.8352\n",
      "  train AUC per head: h0: 0.8425 | h1: 0.8092 | h2: 0.8427 | h3: 0.8607\n",
      "  val   AUC per head: h0: 0.8370 | h1: 0.8070 | h2: 0.8396 | h3: 0.8573\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8371', '0.8070', '0.8412', '0.8580']\n",
      "  [EdgeMLP] best mean val AUC = 0.8356\n",
      "Epoch 373 | train_loss(step) = 0.3333 | train_loss(eval) = 0.3357 | train_mean_auc = 0.8391 | val_mean_auc = 0.8356\n",
      "  train AUC per head: h0: 0.8424 | h1: 0.8100 | h2: 0.8433 | h3: 0.8607\n",
      "  val   AUC per head: h0: 0.8368 | h1: 0.8079 | h2: 0.8404 | h3: 0.8573\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8371', '0.8079', '0.8412', '0.8580']\n",
      "  [EdgeMLP] best mean val AUC = 0.8356\n",
      "Epoch 374 | train_loss(step) = 0.3329 | train_loss(eval) = 0.3359 | train_mean_auc = 0.8391 | val_mean_auc = 0.8357\n",
      "  train AUC per head: h0: 0.8420 | h1: 0.8102 | h2: 0.8435 | h3: 0.8608\n",
      "  val   AUC per head: h0: 0.8365 | h1: 0.8082 | h2: 0.8408 | h3: 0.8574\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8371', '0.8082', '0.8412', '0.8580']\n",
      "  [EdgeMLP] best mean val AUC = 0.8357\n",
      "Epoch 375 | train_loss(step) = 0.3333 | train_loss(eval) = 0.3360 | train_mean_auc = 0.8391 | val_mean_auc = 0.8358\n",
      "  train AUC per head: h0: 0.8420 | h1: 0.8102 | h2: 0.8436 | h3: 0.8608\n",
      "  val   AUC per head: h0: 0.8365 | h1: 0.8083 | h2: 0.8409 | h3: 0.8574\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8371', '0.8083', '0.8412', '0.8580']\n",
      "  [EdgeMLP] best mean val AUC = 0.8358\n",
      "Epoch 376 | train_loss(step) = 0.3265 | train_loss(eval) = 0.3359 | train_mean_auc = 0.8393 | val_mean_auc = 0.8359\n",
      "  train AUC per head: h0: 0.8423 | h1: 0.8102 | h2: 0.8438 | h3: 0.8609\n",
      "  val   AUC per head: h0: 0.8369 | h1: 0.8082 | h2: 0.8410 | h3: 0.8575\n",
      "  no improvement this epoch. no_improve_heads = [18, 1, 17, 15]\n",
      "Epoch 377 | train_loss(step) = 0.3360 | train_loss(eval) = 0.3358 | train_mean_auc = 0.8394 | val_mean_auc = 0.8360\n",
      "  train AUC per head: h0: 0.8425 | h1: 0.8100 | h2: 0.8439 | h3: 0.8609\n",
      "  val   AUC per head: h0: 0.8372 | h1: 0.8080 | h2: 0.8411 | h3: 0.8575\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8372', '0.8083', '0.8412', '0.8580']\n",
      "  [EdgeMLP] best mean val AUC = 0.8360\n",
      "Epoch 378 | train_loss(step) = 0.3348 | train_loss(eval) = 0.3356 | train_mean_auc = 0.8393 | val_mean_auc = 0.8359\n",
      "  train AUC per head: h0: 0.8427 | h1: 0.8098 | h2: 0.8437 | h3: 0.8609\n",
      "  val   AUC per head: h0: 0.8375 | h1: 0.8078 | h2: 0.8407 | h3: 0.8576\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8375', '0.8083', '0.8412', '0.8580']\n",
      "  [EdgeMLP] best mean val AUC = 0.8360\n",
      "Epoch 379 | train_loss(step) = 0.3414 | train_loss(eval) = 0.3360 | train_mean_auc = 0.8391 | val_mean_auc = 0.8357\n",
      "  train AUC per head: h0: 0.8424 | h1: 0.8096 | h2: 0.8434 | h3: 0.8609\n",
      "  val   AUC per head: h0: 0.8374 | h1: 0.8075 | h2: 0.8403 | h3: 0.8576\n",
      "  no improvement this epoch. no_improve_heads = [1, 4, 20, 18]\n",
      "Epoch 380 | train_loss(step) = 0.3281 | train_loss(eval) = 0.3358 | train_mean_auc = 0.8393 | val_mean_auc = 0.8359\n",
      "  train AUC per head: h0: 0.8427 | h1: 0.8100 | h2: 0.8436 | h3: 0.8609\n",
      "  val   AUC per head: h0: 0.8375 | h1: 0.8078 | h2: 0.8406 | h3: 0.8576\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8375', '0.8083', '0.8412', '0.8580']\n",
      "  [EdgeMLP] best mean val AUC = 0.8360\n",
      "Epoch 381 | train_loss(step) = 0.3325 | train_loss(eval) = 0.3354 | train_mean_auc = 0.8396 | val_mean_auc = 0.8362\n",
      "  train AUC per head: h0: 0.8429 | h1: 0.8105 | h2: 0.8441 | h3: 0.8610\n",
      "  val   AUC per head: h0: 0.8376 | h1: 0.8083 | h2: 0.8410 | h3: 0.8577\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8376', '0.8083', '0.8412', '0.8580']\n",
      "  [EdgeMLP] best mean val AUC = 0.8362\n",
      "Epoch 382 | train_loss(step) = 0.3353 | train_loss(eval) = 0.3354 | train_mean_auc = 0.8397 | val_mean_auc = 0.8362\n",
      "  train AUC per head: h0: 0.8428 | h1: 0.8107 | h2: 0.8444 | h3: 0.8611\n",
      "  val   AUC per head: h0: 0.8373 | h1: 0.8085 | h2: 0.8413 | h3: 0.8578\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8376', '0.8085', '0.8413', '0.8580']\n",
      "  [EdgeMLP] best mean val AUC = 0.8362\n",
      "Epoch 383 | train_loss(step) = 0.3350 | train_loss(eval) = 0.3357 | train_mean_auc = 0.8396 | val_mean_auc = 0.8361\n",
      "  train AUC per head: h0: 0.8425 | h1: 0.8105 | h2: 0.8443 | h3: 0.8611\n",
      "  val   AUC per head: h0: 0.8368 | h1: 0.8083 | h2: 0.8412 | h3: 0.8579\n",
      "  no improvement this epoch. no_improve_heads = [2, 1, 1, 22]\n",
      "Epoch 384 | train_loss(step) = 0.3354 | train_loss(eval) = 0.3355 | train_mean_auc = 0.8396 | val_mean_auc = 0.8360\n",
      "  train AUC per head: h0: 0.8425 | h1: 0.8106 | h2: 0.8442 | h3: 0.8612\n",
      "  val   AUC per head: h0: 0.8368 | h1: 0.8084 | h2: 0.8411 | h3: 0.8580\n",
      "  no improvement this epoch. no_improve_heads = [3, 2, 2, 23]\n",
      "Epoch 385 | train_loss(step) = 0.3367 | train_loss(eval) = 0.3354 | train_mean_auc = 0.8396 | val_mean_auc = 0.8360\n",
      "  train AUC per head: h0: 0.8427 | h1: 0.8106 | h2: 0.8439 | h3: 0.8612\n",
      "  val   AUC per head: h0: 0.8370 | h1: 0.8084 | h2: 0.8407 | h3: 0.8580\n",
      "  no improvement this epoch. no_improve_heads = [4, 3, 3, 24]\n",
      "Epoch 386 | train_loss(step) = 0.3369 | train_loss(eval) = 0.3357 | train_mean_auc = 0.8395 | val_mean_auc = 0.8359\n",
      "  train AUC per head: h0: 0.8427 | h1: 0.8103 | h2: 0.8437 | h3: 0.8612\n",
      "  val   AUC per head: h0: 0.8371 | h1: 0.8081 | h2: 0.8404 | h3: 0.8580\n",
      "  no improvement this epoch. no_improve_heads = [5, 4, 4, 25]\n",
      "Epoch 387 | train_loss(step) = 0.3362 | train_loss(eval) = 0.3354 | train_mean_auc = 0.8397 | val_mean_auc = 0.8361\n",
      "  train AUC per head: h0: 0.8429 | h1: 0.8105 | h2: 0.8441 | h3: 0.8613\n",
      "  val   AUC per head: h0: 0.8373 | h1: 0.8083 | h2: 0.8409 | h3: 0.8580\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8376', '0.8085', '0.8413', '0.8580']\n",
      "  [EdgeMLP] best mean val AUC = 0.8362\n",
      "Epoch 388 | train_loss(step) = 0.3406 | train_loss(eval) = 0.3350 | train_mean_auc = 0.8402 | val_mean_auc = 0.8366\n",
      "  train AUC per head: h0: 0.8431 | h1: 0.8111 | h2: 0.8451 | h3: 0.8613\n",
      "  val   AUC per head: h0: 0.8374 | h1: 0.8089 | h2: 0.8419 | h3: 0.8580\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8376', '0.8089', '0.8419', '0.8580']\n",
      "  [EdgeMLP] best mean val AUC = 0.8366\n",
      "Epoch 389 | train_loss(step) = 0.3315 | train_loss(eval) = 0.3350 | train_mean_auc = 0.8404 | val_mean_auc = 0.8368\n",
      "  train AUC per head: h0: 0.8433 | h1: 0.8114 | h2: 0.8455 | h3: 0.8613\n",
      "  val   AUC per head: h0: 0.8376 | h1: 0.8091 | h2: 0.8424 | h3: 0.8580\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8376', '0.8091', '0.8424', '0.8580']\n",
      "  [EdgeMLP] best mean val AUC = 0.8368\n",
      "Epoch 390 | train_loss(step) = 0.3295 | train_loss(eval) = 0.3349 | train_mean_auc = 0.8404 | val_mean_auc = 0.8368\n",
      "  train AUC per head: h0: 0.8435 | h1: 0.8113 | h2: 0.8456 | h3: 0.8613\n",
      "  val   AUC per head: h0: 0.8378 | h1: 0.8090 | h2: 0.8425 | h3: 0.8579\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8378', '0.8091', '0.8425', '0.8580']\n",
      "  [EdgeMLP] best mean val AUC = 0.8368\n",
      "Epoch 391 | train_loss(step) = 0.3287 | train_loss(eval) = 0.3349 | train_mean_auc = 0.8404 | val_mean_auc = 0.8368\n",
      "  train AUC per head: h0: 0.8434 | h1: 0.8113 | h2: 0.8457 | h3: 0.8613\n",
      "  val   AUC per head: h0: 0.8378 | h1: 0.8089 | h2: 0.8426 | h3: 0.8579\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8378', '0.8091', '0.8426', '0.8580']\n",
      "  [EdgeMLP] best mean val AUC = 0.8368\n",
      "Epoch 392 | train_loss(step) = 0.3397 | train_loss(eval) = 0.3349 | train_mean_auc = 0.8405 | val_mean_auc = 0.8368\n",
      "  train AUC per head: h0: 0.8434 | h1: 0.8113 | h2: 0.8456 | h3: 0.8614\n",
      "  val   AUC per head: h0: 0.8379 | h1: 0.8089 | h2: 0.8426 | h3: 0.8580\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8379', '0.8091', '0.8426', '0.8580']\n",
      "  [EdgeMLP] best mean val AUC = 0.8368\n",
      "Epoch 393 | train_loss(step) = 0.3266 | train_loss(eval) = 0.3349 | train_mean_auc = 0.8404 | val_mean_auc = 0.8368\n",
      "  train AUC per head: h0: 0.8433 | h1: 0.8114 | h2: 0.8456 | h3: 0.8615\n",
      "  val   AUC per head: h0: 0.8377 | h1: 0.8089 | h2: 0.8425 | h3: 0.8581\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8379', '0.8091', '0.8426', '0.8581']\n",
      "  [EdgeMLP] best mean val AUC = 0.8368\n",
      "Epoch 394 | train_loss(step) = 0.3491 | train_loss(eval) = 0.3348 | train_mean_auc = 0.8405 | val_mean_auc = 0.8369\n",
      "  train AUC per head: h0: 0.8437 | h1: 0.8112 | h2: 0.8455 | h3: 0.8615\n",
      "  val   AUC per head: h0: 0.8382 | h1: 0.8088 | h2: 0.8423 | h3: 0.8581\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8382', '0.8091', '0.8426', '0.8581']\n",
      "  [EdgeMLP] best mean val AUC = 0.8369\n",
      "Epoch 395 | train_loss(step) = 0.3368 | train_loss(eval) = 0.3351 | train_mean_auc = 0.8404 | val_mean_auc = 0.8369\n",
      "  train AUC per head: h0: 0.8438 | h1: 0.8112 | h2: 0.8454 | h3: 0.8614\n",
      "  val   AUC per head: h0: 0.8384 | h1: 0.8089 | h2: 0.8421 | h3: 0.8581\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8384', '0.8091', '0.8426', '0.8581']\n",
      "  [EdgeMLP] best mean val AUC = 0.8369\n",
      "Epoch 396 | train_loss(step) = 0.3331 | train_loss(eval) = 0.3350 | train_mean_auc = 0.8405 | val_mean_auc = 0.8369\n",
      "  train AUC per head: h0: 0.8439 | h1: 0.8114 | h2: 0.8454 | h3: 0.8615\n",
      "  val   AUC per head: h0: 0.8385 | h1: 0.8091 | h2: 0.8420 | h3: 0.8582\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8385', '0.8091', '0.8426', '0.8582']\n",
      "  [EdgeMLP] best mean val AUC = 0.8369\n",
      "Epoch 397 | train_loss(step) = 0.3380 | train_loss(eval) = 0.3345 | train_mean_auc = 0.8407 | val_mean_auc = 0.8370\n",
      "  train AUC per head: h0: 0.8435 | h1: 0.8120 | h2: 0.8454 | h3: 0.8617\n",
      "  val   AUC per head: h0: 0.8380 | h1: 0.8097 | h2: 0.8420 | h3: 0.8584\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8385', '0.8097', '0.8426', '0.8584']\n",
      "  [EdgeMLP] best mean val AUC = 0.8370\n",
      "Epoch 398 | train_loss(step) = 0.3303 | train_loss(eval) = 0.3352 | train_mean_auc = 0.8404 | val_mean_auc = 0.8366\n",
      "  train AUC per head: h0: 0.8427 | h1: 0.8118 | h2: 0.8451 | h3: 0.8619\n",
      "  val   AUC per head: h0: 0.8370 | h1: 0.8093 | h2: 0.8417 | h3: 0.8585\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8385', '0.8097', '0.8426', '0.8585']\n",
      "  [EdgeMLP] best mean val AUC = 0.8370\n",
      "Epoch 399 | train_loss(step) = 0.3302 | train_loss(eval) = 0.3358 | train_mean_auc = 0.8402 | val_mean_auc = 0.8364\n",
      "  train AUC per head: h0: 0.8422 | h1: 0.8115 | h2: 0.8449 | h3: 0.8620\n",
      "  val   AUC per head: h0: 0.8365 | h1: 0.8090 | h2: 0.8415 | h3: 0.8585\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8385', '0.8097', '0.8426', '0.8585']\n",
      "  [EdgeMLP] best mean val AUC = 0.8370\n",
      "Epoch 400 | train_loss(step) = 0.3433 | train_loss(eval) = 0.3353 | train_mean_auc = 0.8404 | val_mean_auc = 0.8366\n",
      "  train AUC per head: h0: 0.8427 | h1: 0.8117 | h2: 0.8450 | h3: 0.8620\n",
      "  val   AUC per head: h0: 0.8371 | h1: 0.8092 | h2: 0.8416 | h3: 0.8585\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8385', '0.8097', '0.8426', '0.8585']\n",
      "  [EdgeMLP] best mean val AUC = 0.8370\n",
      "Epoch 401 | train_loss(step) = 0.3328 | train_loss(eval) = 0.3347 | train_mean_auc = 0.8405 | val_mean_auc = 0.8368\n",
      "  train AUC per head: h0: 0.8433 | h1: 0.8118 | h2: 0.8448 | h3: 0.8620\n",
      "  val   AUC per head: h0: 0.8380 | h1: 0.8094 | h2: 0.8414 | h3: 0.8585\n",
      "  no improvement this epoch. no_improve_heads = [5, 4, 9, 1]\n",
      "Epoch 402 | train_loss(step) = 0.3256 | train_loss(eval) = 0.3351 | train_mean_auc = 0.8401 | val_mean_auc = 0.8366\n",
      "  train AUC per head: h0: 0.8431 | h1: 0.8113 | h2: 0.8441 | h3: 0.8621\n",
      "  val   AUC per head: h0: 0.8381 | h1: 0.8089 | h2: 0.8408 | h3: 0.8585\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8385', '0.8097', '0.8426', '0.8585']\n",
      "  [EdgeMLP] best mean val AUC = 0.8370\n",
      "Epoch 403 | train_loss(step) = 0.3313 | train_loss(eval) = 0.3352 | train_mean_auc = 0.8400 | val_mean_auc = 0.8365\n",
      "  train AUC per head: h0: 0.8431 | h1: 0.8110 | h2: 0.8439 | h3: 0.8621\n",
      "  val   AUC per head: h0: 0.8381 | h1: 0.8086 | h2: 0.8406 | h3: 0.8585\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8385', '0.8097', '0.8426', '0.8585']\n",
      "  [EdgeMLP] best mean val AUC = 0.8370\n",
      "Epoch 404 | train_loss(step) = 0.3364 | train_loss(eval) = 0.3346 | train_mean_auc = 0.8406 | val_mean_auc = 0.8370\n",
      "  train AUC per head: h0: 0.8436 | h1: 0.8117 | h2: 0.8449 | h3: 0.8621\n",
      "  val   AUC per head: h0: 0.8386 | h1: 0.8091 | h2: 0.8416 | h3: 0.8586\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8386', '0.8097', '0.8426', '0.8586']\n",
      "  [EdgeMLP] best mean val AUC = 0.8370\n",
      "Epoch 405 | train_loss(step) = 0.3416 | train_loss(eval) = 0.3343 | train_mean_auc = 0.8411 | val_mean_auc = 0.8374\n",
      "  train AUC per head: h0: 0.8440 | h1: 0.8124 | h2: 0.8459 | h3: 0.8621\n",
      "  val   AUC per head: h0: 0.8387 | h1: 0.8096 | h2: 0.8426 | h3: 0.8585\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8387', '0.8097', '0.8426', '0.8586']\n",
      "  [EdgeMLP] best mean val AUC = 0.8374\n",
      "Epoch 406 | train_loss(step) = 0.3424 | train_loss(eval) = 0.3342 | train_mean_auc = 0.8413 | val_mean_auc = 0.8375\n",
      "  train AUC per head: h0: 0.8440 | h1: 0.8127 | h2: 0.8463 | h3: 0.8620\n",
      "  val   AUC per head: h0: 0.8386 | h1: 0.8099 | h2: 0.8429 | h3: 0.8584\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8387', '0.8099', '0.8429', '0.8586']\n",
      "  [EdgeMLP] best mean val AUC = 0.8375\n",
      "Epoch 407 | train_loss(step) = 0.3331 | train_loss(eval) = 0.3340 | train_mean_auc = 0.8413 | val_mean_auc = 0.8374\n",
      "  train AUC per head: h0: 0.8440 | h1: 0.8128 | h2: 0.8463 | h3: 0.8620\n",
      "  val   AUC per head: h0: 0.8384 | h1: 0.8099 | h2: 0.8428 | h3: 0.8584\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8387', '0.8099', '0.8429', '0.8586']\n",
      "  [EdgeMLP] best mean val AUC = 0.8375\n",
      "Epoch 408 | train_loss(step) = 0.3390 | train_loss(eval) = 0.3340 | train_mean_auc = 0.8413 | val_mean_auc = 0.8374\n",
      "  train AUC per head: h0: 0.8440 | h1: 0.8128 | h2: 0.8462 | h3: 0.8620\n",
      "  val   AUC per head: h0: 0.8385 | h1: 0.8099 | h2: 0.8426 | h3: 0.8584\n",
      "  no improvement this epoch. no_improve_heads = [3, 1, 2, 4]\n",
      "Epoch 409 | train_loss(step) = 0.3367 | train_loss(eval) = 0.3343 | train_mean_auc = 0.8412 | val_mean_auc = 0.8372\n",
      "  train AUC per head: h0: 0.8439 | h1: 0.8127 | h2: 0.8460 | h3: 0.8621\n",
      "  val   AUC per head: h0: 0.8384 | h1: 0.8097 | h2: 0.8424 | h3: 0.8584\n",
      "  no improvement this epoch. no_improve_heads = [4, 2, 3, 5]\n",
      "Epoch 410 | train_loss(step) = 0.3296 | train_loss(eval) = 0.3342 | train_mean_auc = 0.8411 | val_mean_auc = 0.8372\n",
      "  train AUC per head: h0: 0.8435 | h1: 0.8128 | h2: 0.8460 | h3: 0.8621\n",
      "  val   AUC per head: h0: 0.8379 | h1: 0.8098 | h2: 0.8425 | h3: 0.8584\n",
      "  no improvement this epoch. no_improve_heads = [5, 3, 4, 6]\n",
      "Epoch 411 | train_loss(step) = 0.3250 | train_loss(eval) = 0.3344 | train_mean_auc = 0.8410 | val_mean_auc = 0.8371\n",
      "  train AUC per head: h0: 0.8431 | h1: 0.8128 | h2: 0.8461 | h3: 0.8621\n",
      "  val   AUC per head: h0: 0.8375 | h1: 0.8097 | h2: 0.8427 | h3: 0.8584\n",
      "  no improvement this epoch. no_improve_heads = [6, 4, 5, 7]\n",
      "Epoch 412 | train_loss(step) = 0.3418 | train_loss(eval) = 0.3349 | train_mean_auc = 0.8409 | val_mean_auc = 0.8370\n",
      "  train AUC per head: h0: 0.8430 | h1: 0.8125 | h2: 0.8461 | h3: 0.8622\n",
      "  val   AUC per head: h0: 0.8374 | h1: 0.8093 | h2: 0.8428 | h3: 0.8585\n",
      "  no improvement this epoch. no_improve_heads = [7, 5, 6, 8]\n",
      "Epoch 413 | train_loss(step) = 0.3369 | train_loss(eval) = 0.3345 | train_mean_auc = 0.8411 | val_mean_auc = 0.8373\n",
      "  train AUC per head: h0: 0.8435 | h1: 0.8126 | h2: 0.8462 | h3: 0.8622\n",
      "  val   AUC per head: h0: 0.8380 | h1: 0.8095 | h2: 0.8430 | h3: 0.8586\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8387', '0.8099', '0.8430', '0.8586']\n",
      "  [EdgeMLP] best mean val AUC = 0.8375\n",
      "Epoch 414 | train_loss(step) = 0.3388 | train_loss(eval) = 0.3341 | train_mean_auc = 0.8412 | val_mean_auc = 0.8375\n",
      "  train AUC per head: h0: 0.8438 | h1: 0.8128 | h2: 0.8461 | h3: 0.8622\n",
      "  val   AUC per head: h0: 0.8384 | h1: 0.8099 | h2: 0.8429 | h3: 0.8586\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8387', '0.8099', '0.8430', '0.8586']\n",
      "  [EdgeMLP] best mean val AUC = 0.8375\n",
      "Epoch 415 | train_loss(step) = 0.3430 | train_loss(eval) = 0.3344 | train_mean_auc = 0.8411 | val_mean_auc = 0.8374\n",
      "  train AUC per head: h0: 0.8438 | h1: 0.8126 | h2: 0.8457 | h3: 0.8621\n",
      "  val   AUC per head: h0: 0.8385 | h1: 0.8099 | h2: 0.8426 | h3: 0.8585\n",
      "  no improvement this epoch. no_improve_heads = [10, 8, 2, 1]\n",
      "Epoch 416 | train_loss(step) = 0.3311 | train_loss(eval) = 0.3344 | train_mean_auc = 0.8412 | val_mean_auc = 0.8376\n",
      "  train AUC per head: h0: 0.8441 | h1: 0.8129 | h2: 0.8459 | h3: 0.8619\n",
      "  val   AUC per head: h0: 0.8387 | h1: 0.8103 | h2: 0.8429 | h3: 0.8584\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8387', '0.8103', '0.8430', '0.8586']\n",
      "  [EdgeMLP] best mean val AUC = 0.8376\n",
      "Epoch 417 | train_loss(step) = 0.3389 | train_loss(eval) = 0.3339 | train_mean_auc = 0.8414 | val_mean_auc = 0.8377\n",
      "  train AUC per head: h0: 0.8442 | h1: 0.8132 | h2: 0.8463 | h3: 0.8620\n",
      "  val   AUC per head: h0: 0.8384 | h1: 0.8107 | h2: 0.8434 | h3: 0.8585\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8387', '0.8107', '0.8434', '0.8586']\n",
      "  [EdgeMLP] best mean val AUC = 0.8377\n",
      "Epoch 418 | train_loss(step) = 0.3459 | train_loss(eval) = 0.3345 | train_mean_auc = 0.8409 | val_mean_auc = 0.8372\n",
      "  train AUC per head: h0: 0.8429 | h1: 0.8125 | h2: 0.8459 | h3: 0.8621\n",
      "  val   AUC per head: h0: 0.8369 | h1: 0.8100 | h2: 0.8431 | h3: 0.8586\n",
      "  no improvement this epoch. no_improve_heads = [13, 1, 1, 4]\n",
      "Epoch 419 | train_loss(step) = 0.3395 | train_loss(eval) = 0.3349 | train_mean_auc = 0.8405 | val_mean_auc = 0.8368\n",
      "  train AUC per head: h0: 0.8419 | h1: 0.8122 | h2: 0.8457 | h3: 0.8623\n",
      "  val   AUC per head: h0: 0.8360 | h1: 0.8098 | h2: 0.8429 | h3: 0.8587\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8387', '0.8107', '0.8434', '0.8587']\n",
      "  [EdgeMLP] best mean val AUC = 0.8377\n",
      "Epoch 420 | train_loss(step) = 0.3358 | train_loss(eval) = 0.3348 | train_mean_auc = 0.8406 | val_mean_auc = 0.8370\n",
      "  train AUC per head: h0: 0.8419 | h1: 0.8124 | h2: 0.8457 | h3: 0.8624\n",
      "  val   AUC per head: h0: 0.8360 | h1: 0.8102 | h2: 0.8430 | h3: 0.8587\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8387', '0.8107', '0.8434', '0.8587']\n",
      "  [EdgeMLP] best mean val AUC = 0.8377\n",
      "Epoch 421 | train_loss(step) = 0.3341 | train_loss(eval) = 0.3345 | train_mean_auc = 0.8411 | val_mean_auc = 0.8375\n",
      "  train AUC per head: h0: 0.8430 | h1: 0.8132 | h2: 0.8459 | h3: 0.8624\n",
      "  val   AUC per head: h0: 0.8372 | h1: 0.8109 | h2: 0.8432 | h3: 0.8588\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8387', '0.8109', '0.8434', '0.8588']\n",
      "  [EdgeMLP] best mean val AUC = 0.8377\n",
      "Epoch 422 | train_loss(step) = 0.3405 | train_loss(eval) = 0.3345 | train_mean_auc = 0.8414 | val_mean_auc = 0.8377\n",
      "  train AUC per head: h0: 0.8439 | h1: 0.8134 | h2: 0.8457 | h3: 0.8624\n",
      "  val   AUC per head: h0: 0.8382 | h1: 0.8111 | h2: 0.8428 | h3: 0.8588\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8387', '0.8111', '0.8434', '0.8588']\n",
      "  [EdgeMLP] best mean val AUC = 0.8377\n",
      "Epoch 423 | train_loss(step) = 0.3301 | train_loss(eval) = 0.3347 | train_mean_auc = 0.8412 | val_mean_auc = 0.8376\n",
      "  train AUC per head: h0: 0.8441 | h1: 0.8131 | h2: 0.8452 | h3: 0.8625\n",
      "  val   AUC per head: h0: 0.8385 | h1: 0.8107 | h2: 0.8422 | h3: 0.8588\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8387', '0.8111', '0.8434', '0.8588']\n",
      "  [EdgeMLP] best mean val AUC = 0.8377\n",
      "Epoch 424 | train_loss(step) = 0.3473 | train_loss(eval) = 0.3340 | train_mean_auc = 0.8415 | val_mean_auc = 0.8377\n",
      "  train AUC per head: h0: 0.8442 | h1: 0.8132 | h2: 0.8459 | h3: 0.8625\n",
      "  val   AUC per head: h0: 0.8385 | h1: 0.8105 | h2: 0.8427 | h3: 0.8589\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8387', '0.8111', '0.8434', '0.8589']\n",
      "  [EdgeMLP] best mean val AUC = 0.8377\n",
      "Epoch 425 | train_loss(step) = 0.3191 | train_loss(eval) = 0.3340 | train_mean_auc = 0.8416 | val_mean_auc = 0.8377\n",
      "  train AUC per head: h0: 0.8442 | h1: 0.8129 | h2: 0.8469 | h3: 0.8626\n",
      "  val   AUC per head: h0: 0.8384 | h1: 0.8099 | h2: 0.8435 | h3: 0.8590\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8387', '0.8111', '0.8435', '0.8590']\n",
      "  [EdgeMLP] best mean val AUC = 0.8377\n",
      "Epoch 426 | train_loss(step) = 0.3296 | train_loss(eval) = 0.3346 | train_mean_auc = 0.8418 | val_mean_auc = 0.8378\n",
      "  train AUC per head: h0: 0.8443 | h1: 0.8127 | h2: 0.8475 | h3: 0.8627\n",
      "  val   AUC per head: h0: 0.8385 | h1: 0.8097 | h2: 0.8439 | h3: 0.8591\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8387', '0.8111', '0.8439', '0.8591']\n",
      "  [EdgeMLP] best mean val AUC = 0.8378\n",
      "Epoch 427 | train_loss(step) = 0.3351 | train_loss(eval) = 0.3338 | train_mean_auc = 0.8420 | val_mean_auc = 0.8381\n",
      "  train AUC per head: h0: 0.8446 | h1: 0.8131 | h2: 0.8475 | h3: 0.8625\n",
      "  val   AUC per head: h0: 0.8390 | h1: 0.8102 | h2: 0.8439 | h3: 0.8591\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8390', '0.8111', '0.8439', '0.8591']\n",
      "  [EdgeMLP] best mean val AUC = 0.8381\n",
      "Epoch 428 | train_loss(step) = 0.3410 | train_loss(eval) = 0.3340 | train_mean_auc = 0.8414 | val_mean_auc = 0.8377\n",
      "  train AUC per head: h0: 0.8441 | h1: 0.8126 | h2: 0.8467 | h3: 0.8624\n",
      "  val   AUC per head: h0: 0.8388 | h1: 0.8100 | h2: 0.8431 | h3: 0.8589\n",
      "  no improvement this epoch. no_improve_heads = [1, 6, 2, 2]\n",
      "Epoch 429 | train_loss(step) = 0.3301 | train_loss(eval) = 0.3347 | train_mean_auc = 0.8411 | val_mean_auc = 0.8375\n",
      "  train AUC per head: h0: 0.8438 | h1: 0.8121 | h2: 0.8463 | h3: 0.8622\n",
      "  val   AUC per head: h0: 0.8386 | h1: 0.8098 | h2: 0.8427 | h3: 0.8588\n",
      "  no improvement this epoch. no_improve_heads = [2, 7, 3, 3]\n",
      "Epoch 430 | train_loss(step) = 0.3313 | train_loss(eval) = 0.3341 | train_mean_auc = 0.8416 | val_mean_auc = 0.8380\n",
      "  train AUC per head: h0: 0.8441 | h1: 0.8131 | h2: 0.8470 | h3: 0.8622\n",
      "  val   AUC per head: h0: 0.8389 | h1: 0.8108 | h2: 0.8435 | h3: 0.8588\n",
      "  no improvement this epoch. no_improve_heads = [3, 8, 4, 4]\n",
      "Epoch 431 | train_loss(step) = 0.3335 | train_loss(eval) = 0.3336 | train_mean_auc = 0.8421 | val_mean_auc = 0.8385\n",
      "  train AUC per head: h0: 0.8444 | h1: 0.8140 | h2: 0.8477 | h3: 0.8623\n",
      "  val   AUC per head: h0: 0.8390 | h1: 0.8116 | h2: 0.8444 | h3: 0.8589\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8390', '0.8116', '0.8444', '0.8591']\n",
      "  [EdgeMLP] best mean val AUC = 0.8385\n",
      "Epoch 432 | train_loss(step) = 0.3291 | train_loss(eval) = 0.3341 | train_mean_auc = 0.8420 | val_mean_auc = 0.8384\n",
      "  train AUC per head: h0: 0.8439 | h1: 0.8141 | h2: 0.8478 | h3: 0.8624\n",
      "  val   AUC per head: h0: 0.8384 | h1: 0.8116 | h2: 0.8446 | h3: 0.8589\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8390', '0.8116', '0.8446', '0.8591']\n",
      "  [EdgeMLP] best mean val AUC = 0.8385\n",
      "Epoch 433 | train_loss(step) = 0.3347 | train_loss(eval) = 0.3339 | train_mean_auc = 0.8421 | val_mean_auc = 0.8384\n",
      "  train AUC per head: h0: 0.8438 | h1: 0.8140 | h2: 0.8478 | h3: 0.8626\n",
      "  val   AUC per head: h0: 0.8383 | h1: 0.8115 | h2: 0.8447 | h3: 0.8590\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8390', '0.8116', '0.8447', '0.8591']\n",
      "  [EdgeMLP] best mean val AUC = 0.8385\n",
      "Epoch 434 | train_loss(step) = 0.3283 | train_loss(eval) = 0.3335 | train_mean_auc = 0.8420 | val_mean_auc = 0.8384\n",
      "  train AUC per head: h0: 0.8441 | h1: 0.8141 | h2: 0.8476 | h3: 0.8625\n",
      "  val   AUC per head: h0: 0.8387 | h1: 0.8115 | h2: 0.8444 | h3: 0.8589\n",
      "  no improvement this epoch. no_improve_heads = [3, 3, 1, 8]\n",
      "Epoch 435 | train_loss(step) = 0.3305 | train_loss(eval) = 0.3337 | train_mean_auc = 0.8418 | val_mean_auc = 0.8381\n",
      "  train AUC per head: h0: 0.8442 | h1: 0.8138 | h2: 0.8470 | h3: 0.8623\n",
      "  val   AUC per head: h0: 0.8389 | h1: 0.8112 | h2: 0.8436 | h3: 0.8587\n",
      "  no improvement this epoch. no_improve_heads = [4, 4, 2, 9]\n",
      "Epoch 436 | train_loss(step) = 0.3407 | train_loss(eval) = 0.3340 | train_mean_auc = 0.8417 | val_mean_auc = 0.8379\n",
      "  train AUC per head: h0: 0.8441 | h1: 0.8136 | h2: 0.8467 | h3: 0.8622\n",
      "  val   AUC per head: h0: 0.8388 | h1: 0.8110 | h2: 0.8432 | h3: 0.8587\n",
      "  no improvement this epoch. no_improve_heads = [5, 5, 3, 10]\n",
      "Epoch 437 | train_loss(step) = 0.3359 | train_loss(eval) = 0.3336 | train_mean_auc = 0.8419 | val_mean_auc = 0.8381\n",
      "  train AUC per head: h0: 0.8444 | h1: 0.8139 | h2: 0.8471 | h3: 0.8624\n",
      "  val   AUC per head: h0: 0.8389 | h1: 0.8112 | h2: 0.8435 | h3: 0.8588\n",
      "  no improvement this epoch. no_improve_heads = [6, 6, 4, 11]\n",
      "Epoch 438 | train_loss(step) = 0.3294 | train_loss(eval) = 0.3333 | train_mean_auc = 0.8423 | val_mean_auc = 0.8384\n",
      "  train AUC per head: h0: 0.8447 | h1: 0.8143 | h2: 0.8478 | h3: 0.8626\n",
      "  val   AUC per head: h0: 0.8390 | h1: 0.8115 | h2: 0.8442 | h3: 0.8590\n",
      "  no improvement this epoch. no_improve_heads = [7, 7, 5, 12]\n",
      "Epoch 439 | train_loss(step) = 0.3387 | train_loss(eval) = 0.3337 | train_mean_auc = 0.8423 | val_mean_auc = 0.8383\n",
      "  train AUC per head: h0: 0.8444 | h1: 0.8142 | h2: 0.8479 | h3: 0.8627\n",
      "  val   AUC per head: h0: 0.8385 | h1: 0.8114 | h2: 0.8442 | h3: 0.8591\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8390', '0.8116', '0.8447', '0.8591']\n",
      "  [EdgeMLP] best mean val AUC = 0.8385\n",
      "Epoch 440 | train_loss(step) = 0.3325 | train_loss(eval) = 0.3336 | train_mean_auc = 0.8423 | val_mean_auc = 0.8383\n",
      "  train AUC per head: h0: 0.8444 | h1: 0.8143 | h2: 0.8479 | h3: 0.8627\n",
      "  val   AUC per head: h0: 0.8384 | h1: 0.8115 | h2: 0.8442 | h3: 0.8592\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8390', '0.8116', '0.8447', '0.8592']\n",
      "  [EdgeMLP] best mean val AUC = 0.8385\n",
      "Epoch 441 | train_loss(step) = 0.3437 | train_loss(eval) = 0.3331 | train_mean_auc = 0.8423 | val_mean_auc = 0.8384\n",
      "  train AUC per head: h0: 0.8448 | h1: 0.8142 | h2: 0.8477 | h3: 0.8626\n",
      "  val   AUC per head: h0: 0.8389 | h1: 0.8117 | h2: 0.8438 | h3: 0.8592\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8390', '0.8117', '0.8447', '0.8592']\n",
      "  [EdgeMLP] best mean val AUC = 0.8385\n",
      "Epoch 442 | train_loss(step) = 0.3399 | train_loss(eval) = 0.3345 | train_mean_auc = 0.8418 | val_mean_auc = 0.8379\n",
      "  train AUC per head: h0: 0.8449 | h1: 0.8129 | h2: 0.8468 | h3: 0.8626\n",
      "  val   AUC per head: h0: 0.8391 | h1: 0.8105 | h2: 0.8429 | h3: 0.8592\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8391', '0.8117', '0.8447', '0.8592']\n",
      "  [EdgeMLP] best mean val AUC = 0.8385\n",
      "Epoch 443 | train_loss(step) = 0.3314 | train_loss(eval) = 0.3345 | train_mean_auc = 0.8419 | val_mean_auc = 0.8380\n",
      "  train AUC per head: h0: 0.8451 | h1: 0.8129 | h2: 0.8470 | h3: 0.8626\n",
      "  val   AUC per head: h0: 0.8393 | h1: 0.8105 | h2: 0.8430 | h3: 0.8592\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8393', '0.8117', '0.8447', '0.8592']\n",
      "  [EdgeMLP] best mean val AUC = 0.8385\n",
      "Epoch 444 | train_loss(step) = 0.3305 | train_loss(eval) = 0.3331 | train_mean_auc = 0.8425 | val_mean_auc = 0.8386\n",
      "  train AUC per head: h0: 0.8451 | h1: 0.8144 | h2: 0.8480 | h3: 0.8627\n",
      "  val   AUC per head: h0: 0.8393 | h1: 0.8118 | h2: 0.8440 | h3: 0.8593\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8393', '0.8118', '0.8447', '0.8593']\n",
      "  [EdgeMLP] best mean val AUC = 0.8386\n",
      "Epoch 445 | train_loss(step) = 0.3324 | train_loss(eval) = 0.3329 | train_mean_auc = 0.8426 | val_mean_auc = 0.8386\n",
      "  train AUC per head: h0: 0.8446 | h1: 0.8147 | h2: 0.8484 | h3: 0.8627\n",
      "  val   AUC per head: h0: 0.8388 | h1: 0.8120 | h2: 0.8445 | h3: 0.8593\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8393', '0.8120', '0.8447', '0.8593']\n",
      "  [EdgeMLP] best mean val AUC = 0.8386\n",
      "Epoch 446 | train_loss(step) = 0.3309 | train_loss(eval) = 0.3335 | train_mean_auc = 0.8424 | val_mean_auc = 0.8383\n",
      "  train AUC per head: h0: 0.8438 | h1: 0.8144 | h2: 0.8486 | h3: 0.8627\n",
      "  val   AUC per head: h0: 0.8379 | h1: 0.8115 | h2: 0.8447 | h3: 0.8592\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8393', '0.8120', '0.8447', '0.8593']\n",
      "  [EdgeMLP] best mean val AUC = 0.8386\n",
      "Epoch 447 | train_loss(step) = 0.3324 | train_loss(eval) = 0.3340 | train_mean_auc = 0.8421 | val_mean_auc = 0.8381\n",
      "  train AUC per head: h0: 0.8432 | h1: 0.8140 | h2: 0.8484 | h3: 0.8626\n",
      "  val   AUC per head: h0: 0.8374 | h1: 0.8111 | h2: 0.8447 | h3: 0.8592\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8393', '0.8120', '0.8447', '0.8593']\n",
      "  [EdgeMLP] best mean val AUC = 0.8386\n",
      "Epoch 448 | train_loss(step) = 0.3349 | train_loss(eval) = 0.3336 | train_mean_auc = 0.8423 | val_mean_auc = 0.8383\n",
      "  train AUC per head: h0: 0.8438 | h1: 0.8143 | h2: 0.8485 | h3: 0.8625\n",
      "  val   AUC per head: h0: 0.8380 | h1: 0.8113 | h2: 0.8449 | h3: 0.8591\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8393', '0.8120', '0.8449', '0.8593']\n",
      "  [EdgeMLP] best mean val AUC = 0.8386\n",
      "Epoch 449 | train_loss(step) = 0.3391 | train_loss(eval) = 0.3331 | train_mean_auc = 0.8425 | val_mean_auc = 0.8387\n",
      "  train AUC per head: h0: 0.8446 | h1: 0.8146 | h2: 0.8483 | h3: 0.8625\n",
      "  val   AUC per head: h0: 0.8389 | h1: 0.8118 | h2: 0.8448 | h3: 0.8591\n",
      "  no improvement this epoch. no_improve_heads = [6, 4, 1, 4]\n",
      "Epoch 450 | train_loss(step) = 0.3312 | train_loss(eval) = 0.3335 | train_mean_auc = 0.8424 | val_mean_auc = 0.8386\n",
      "  train AUC per head: h0: 0.8448 | h1: 0.8144 | h2: 0.8479 | h3: 0.8625\n",
      "  val   AUC per head: h0: 0.8392 | h1: 0.8117 | h2: 0.8444 | h3: 0.8591\n",
      "  no improvement this epoch. no_improve_heads = [7, 5, 2, 5]\n",
      "Epoch 451 | train_loss(step) = 0.3283 | train_loss(eval) = 0.3335 | train_mean_auc = 0.8423 | val_mean_auc = 0.8386\n",
      "  train AUC per head: h0: 0.8448 | h1: 0.8142 | h2: 0.8476 | h3: 0.8625\n",
      "  val   AUC per head: h0: 0.8393 | h1: 0.8115 | h2: 0.8443 | h3: 0.8592\n",
      "  no improvement this epoch. no_improve_heads = [8, 6, 3, 6]\n",
      "Epoch 452 | train_loss(step) = 0.3406 | train_loss(eval) = 0.3329 | train_mean_auc = 0.8426 | val_mean_auc = 0.8388\n",
      "  train AUC per head: h0: 0.8451 | h1: 0.8147 | h2: 0.8480 | h3: 0.8625\n",
      "  val   AUC per head: h0: 0.8394 | h1: 0.8119 | h2: 0.8446 | h3: 0.8592\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8394', '0.8120', '0.8449', '0.8593']\n",
      "  [EdgeMLP] best mean val AUC = 0.8388\n",
      "Epoch 453 | train_loss(step) = 0.3387 | train_loss(eval) = 0.3330 | train_mean_auc = 0.8426 | val_mean_auc = 0.8386\n",
      "  train AUC per head: h0: 0.8448 | h1: 0.8148 | h2: 0.8481 | h3: 0.8626\n",
      "  val   AUC per head: h0: 0.8388 | h1: 0.8119 | h2: 0.8447 | h3: 0.8592\n",
      "  no improvement this epoch. no_improve_heads = [1, 8, 5, 8]\n",
      "Epoch 454 | train_loss(step) = 0.3387 | train_loss(eval) = 0.3332 | train_mean_auc = 0.8424 | val_mean_auc = 0.8385\n",
      "  train AUC per head: h0: 0.8444 | h1: 0.8147 | h2: 0.8481 | h3: 0.8626\n",
      "  val   AUC per head: h0: 0.8383 | h1: 0.8117 | h2: 0.8446 | h3: 0.8592\n",
      "  no improvement this epoch. no_improve_heads = [2, 9, 6, 9]\n",
      "Epoch 455 | train_loss(step) = 0.3347 | train_loss(eval) = 0.3330 | train_mean_auc = 0.8425 | val_mean_auc = 0.8385\n",
      "  train AUC per head: h0: 0.8447 | h1: 0.8146 | h2: 0.8481 | h3: 0.8625\n",
      "  val   AUC per head: h0: 0.8386 | h1: 0.8116 | h2: 0.8446 | h3: 0.8592\n",
      "  no improvement this epoch. no_improve_heads = [3, 10, 7, 10]\n",
      "Epoch 456 | train_loss(step) = 0.3383 | train_loss(eval) = 0.3331 | train_mean_auc = 0.8425 | val_mean_auc = 0.8385\n",
      "  train AUC per head: h0: 0.8451 | h1: 0.8143 | h2: 0.8479 | h3: 0.8626\n",
      "  val   AUC per head: h0: 0.8392 | h1: 0.8112 | h2: 0.8444 | h3: 0.8593\n",
      "  no improvement this epoch. no_improve_heads = [4, 11, 8, 11]\n",
      "Epoch 457 | train_loss(step) = 0.3307 | train_loss(eval) = 0.3331 | train_mean_auc = 0.8425 | val_mean_auc = 0.8386\n",
      "  train AUC per head: h0: 0.8453 | h1: 0.8143 | h2: 0.8478 | h3: 0.8626\n",
      "  val   AUC per head: h0: 0.8395 | h1: 0.8112 | h2: 0.8443 | h3: 0.8593\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8395', '0.8120', '0.8449', '0.8593']\n",
      "  [EdgeMLP] best mean val AUC = 0.8388\n",
      "Epoch 458 | train_loss(step) = 0.3206 | train_loss(eval) = 0.3326 | train_mean_auc = 0.8428 | val_mean_auc = 0.8388\n",
      "  train AUC per head: h0: 0.8455 | h1: 0.8149 | h2: 0.8483 | h3: 0.8626\n",
      "  val   AUC per head: h0: 0.8397 | h1: 0.8117 | h2: 0.8447 | h3: 0.8592\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8397', '0.8120', '0.8449', '0.8593']\n",
      "  [EdgeMLP] best mean val AUC = 0.8388\n",
      "Epoch 459 | train_loss(step) = 0.3343 | train_loss(eval) = 0.3326 | train_mean_auc = 0.8431 | val_mean_auc = 0.8391\n",
      "  train AUC per head: h0: 0.8455 | h1: 0.8153 | h2: 0.8491 | h3: 0.8626\n",
      "  val   AUC per head: h0: 0.8397 | h1: 0.8120 | h2: 0.8455 | h3: 0.8593\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8397', '0.8120', '0.8455', '0.8593']\n",
      "  [EdgeMLP] best mean val AUC = 0.8391\n",
      "Epoch 460 | train_loss(step) = 0.3284 | train_loss(eval) = 0.3330 | train_mean_auc = 0.8431 | val_mean_auc = 0.8391\n",
      "  train AUC per head: h0: 0.8451 | h1: 0.8152 | h2: 0.8493 | h3: 0.8627\n",
      "  val   AUC per head: h0: 0.8393 | h1: 0.8119 | h2: 0.8458 | h3: 0.8593\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8397', '0.8120', '0.8458', '0.8593']\n",
      "  [EdgeMLP] best mean val AUC = 0.8391\n",
      "Epoch 461 | train_loss(step) = 0.3315 | train_loss(eval) = 0.3330 | train_mean_auc = 0.8430 | val_mean_auc = 0.8390\n",
      "  train AUC per head: h0: 0.8449 | h1: 0.8151 | h2: 0.8491 | h3: 0.8629\n",
      "  val   AUC per head: h0: 0.8392 | h1: 0.8118 | h2: 0.8456 | h3: 0.8594\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8397', '0.8120', '0.8458', '0.8594']\n",
      "  [EdgeMLP] best mean val AUC = 0.8391\n",
      "Epoch 462 | train_loss(step) = 0.3395 | train_loss(eval) = 0.3327 | train_mean_auc = 0.8429 | val_mean_auc = 0.8389\n",
      "  train AUC per head: h0: 0.8448 | h1: 0.8152 | h2: 0.8485 | h3: 0.8630\n",
      "  val   AUC per head: h0: 0.8394 | h1: 0.8120 | h2: 0.8450 | h3: 0.8594\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8397', '0.8120', '0.8458', '0.8594']\n",
      "  [EdgeMLP] best mean val AUC = 0.8391\n",
      "Epoch 463 | train_loss(step) = 0.3278 | train_loss(eval) = 0.3331 | train_mean_auc = 0.8425 | val_mean_auc = 0.8386\n",
      "  train AUC per head: h0: 0.8446 | h1: 0.8148 | h2: 0.8476 | h3: 0.8629\n",
      "  val   AUC per head: h0: 0.8393 | h1: 0.8117 | h2: 0.8441 | h3: 0.8594\n",
      "  no improvement this epoch. no_improve_heads = [4, 4, 3, 1]\n",
      "Epoch 464 | train_loss(step) = 0.3357 | train_loss(eval) = 0.3331 | train_mean_auc = 0.8425 | val_mean_auc = 0.8387\n",
      "  train AUC per head: h0: 0.8445 | h1: 0.8149 | h2: 0.8477 | h3: 0.8630\n",
      "  val   AUC per head: h0: 0.8393 | h1: 0.8118 | h2: 0.8442 | h3: 0.8594\n",
      "  no improvement this epoch. no_improve_heads = [5, 5, 4, 2]\n",
      "Epoch 465 | train_loss(step) = 0.3330 | train_loss(eval) = 0.3329 | train_mean_auc = 0.8428 | val_mean_auc = 0.8388\n",
      "  train AUC per head: h0: 0.8446 | h1: 0.8151 | h2: 0.8483 | h3: 0.8630\n",
      "  val   AUC per head: h0: 0.8392 | h1: 0.8120 | h2: 0.8447 | h3: 0.8594\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8397', '0.8120', '0.8458', '0.8594']\n",
      "  [EdgeMLP] best mean val AUC = 0.8391\n",
      "Epoch 466 | train_loss(step) = 0.3365 | train_loss(eval) = 0.3330 | train_mean_auc = 0.8428 | val_mean_auc = 0.8388\n",
      "  train AUC per head: h0: 0.8442 | h1: 0.8152 | h2: 0.8489 | h3: 0.8630\n",
      "  val   AUC per head: h0: 0.8386 | h1: 0.8120 | h2: 0.8452 | h3: 0.8594\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8397', '0.8120', '0.8458', '0.8594']\n",
      "  [EdgeMLP] best mean val AUC = 0.8391\n",
      "Epoch 467 | train_loss(step) = 0.3321 | train_loss(eval) = 0.3332 | train_mean_auc = 0.8427 | val_mean_auc = 0.8386\n",
      "  train AUC per head: h0: 0.8439 | h1: 0.8150 | h2: 0.8491 | h3: 0.8630\n",
      "  val   AUC per head: h0: 0.8381 | h1: 0.8117 | h2: 0.8453 | h3: 0.8594\n",
      "  no improvement this epoch. no_improve_heads = [8, 8, 7, 1]\n",
      "Epoch 468 | train_loss(step) = 0.3300 | train_loss(eval) = 0.3331 | train_mean_auc = 0.8429 | val_mean_auc = 0.8387\n",
      "  train AUC per head: h0: 0.8442 | h1: 0.8151 | h2: 0.8491 | h3: 0.8630\n",
      "  val   AUC per head: h0: 0.8384 | h1: 0.8115 | h2: 0.8453 | h3: 0.8594\n",
      "  no improvement this epoch. no_improve_heads = [9, 9, 8, 2]\n",
      "Epoch 469 | train_loss(step) = 0.3357 | train_loss(eval) = 0.3325 | train_mean_auc = 0.8432 | val_mean_auc = 0.8390\n",
      "  train AUC per head: h0: 0.8450 | h1: 0.8156 | h2: 0.8492 | h3: 0.8630\n",
      "  val   AUC per head: h0: 0.8393 | h1: 0.8120 | h2: 0.8453 | h3: 0.8594\n",
      "  no improvement this epoch. no_improve_heads = [10, 10, 9, 3]\n",
      "Epoch 470 | train_loss(step) = 0.3280 | train_loss(eval) = 0.3327 | train_mean_auc = 0.8432 | val_mean_auc = 0.8390\n",
      "  train AUC per head: h0: 0.8452 | h1: 0.8156 | h2: 0.8491 | h3: 0.8630\n",
      "  val   AUC per head: h0: 0.8395 | h1: 0.8120 | h2: 0.8451 | h3: 0.8594\n",
      "  no improvement this epoch. no_improve_heads = [11, 11, 10, 4]\n",
      "Epoch 471 | train_loss(step) = 0.3433 | train_loss(eval) = 0.3331 | train_mean_auc = 0.8431 | val_mean_auc = 0.8389\n",
      "  train AUC per head: h0: 0.8451 | h1: 0.8154 | h2: 0.8489 | h3: 0.8630\n",
      "  val   AUC per head: h0: 0.8395 | h1: 0.8118 | h2: 0.8449 | h3: 0.8594\n",
      "  no improvement this epoch. no_improve_heads = [12, 12, 11, 5]\n",
      "Epoch 472 | train_loss(step) = 0.3351 | train_loss(eval) = 0.3330 | train_mean_auc = 0.8431 | val_mean_auc = 0.8389\n",
      "  train AUC per head: h0: 0.8451 | h1: 0.8152 | h2: 0.8489 | h3: 0.8630\n",
      "  val   AUC per head: h0: 0.8395 | h1: 0.8117 | h2: 0.8450 | h3: 0.8595\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8397', '0.8120', '0.8458', '0.8595']\n",
      "  [EdgeMLP] best mean val AUC = 0.8391\n",
      "Epoch 473 | train_loss(step) = 0.3244 | train_loss(eval) = 0.3324 | train_mean_auc = 0.8432 | val_mean_auc = 0.8390\n",
      "  train AUC per head: h0: 0.8450 | h1: 0.8154 | h2: 0.8493 | h3: 0.8631\n",
      "  val   AUC per head: h0: 0.8392 | h1: 0.8117 | h2: 0.8454 | h3: 0.8595\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8397', '0.8120', '0.8458', '0.8595']\n",
      "  [EdgeMLP] best mean val AUC = 0.8391\n",
      "Epoch 474 | train_loss(step) = 0.3279 | train_loss(eval) = 0.3332 | train_mean_auc = 0.8429 | val_mean_auc = 0.8387\n",
      "  train AUC per head: h0: 0.8444 | h1: 0.8150 | h2: 0.8491 | h3: 0.8631\n",
      "  val   AUC per head: h0: 0.8383 | h1: 0.8114 | h2: 0.8455 | h3: 0.8595\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8397', '0.8120', '0.8458', '0.8595']\n",
      "  [EdgeMLP] best mean val AUC = 0.8391\n",
      "Epoch 475 | train_loss(step) = 0.3286 | train_loss(eval) = 0.3330 | train_mean_auc = 0.8430 | val_mean_auc = 0.8389\n",
      "  train AUC per head: h0: 0.8446 | h1: 0.8151 | h2: 0.8493 | h3: 0.8631\n",
      "  val   AUC per head: h0: 0.8387 | h1: 0.8115 | h2: 0.8458 | h3: 0.8595\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8397', '0.8120', '0.8458', '0.8595']\n",
      "  [EdgeMLP] best mean val AUC = 0.8391\n",
      "Epoch 476 | train_loss(step) = 0.3374 | train_loss(eval) = 0.3325 | train_mean_auc = 0.8432 | val_mean_auc = 0.8392\n",
      "  train AUC per head: h0: 0.8452 | h1: 0.8153 | h2: 0.8494 | h3: 0.8631\n",
      "  val   AUC per head: h0: 0.8393 | h1: 0.8119 | h2: 0.8459 | h3: 0.8596\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8397', '0.8120', '0.8459', '0.8596']\n",
      "  [EdgeMLP] best mean val AUC = 0.8392\n",
      "Epoch 477 | train_loss(step) = 0.3254 | train_loss(eval) = 0.3321 | train_mean_auc = 0.8434 | val_mean_auc = 0.8394\n",
      "  train AUC per head: h0: 0.8458 | h1: 0.8153 | h2: 0.8492 | h3: 0.8631\n",
      "  val   AUC per head: h0: 0.8401 | h1: 0.8121 | h2: 0.8458 | h3: 0.8595\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8401', '0.8121', '0.8459', '0.8596']\n",
      "  [EdgeMLP] best mean val AUC = 0.8394\n",
      "Epoch 478 | train_loss(step) = 0.3294 | train_loss(eval) = 0.3328 | train_mean_auc = 0.8429 | val_mean_auc = 0.8391\n",
      "  train AUC per head: h0: 0.8456 | h1: 0.8147 | h2: 0.8483 | h3: 0.8631\n",
      "  val   AUC per head: h0: 0.8400 | h1: 0.8117 | h2: 0.8451 | h3: 0.8595\n",
      "  no improvement this epoch. no_improve_heads = [1, 1, 2, 2]\n",
      "Epoch 479 | train_loss(step) = 0.3336 | train_loss(eval) = 0.3331 | train_mean_auc = 0.8427 | val_mean_auc = 0.8389\n",
      "  train AUC per head: h0: 0.8453 | h1: 0.8146 | h2: 0.8479 | h3: 0.8631\n",
      "  val   AUC per head: h0: 0.8398 | h1: 0.8116 | h2: 0.8447 | h3: 0.8594\n",
      "  no improvement this epoch. no_improve_heads = [2, 2, 3, 3]\n",
      "Epoch 480 | train_loss(step) = 0.3328 | train_loss(eval) = 0.3324 | train_mean_auc = 0.8431 | val_mean_auc = 0.8393\n",
      "  train AUC per head: h0: 0.8453 | h1: 0.8155 | h2: 0.8485 | h3: 0.8630\n",
      "  val   AUC per head: h0: 0.8396 | h1: 0.8126 | h2: 0.8454 | h3: 0.8594\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8401', '0.8126', '0.8459', '0.8596']\n",
      "  [EdgeMLP] best mean val AUC = 0.8394\n",
      "Epoch 481 | train_loss(step) = 0.3331 | train_loss(eval) = 0.3325 | train_mean_auc = 0.8433 | val_mean_auc = 0.8394\n",
      "  train AUC per head: h0: 0.8450 | h1: 0.8160 | h2: 0.8493 | h3: 0.8630\n",
      "  val   AUC per head: h0: 0.8393 | h1: 0.8130 | h2: 0.8461 | h3: 0.8594\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8401', '0.8130', '0.8461', '0.8596']\n",
      "  [EdgeMLP] best mean val AUC = 0.8394\n",
      "Epoch 482 | train_loss(step) = 0.3358 | train_loss(eval) = 0.3330 | train_mean_auc = 0.8433 | val_mean_auc = 0.8394\n",
      "  train AUC per head: h0: 0.8449 | h1: 0.8158 | h2: 0.8497 | h3: 0.8630\n",
      "  val   AUC per head: h0: 0.8390 | h1: 0.8127 | h2: 0.8465 | h3: 0.8593\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8401', '0.8130', '0.8465', '0.8596']\n",
      "  [EdgeMLP] best mean val AUC = 0.8394\n",
      "Epoch 483 | train_loss(step) = 0.3301 | train_loss(eval) = 0.3330 | train_mean_auc = 0.8435 | val_mean_auc = 0.8395\n",
      "  train AUC per head: h0: 0.8451 | h1: 0.8157 | h2: 0.8500 | h3: 0.8630\n",
      "  val   AUC per head: h0: 0.8393 | h1: 0.8126 | h2: 0.8467 | h3: 0.8594\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8401', '0.8130', '0.8467', '0.8596']\n",
      "  [EdgeMLP] best mean val AUC = 0.8395\n",
      "Epoch 484 | train_loss(step) = 0.3352 | train_loss(eval) = 0.3323 | train_mean_auc = 0.8437 | val_mean_auc = 0.8398\n",
      "  train AUC per head: h0: 0.8457 | h1: 0.8161 | h2: 0.8502 | h3: 0.8630\n",
      "  val   AUC per head: h0: 0.8400 | h1: 0.8130 | h2: 0.8467 | h3: 0.8594\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8401', '0.8130', '0.8467', '0.8596']\n",
      "  [EdgeMLP] best mean val AUC = 0.8398\n",
      "Epoch 485 | train_loss(step) = 0.3325 | train_loss(eval) = 0.3319 | train_mean_auc = 0.8437 | val_mean_auc = 0.8398\n",
      "  train AUC per head: h0: 0.8458 | h1: 0.8164 | h2: 0.8498 | h3: 0.8630\n",
      "  val   AUC per head: h0: 0.8402 | h1: 0.8134 | h2: 0.8463 | h3: 0.8594\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8402', '0.8134', '0.8467', '0.8596']\n",
      "  [EdgeMLP] best mean val AUC = 0.8398\n",
      "Epoch 486 | train_loss(step) = 0.3324 | train_loss(eval) = 0.3327 | train_mean_auc = 0.8432 | val_mean_auc = 0.8394\n",
      "  train AUC per head: h0: 0.8453 | h1: 0.8159 | h2: 0.8487 | h3: 0.8630\n",
      "  val   AUC per head: h0: 0.8399 | h1: 0.8131 | h2: 0.8451 | h3: 0.8595\n",
      "  no improvement this epoch. no_improve_heads = [1, 1, 2, 10]\n",
      "Epoch 487 | train_loss(step) = 0.3335 | train_loss(eval) = 0.3331 | train_mean_auc = 0.8430 | val_mean_auc = 0.8392\n",
      "  train AUC per head: h0: 0.8452 | h1: 0.8156 | h2: 0.8482 | h3: 0.8631\n",
      "  val   AUC per head: h0: 0.8397 | h1: 0.8129 | h2: 0.8445 | h3: 0.8595\n",
      "  no improvement this epoch. no_improve_heads = [2, 2, 3, 11]\n",
      "Epoch 488 | train_loss(step) = 0.3376 | train_loss(eval) = 0.3322 | train_mean_auc = 0.8435 | val_mean_auc = 0.8396\n",
      "  train AUC per head: h0: 0.8456 | h1: 0.8162 | h2: 0.8492 | h3: 0.8631\n",
      "  val   AUC per head: h0: 0.8399 | h1: 0.8133 | h2: 0.8454 | h3: 0.8595\n",
      "  no improvement this epoch. no_improve_heads = [3, 3, 4, 12]\n",
      "Epoch 489 | train_loss(step) = 0.3256 | train_loss(eval) = 0.3323 | train_mean_auc = 0.8437 | val_mean_auc = 0.8395\n",
      "  train AUC per head: h0: 0.8453 | h1: 0.8162 | h2: 0.8501 | h3: 0.8631\n",
      "  val   AUC per head: h0: 0.8393 | h1: 0.8131 | h2: 0.8462 | h3: 0.8595\n",
      "  no improvement this epoch. no_improve_heads = [4, 4, 5, 13]\n",
      "Epoch 490 | train_loss(step) = 0.3385 | train_loss(eval) = 0.3330 | train_mean_auc = 0.8434 | val_mean_auc = 0.8392\n",
      "  train AUC per head: h0: 0.8447 | h1: 0.8157 | h2: 0.8502 | h3: 0.8631\n",
      "  val   AUC per head: h0: 0.8386 | h1: 0.8125 | h2: 0.8463 | h3: 0.8596\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8402', '0.8134', '0.8467', '0.8596']\n",
      "  [EdgeMLP] best mean val AUC = 0.8398\n",
      "Epoch 491 | train_loss(step) = 0.3466 | train_loss(eval) = 0.3324 | train_mean_auc = 0.8435 | val_mean_auc = 0.8394\n",
      "  train AUC per head: h0: 0.8451 | h1: 0.8159 | h2: 0.8501 | h3: 0.8631\n",
      "  val   AUC per head: h0: 0.8390 | h1: 0.8126 | h2: 0.8462 | h3: 0.8596\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8402', '0.8134', '0.8467', '0.8596']\n",
      "  [EdgeMLP] best mean val AUC = 0.8398\n",
      "Epoch 492 | train_loss(step) = 0.3323 | train_loss(eval) = 0.3320 | train_mean_auc = 0.8437 | val_mean_auc = 0.8395\n",
      "  train AUC per head: h0: 0.8454 | h1: 0.8162 | h2: 0.8500 | h3: 0.8631\n",
      "  val   AUC per head: h0: 0.8395 | h1: 0.8128 | h2: 0.8461 | h3: 0.8596\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8402', '0.8134', '0.8467', '0.8596']\n",
      "  [EdgeMLP] best mean val AUC = 0.8398\n",
      "Epoch 493 | train_loss(step) = 0.3311 | train_loss(eval) = 0.3321 | train_mean_auc = 0.8438 | val_mean_auc = 0.8396\n",
      "  train AUC per head: h0: 0.8457 | h1: 0.8165 | h2: 0.8498 | h3: 0.8632\n",
      "  val   AUC per head: h0: 0.8398 | h1: 0.8130 | h2: 0.8460 | h3: 0.8597\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8402', '0.8134', '0.8467', '0.8597']\n",
      "  [EdgeMLP] best mean val AUC = 0.8398\n",
      "Epoch 494 | train_loss(step) = 0.3380 | train_loss(eval) = 0.3322 | train_mean_auc = 0.8438 | val_mean_auc = 0.8396\n",
      "  train AUC per head: h0: 0.8458 | h1: 0.8165 | h2: 0.8498 | h3: 0.8632\n",
      "  val   AUC per head: h0: 0.8398 | h1: 0.8130 | h2: 0.8461 | h3: 0.8597\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8402', '0.8134', '0.8467', '0.8597']\n",
      "  [EdgeMLP] best mean val AUC = 0.8398\n",
      "Epoch 495 | train_loss(step) = 0.3372 | train_loss(eval) = 0.3321 | train_mean_auc = 0.8439 | val_mean_auc = 0.8397\n",
      "  train AUC per head: h0: 0.8458 | h1: 0.8165 | h2: 0.8499 | h3: 0.8634\n",
      "  val   AUC per head: h0: 0.8397 | h1: 0.8129 | h2: 0.8463 | h3: 0.8598\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8402', '0.8134', '0.8467', '0.8598']\n",
      "  [EdgeMLP] best mean val AUC = 0.8398\n",
      "Epoch 496 | train_loss(step) = 0.3251 | train_loss(eval) = 0.3318 | train_mean_auc = 0.8440 | val_mean_auc = 0.8398\n",
      "  train AUC per head: h0: 0.8458 | h1: 0.8165 | h2: 0.8504 | h3: 0.8635\n",
      "  val   AUC per head: h0: 0.8397 | h1: 0.8128 | h2: 0.8469 | h3: 0.8599\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8402', '0.8134', '0.8469', '0.8599']\n",
      "  [EdgeMLP] best mean val AUC = 0.8398\n",
      "Epoch 497 | train_loss(step) = 0.3362 | train_loss(eval) = 0.3319 | train_mean_auc = 0.8440 | val_mean_auc = 0.8399\n",
      "  train AUC per head: h0: 0.8457 | h1: 0.8163 | h2: 0.8507 | h3: 0.8635\n",
      "  val   AUC per head: h0: 0.8395 | h1: 0.8127 | h2: 0.8473 | h3: 0.8599\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8402', '0.8134', '0.8473', '0.8599']\n",
      "  [EdgeMLP] best mean val AUC = 0.8399\n",
      "Epoch 498 | train_loss(step) = 0.3335 | train_loss(eval) = 0.3317 | train_mean_auc = 0.8442 | val_mean_auc = 0.8400\n",
      "  train AUC per head: h0: 0.8459 | h1: 0.8166 | h2: 0.8507 | h3: 0.8636\n",
      "  val   AUC per head: h0: 0.8398 | h1: 0.8129 | h2: 0.8474 | h3: 0.8600\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8402', '0.8134', '0.8474', '0.8600']\n",
      "  [EdgeMLP] best mean val AUC = 0.8400\n",
      "Epoch 499 | train_loss(step) = 0.3254 | train_loss(eval) = 0.3315 | train_mean_auc = 0.8443 | val_mean_auc = 0.8402\n",
      "  train AUC per head: h0: 0.8462 | h1: 0.8168 | h2: 0.8506 | h3: 0.8636\n",
      "  val   AUC per head: h0: 0.8402 | h1: 0.8132 | h2: 0.8472 | h3: 0.8600\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8402', '0.8134', '0.8474', '0.8600']\n",
      "  [EdgeMLP] best mean val AUC = 0.8402\n",
      "Epoch 500 | train_loss(step) = 0.3329 | train_loss(eval) = 0.3316 | train_mean_auc = 0.8442 | val_mean_auc = 0.8400\n",
      "  train AUC per head: h0: 0.8462 | h1: 0.8165 | h2: 0.8504 | h3: 0.8635\n",
      "  val   AUC per head: h0: 0.8403 | h1: 0.8130 | h2: 0.8469 | h3: 0.8599\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8403', '0.8134', '0.8474', '0.8600']\n",
      "  [EdgeMLP] best mean val AUC = 0.8402\n",
      "Epoch 501 | train_loss(step) = 0.3285 | train_loss(eval) = 0.3317 | train_mean_auc = 0.8440 | val_mean_auc = 0.8398\n",
      "  train AUC per head: h0: 0.8460 | h1: 0.8163 | h2: 0.8503 | h3: 0.8633\n",
      "  val   AUC per head: h0: 0.8401 | h1: 0.8128 | h2: 0.8467 | h3: 0.8598\n",
      "  no improvement this epoch. no_improve_heads = [1, 16, 3, 2]\n",
      "Epoch 502 | train_loss(step) = 0.3402 | train_loss(eval) = 0.3318 | train_mean_auc = 0.8438 | val_mean_auc = 0.8396\n",
      "  train AUC per head: h0: 0.8458 | h1: 0.8162 | h2: 0.8504 | h3: 0.8630\n",
      "  val   AUC per head: h0: 0.8398 | h1: 0.8127 | h2: 0.8466 | h3: 0.8595\n",
      "  no improvement this epoch. no_improve_heads = [2, 17, 4, 3]\n",
      "Epoch 503 | train_loss(step) = 0.3412 | train_loss(eval) = 0.3318 | train_mean_auc = 0.8437 | val_mean_auc = 0.8396\n",
      "  train AUC per head: h0: 0.8455 | h1: 0.8162 | h2: 0.8504 | h3: 0.8629\n",
      "  val   AUC per head: h0: 0.8394 | h1: 0.8128 | h2: 0.8465 | h3: 0.8595\n",
      "  no improvement this epoch. no_improve_heads = [3, 18, 5, 4]\n",
      "Epoch 504 | train_loss(step) = 0.3345 | train_loss(eval) = 0.3318 | train_mean_auc = 0.8438 | val_mean_auc = 0.8396\n",
      "  train AUC per head: h0: 0.8454 | h1: 0.8163 | h2: 0.8504 | h3: 0.8630\n",
      "  val   AUC per head: h0: 0.8395 | h1: 0.8130 | h2: 0.8466 | h3: 0.8596\n",
      "  no improvement this epoch. no_improve_heads = [4, 19, 6, 5]\n",
      "Epoch 505 | train_loss(step) = 0.3233 | train_loss(eval) = 0.3316 | train_mean_auc = 0.8440 | val_mean_auc = 0.8400\n",
      "  train AUC per head: h0: 0.8456 | h1: 0.8166 | h2: 0.8507 | h3: 0.8631\n",
      "  val   AUC per head: h0: 0.8397 | h1: 0.8134 | h2: 0.8470 | h3: 0.8596\n",
      "  no improvement this epoch. no_improve_heads = [5, 20, 7, 6]\n",
      "Epoch 506 | train_loss(step) = 0.3325 | train_loss(eval) = 0.3318 | train_mean_auc = 0.8440 | val_mean_auc = 0.8401\n",
      "  train AUC per head: h0: 0.8455 | h1: 0.8166 | h2: 0.8507 | h3: 0.8633\n",
      "  val   AUC per head: h0: 0.8397 | h1: 0.8135 | h2: 0.8473 | h3: 0.8598\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8403', '0.8135', '0.8474', '0.8600']\n",
      "  [EdgeMLP] best mean val AUC = 0.8402\n",
      "Epoch 507 | train_loss(step) = 0.3320 | train_loss(eval) = 0.3319 | train_mean_auc = 0.8440 | val_mean_auc = 0.8401\n",
      "  train AUC per head: h0: 0.8455 | h1: 0.8165 | h2: 0.8506 | h3: 0.8633\n",
      "  val   AUC per head: h0: 0.8398 | h1: 0.8136 | h2: 0.8474 | h3: 0.8598\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8403', '0.8136', '0.8474', '0.8600']\n",
      "  [EdgeMLP] best mean val AUC = 0.8402\n",
      "Epoch 508 | train_loss(step) = 0.3367 | train_loss(eval) = 0.3317 | train_mean_auc = 0.8440 | val_mean_auc = 0.8403\n",
      "  train AUC per head: h0: 0.8455 | h1: 0.8168 | h2: 0.8503 | h3: 0.8634\n",
      "  val   AUC per head: h0: 0.8400 | h1: 0.8141 | h2: 0.8473 | h3: 0.8598\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8403', '0.8141', '0.8474', '0.8600']\n",
      "  [EdgeMLP] best mean val AUC = 0.8403\n",
      "Epoch 509 | train_loss(step) = 0.3427 | train_loss(eval) = 0.3323 | train_mean_auc = 0.8437 | val_mean_auc = 0.8401\n",
      "  train AUC per head: h0: 0.8451 | h1: 0.8164 | h2: 0.8497 | h3: 0.8635\n",
      "  val   AUC per head: h0: 0.8398 | h1: 0.8140 | h2: 0.8467 | h3: 0.8599\n",
      "  no improvement this epoch. no_improve_heads = [9, 1, 11, 10]\n",
      "Epoch 510 | train_loss(step) = 0.3340 | train_loss(eval) = 0.3334 | train_mean_auc = 0.8432 | val_mean_auc = 0.8397\n",
      "  train AUC per head: h0: 0.8446 | h1: 0.8156 | h2: 0.8490 | h3: 0.8635\n",
      "  val   AUC per head: h0: 0.8394 | h1: 0.8134 | h2: 0.8461 | h3: 0.8599\n",
      "  no improvement this epoch. no_improve_heads = [10, 2, 12, 11]\n",
      "Epoch 511 | train_loss(step) = 0.3415 | train_loss(eval) = 0.3326 | train_mean_auc = 0.8435 | val_mean_auc = 0.8400\n",
      "  train AUC per head: h0: 0.8449 | h1: 0.8160 | h2: 0.8497 | h3: 0.8636\n",
      "  val   AUC per head: h0: 0.8396 | h1: 0.8137 | h2: 0.8468 | h3: 0.8599\n",
      "  no improvement this epoch. no_improve_heads = [11, 3, 13, 12]\n",
      "Epoch 512 | train_loss(step) = 0.3349 | train_loss(eval) = 0.3319 | train_mean_auc = 0.8440 | val_mean_auc = 0.8403\n",
      "  train AUC per head: h0: 0.8455 | h1: 0.8164 | h2: 0.8506 | h3: 0.8635\n",
      "  val   AUC per head: h0: 0.8399 | h1: 0.8138 | h2: 0.8477 | h3: 0.8599\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8403', '0.8141', '0.8477', '0.8600']\n",
      "  [EdgeMLP] best mean val AUC = 0.8403\n",
      "Epoch 513 | train_loss(step) = 0.3362 | train_loss(eval) = 0.3320 | train_mean_auc = 0.8440 | val_mean_auc = 0.8402\n",
      "  train AUC per head: h0: 0.8456 | h1: 0.8160 | h2: 0.8509 | h3: 0.8635\n",
      "  val   AUC per head: h0: 0.8398 | h1: 0.8133 | h2: 0.8479 | h3: 0.8598\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8403', '0.8141', '0.8479', '0.8600']\n",
      "  [EdgeMLP] best mean val AUC = 0.8403\n",
      "Epoch 514 | train_loss(step) = 0.3328 | train_loss(eval) = 0.3325 | train_mean_auc = 0.8437 | val_mean_auc = 0.8398\n",
      "  train AUC per head: h0: 0.8453 | h1: 0.8155 | h2: 0.8508 | h3: 0.8635\n",
      "  val   AUC per head: h0: 0.8393 | h1: 0.8126 | h2: 0.8475 | h3: 0.8598\n",
      "  no improvement this epoch. no_improve_heads = [14, 6, 1, 15]\n",
      "Epoch 515 | train_loss(step) = 0.3268 | train_loss(eval) = 0.3321 | train_mean_auc = 0.8439 | val_mean_auc = 0.8400\n",
      "  train AUC per head: h0: 0.8455 | h1: 0.8160 | h2: 0.8509 | h3: 0.8635\n",
      "  val   AUC per head: h0: 0.8395 | h1: 0.8130 | h2: 0.8475 | h3: 0.8598\n",
      "  no improvement this epoch. no_improve_heads = [15, 7, 2, 16]\n",
      "Epoch 516 | train_loss(step) = 0.3250 | train_loss(eval) = 0.3317 | train_mean_auc = 0.8441 | val_mean_auc = 0.8401\n",
      "  train AUC per head: h0: 0.8455 | h1: 0.8166 | h2: 0.8509 | h3: 0.8635\n",
      "  val   AUC per head: h0: 0.8396 | h1: 0.8137 | h2: 0.8473 | h3: 0.8599\n",
      "  no improvement this epoch. no_improve_heads = [16, 8, 3, 17]\n",
      "Epoch 517 | train_loss(step) = 0.3340 | train_loss(eval) = 0.3317 | train_mean_auc = 0.8441 | val_mean_auc = 0.8400\n",
      "  train AUC per head: h0: 0.8455 | h1: 0.8167 | h2: 0.8506 | h3: 0.8636\n",
      "  val   AUC per head: h0: 0.8395 | h1: 0.8138 | h2: 0.8469 | h3: 0.8599\n",
      "  no improvement this epoch. no_improve_heads = [17, 9, 4, 18]\n",
      "Epoch 518 | train_loss(step) = 0.3337 | train_loss(eval) = 0.3319 | train_mean_auc = 0.8439 | val_mean_auc = 0.8398\n",
      "  train AUC per head: h0: 0.8454 | h1: 0.8165 | h2: 0.8503 | h3: 0.8636\n",
      "  val   AUC per head: h0: 0.8394 | h1: 0.8136 | h2: 0.8464 | h3: 0.8600\n",
      "  no improvement this epoch. no_improve_heads = [18, 10, 5, 19]\n",
      "Epoch 519 | train_loss(step) = 0.3279 | train_loss(eval) = 0.3321 | train_mean_auc = 0.8438 | val_mean_auc = 0.8397\n",
      "  train AUC per head: h0: 0.8455 | h1: 0.8161 | h2: 0.8500 | h3: 0.8635\n",
      "  val   AUC per head: h0: 0.8395 | h1: 0.8133 | h2: 0.8460 | h3: 0.8600\n",
      "  no improvement this epoch. no_improve_heads = [19, 11, 6, 20]\n",
      "Epoch 520 | train_loss(step) = 0.3355 | train_loss(eval) = 0.3319 | train_mean_auc = 0.8439 | val_mean_auc = 0.8398\n",
      "  train AUC per head: h0: 0.8457 | h1: 0.8162 | h2: 0.8501 | h3: 0.8636\n",
      "  val   AUC per head: h0: 0.8398 | h1: 0.8133 | h2: 0.8461 | h3: 0.8600\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8403', '0.8141', '0.8479', '0.8600']\n",
      "  [EdgeMLP] best mean val AUC = 0.8403\n",
      "Epoch 521 | train_loss(step) = 0.3285 | train_loss(eval) = 0.3316 | train_mean_auc = 0.8441 | val_mean_auc = 0.8400\n",
      "  train AUC per head: h0: 0.8460 | h1: 0.8164 | h2: 0.8504 | h3: 0.8637\n",
      "  val   AUC per head: h0: 0.8401 | h1: 0.8134 | h2: 0.8464 | h3: 0.8601\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8403', '0.8141', '0.8479', '0.8601']\n",
      "  [EdgeMLP] best mean val AUC = 0.8403\n",
      "Epoch 522 | train_loss(step) = 0.3370 | train_loss(eval) = 0.3314 | train_mean_auc = 0.8443 | val_mean_auc = 0.8402\n",
      "  train AUC per head: h0: 0.8462 | h1: 0.8165 | h2: 0.8506 | h3: 0.8638\n",
      "  val   AUC per head: h0: 0.8404 | h1: 0.8135 | h2: 0.8467 | h3: 0.8601\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8404', '0.8141', '0.8479', '0.8601']\n",
      "  [EdgeMLP] best mean val AUC = 0.8403\n",
      "Epoch 523 | train_loss(step) = 0.3331 | train_loss(eval) = 0.3316 | train_mean_auc = 0.8443 | val_mean_auc = 0.8402\n",
      "  train AUC per head: h0: 0.8461 | h1: 0.8166 | h2: 0.8507 | h3: 0.8637\n",
      "  val   AUC per head: h0: 0.8403 | h1: 0.8135 | h2: 0.8469 | h3: 0.8601\n",
      "  no improvement this epoch. no_improve_heads = [1, 15, 10, 1]\n",
      "Epoch 524 | train_loss(step) = 0.3358 | train_loss(eval) = 0.3319 | train_mean_auc = 0.8443 | val_mean_auc = 0.8402\n",
      "  train AUC per head: h0: 0.8459 | h1: 0.8167 | h2: 0.8508 | h3: 0.8636\n",
      "  val   AUC per head: h0: 0.8402 | h1: 0.8136 | h2: 0.8470 | h3: 0.8599\n",
      "  no improvement this epoch. no_improve_heads = [2, 16, 11, 2]\n",
      "Epoch 525 | train_loss(step) = 0.3269 | train_loss(eval) = 0.3319 | train_mean_auc = 0.8443 | val_mean_auc = 0.8402\n",
      "  train AUC per head: h0: 0.8459 | h1: 0.8168 | h2: 0.8509 | h3: 0.8635\n",
      "  val   AUC per head: h0: 0.8403 | h1: 0.8136 | h2: 0.8471 | h3: 0.8599\n",
      "  no improvement this epoch. no_improve_heads = [3, 17, 12, 3]\n",
      "Epoch 526 | train_loss(step) = 0.3245 | train_loss(eval) = 0.3316 | train_mean_auc = 0.8444 | val_mean_auc = 0.8403\n",
      "  train AUC per head: h0: 0.8459 | h1: 0.8168 | h2: 0.8510 | h3: 0.8638\n",
      "  val   AUC per head: h0: 0.8404 | h1: 0.8136 | h2: 0.8471 | h3: 0.8602\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8404', '0.8141', '0.8479', '0.8602']\n",
      "  [EdgeMLP] best mean val AUC = 0.8403\n",
      "Epoch 527 | train_loss(step) = 0.3332 | train_loss(eval) = 0.3312 | train_mean_auc = 0.8447 | val_mean_auc = 0.8406\n",
      "  train AUC per head: h0: 0.8463 | h1: 0.8173 | h2: 0.8514 | h3: 0.8640\n",
      "  val   AUC per head: h0: 0.8407 | h1: 0.8140 | h2: 0.8475 | h3: 0.8604\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8407', '0.8141', '0.8479', '0.8604']\n",
      "  [EdgeMLP] best mean val AUC = 0.8406\n",
      "Epoch 528 | train_loss(step) = 0.3230 | train_loss(eval) = 0.3311 | train_mean_auc = 0.8449 | val_mean_auc = 0.8408\n",
      "  train AUC per head: h0: 0.8464 | h1: 0.8176 | h2: 0.8516 | h3: 0.8639\n",
      "  val   AUC per head: h0: 0.8408 | h1: 0.8142 | h2: 0.8477 | h3: 0.8603\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8408', '0.8142', '0.8479', '0.8604']\n",
      "  [EdgeMLP] best mean val AUC = 0.8408\n",
      "Epoch 529 | train_loss(step) = 0.3298 | train_loss(eval) = 0.3312 | train_mean_auc = 0.8449 | val_mean_auc = 0.8407\n",
      "  train AUC per head: h0: 0.8464 | h1: 0.8177 | h2: 0.8517 | h3: 0.8637\n",
      "  val   AUC per head: h0: 0.8406 | h1: 0.8143 | h2: 0.8477 | h3: 0.8602\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8408', '0.8143', '0.8479', '0.8604']\n",
      "  [EdgeMLP] best mean val AUC = 0.8408\n",
      "Epoch 530 | train_loss(step) = 0.3372 | train_loss(eval) = 0.3313 | train_mean_auc = 0.8447 | val_mean_auc = 0.8404\n",
      "  train AUC per head: h0: 0.8462 | h1: 0.8175 | h2: 0.8515 | h3: 0.8638\n",
      "  val   AUC per head: h0: 0.8402 | h1: 0.8139 | h2: 0.8474 | h3: 0.8602\n",
      "  no improvement this epoch. no_improve_heads = [2, 1, 17, 3]\n",
      "Epoch 531 | train_loss(step) = 0.3264 | train_loss(eval) = 0.3314 | train_mean_auc = 0.8445 | val_mean_auc = 0.8402\n",
      "  train AUC per head: h0: 0.8458 | h1: 0.8172 | h2: 0.8512 | h3: 0.8638\n",
      "  val   AUC per head: h0: 0.8397 | h1: 0.8137 | h2: 0.8471 | h3: 0.8602\n",
      "  no improvement this epoch. no_improve_heads = [3, 2, 18, 4]\n",
      "Epoch 532 | train_loss(step) = 0.3216 | train_loss(eval) = 0.3317 | train_mean_auc = 0.8443 | val_mean_auc = 0.8399\n",
      "  train AUC per head: h0: 0.8454 | h1: 0.8170 | h2: 0.8509 | h3: 0.8639\n",
      "  val   AUC per head: h0: 0.8392 | h1: 0.8134 | h2: 0.8468 | h3: 0.8603\n",
      "  no improvement this epoch. no_improve_heads = [4, 3, 19, 5]\n",
      "Epoch 533 | train_loss(step) = 0.3346 | train_loss(eval) = 0.3318 | train_mean_auc = 0.8443 | val_mean_auc = 0.8399\n",
      "  train AUC per head: h0: 0.8453 | h1: 0.8170 | h2: 0.8508 | h3: 0.8639\n",
      "  val   AUC per head: h0: 0.8391 | h1: 0.8134 | h2: 0.8467 | h3: 0.8603\n",
      "  no improvement this epoch. no_improve_heads = [5, 4, 20, 6]\n",
      "Epoch 534 | train_loss(step) = 0.3302 | train_loss(eval) = 0.3316 | train_mean_auc = 0.8443 | val_mean_auc = 0.8399\n",
      "  train AUC per head: h0: 0.8454 | h1: 0.8171 | h2: 0.8508 | h3: 0.8639\n",
      "  val   AUC per head: h0: 0.8394 | h1: 0.8135 | h2: 0.8466 | h3: 0.8603\n",
      "  no improvement this epoch. no_improve_heads = [6, 5, 21, 7]\n",
      "Epoch 535 | train_loss(step) = 0.3245 | train_loss(eval) = 0.3315 | train_mean_auc = 0.8442 | val_mean_auc = 0.8399\n",
      "  train AUC per head: h0: 0.8457 | h1: 0.8168 | h2: 0.8505 | h3: 0.8639\n",
      "  val   AUC per head: h0: 0.8398 | h1: 0.8133 | h2: 0.8464 | h3: 0.8603\n",
      "  no improvement this epoch. no_improve_heads = [7, 6, 22, 8]\n",
      "Epoch 536 | train_loss(step) = 0.3196 | train_loss(eval) = 0.3313 | train_mean_auc = 0.8444 | val_mean_auc = 0.8401\n",
      "  train AUC per head: h0: 0.8460 | h1: 0.8169 | h2: 0.8507 | h3: 0.8639\n",
      "  val   AUC per head: h0: 0.8401 | h1: 0.8135 | h2: 0.8465 | h3: 0.8603\n",
      "  no improvement this epoch. no_improve_heads = [8, 7, 23, 9]\n",
      "Epoch 537 | train_loss(step) = 0.3368 | train_loss(eval) = 0.3309 | train_mean_auc = 0.8448 | val_mean_auc = 0.8405\n",
      "  train AUC per head: h0: 0.8466 | h1: 0.8176 | h2: 0.8513 | h3: 0.8638\n",
      "  val   AUC per head: h0: 0.8407 | h1: 0.8142 | h2: 0.8472 | h3: 0.8601\n",
      "  no improvement this epoch. no_improve_heads = [9, 8, 24, 10]\n",
      "Epoch 538 | train_loss(step) = 0.3327 | train_loss(eval) = 0.3307 | train_mean_auc = 0.8451 | val_mean_auc = 0.8408\n",
      "  train AUC per head: h0: 0.8469 | h1: 0.8181 | h2: 0.8517 | h3: 0.8636\n",
      "  val   AUC per head: h0: 0.8409 | h1: 0.8146 | h2: 0.8476 | h3: 0.8600\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8409', '0.8146', '0.8479', '0.8604']\n",
      "  [EdgeMLP] best mean val AUC = 0.8408\n",
      "Epoch 539 | train_loss(step) = 0.3269 | train_loss(eval) = 0.3308 | train_mean_auc = 0.8451 | val_mean_auc = 0.8407\n",
      "  train AUC per head: h0: 0.8466 | h1: 0.8182 | h2: 0.8519 | h3: 0.8636\n",
      "  val   AUC per head: h0: 0.8406 | h1: 0.8147 | h2: 0.8478 | h3: 0.8599\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8409', '0.8147', '0.8479', '0.8604']\n",
      "  [EdgeMLP] best mean val AUC = 0.8408\n",
      "Epoch 540 | train_loss(step) = 0.3266 | train_loss(eval) = 0.3311 | train_mean_auc = 0.8448 | val_mean_auc = 0.8405\n",
      "  train AUC per head: h0: 0.8461 | h1: 0.8179 | h2: 0.8516 | h3: 0.8636\n",
      "  val   AUC per head: h0: 0.8400 | h1: 0.8145 | h2: 0.8476 | h3: 0.8599\n",
      "  no improvement this epoch. no_improve_heads = [2, 1, 27, 13]\n",
      "Epoch 541 | train_loss(step) = 0.3269 | train_loss(eval) = 0.3310 | train_mean_auc = 0.8448 | val_mean_auc = 0.8405\n",
      "  train AUC per head: h0: 0.8462 | h1: 0.8179 | h2: 0.8515 | h3: 0.8638\n",
      "  val   AUC per head: h0: 0.8402 | h1: 0.8145 | h2: 0.8475 | h3: 0.8600\n",
      "  no improvement this epoch. no_improve_heads = [3, 2, 28, 14]\n",
      "Epoch 542 | train_loss(step) = 0.3328 | train_loss(eval) = 0.3308 | train_mean_auc = 0.8450 | val_mean_auc = 0.8407\n",
      "  train AUC per head: h0: 0.8465 | h1: 0.8180 | h2: 0.8516 | h3: 0.8639\n",
      "  val   AUC per head: h0: 0.8406 | h1: 0.8147 | h2: 0.8476 | h3: 0.8601\n",
      "  no improvement this epoch. no_improve_heads = [4, 3, 29, 15]\n",
      "Epoch 543 | train_loss(step) = 0.3263 | train_loss(eval) = 0.3306 | train_mean_auc = 0.8452 | val_mean_auc = 0.8409\n",
      "  train AUC per head: h0: 0.8467 | h1: 0.8183 | h2: 0.8518 | h3: 0.8638\n",
      "  val   AUC per head: h0: 0.8408 | h1: 0.8149 | h2: 0.8479 | h3: 0.8600\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8409', '0.8149', '0.8479', '0.8604']\n",
      "  [EdgeMLP] best mean val AUC = 0.8409\n",
      "Epoch 544 | train_loss(step) = 0.3317 | train_loss(eval) = 0.3307 | train_mean_auc = 0.8451 | val_mean_auc = 0.8409\n",
      "  train AUC per head: h0: 0.8468 | h1: 0.8183 | h2: 0.8519 | h3: 0.8636\n",
      "  val   AUC per head: h0: 0.8410 | h1: 0.8149 | h2: 0.8480 | h3: 0.8597\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8410', '0.8149', '0.8480', '0.8604']\n",
      "  [EdgeMLP] best mean val AUC = 0.8409\n",
      "Epoch 545 | train_loss(step) = 0.3297 | train_loss(eval) = 0.3309 | train_mean_auc = 0.8449 | val_mean_auc = 0.8407\n",
      "  train AUC per head: h0: 0.8467 | h1: 0.8182 | h2: 0.8516 | h3: 0.8632\n",
      "  val   AUC per head: h0: 0.8409 | h1: 0.8148 | h2: 0.8479 | h3: 0.8594\n",
      "  no improvement this epoch. no_improve_heads = [1, 1, 1, 18]\n",
      "Epoch 546 | train_loss(step) = 0.3343 | train_loss(eval) = 0.3310 | train_mean_auc = 0.8449 | val_mean_auc = 0.8408\n",
      "  train AUC per head: h0: 0.8466 | h1: 0.8182 | h2: 0.8515 | h3: 0.8632\n",
      "  val   AUC per head: h0: 0.8408 | h1: 0.8149 | h2: 0.8480 | h3: 0.8594\n",
      "  no improvement this epoch. no_improve_heads = [2, 2, 2, 19]\n",
      "Epoch 547 | train_loss(step) = 0.3282 | train_loss(eval) = 0.3307 | train_mean_auc = 0.8451 | val_mean_auc = 0.8409\n",
      "  train AUC per head: h0: 0.8467 | h1: 0.8183 | h2: 0.8518 | h3: 0.8635\n",
      "  val   AUC per head: h0: 0.8408 | h1: 0.8150 | h2: 0.8482 | h3: 0.8597\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8410', '0.8150', '0.8482', '0.8604']\n",
      "  [EdgeMLP] best mean val AUC = 0.8409\n",
      "Epoch 548 | train_loss(step) = 0.3252 | train_loss(eval) = 0.3306 | train_mean_auc = 0.8452 | val_mean_auc = 0.8410\n",
      "  train AUC per head: h0: 0.8467 | h1: 0.8184 | h2: 0.8519 | h3: 0.8638\n",
      "  val   AUC per head: h0: 0.8407 | h1: 0.8151 | h2: 0.8483 | h3: 0.8601\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8410', '0.8151', '0.8483', '0.8604']\n",
      "  [EdgeMLP] best mean val AUC = 0.8410\n",
      "Epoch 549 | train_loss(step) = 0.3268 | train_loss(eval) = 0.3307 | train_mean_auc = 0.8451 | val_mean_auc = 0.8410\n",
      "  train AUC per head: h0: 0.8466 | h1: 0.8183 | h2: 0.8518 | h3: 0.8639\n",
      "  val   AUC per head: h0: 0.8405 | h1: 0.8151 | h2: 0.8482 | h3: 0.8602\n",
      "  no improvement this epoch. no_improve_heads = [5, 1, 1, 22]\n",
      "Epoch 550 | train_loss(step) = 0.3280 | train_loss(eval) = 0.3307 | train_mean_auc = 0.8452 | val_mean_auc = 0.8411\n",
      "  train AUC per head: h0: 0.8467 | h1: 0.8183 | h2: 0.8518 | h3: 0.8639\n",
      "  val   AUC per head: h0: 0.8407 | h1: 0.8151 | h2: 0.8482 | h3: 0.8602\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8410', '0.8151', '0.8483', '0.8604']\n",
      "  [EdgeMLP] best mean val AUC = 0.8411\n",
      "Epoch 551 | train_loss(step) = 0.3331 | train_loss(eval) = 0.3306 | train_mean_auc = 0.8453 | val_mean_auc = 0.8412\n",
      "  train AUC per head: h0: 0.8468 | h1: 0.8185 | h2: 0.8520 | h3: 0.8639\n",
      "  val   AUC per head: h0: 0.8408 | h1: 0.8152 | h2: 0.8484 | h3: 0.8602\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8410', '0.8152', '0.8484', '0.8604']\n",
      "  [EdgeMLP] best mean val AUC = 0.8412\n",
      "Epoch 552 | train_loss(step) = 0.3340 | train_loss(eval) = 0.3305 | train_mean_auc = 0.8454 | val_mean_auc = 0.8413\n",
      "  train AUC per head: h0: 0.8470 | h1: 0.8186 | h2: 0.8521 | h3: 0.8639\n",
      "  val   AUC per head: h0: 0.8412 | h1: 0.8152 | h2: 0.8485 | h3: 0.8603\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8412', '0.8152', '0.8485', '0.8604']\n",
      "  [EdgeMLP] best mean val AUC = 0.8413\n",
      "Epoch 553 | train_loss(step) = 0.3343 | train_loss(eval) = 0.3308 | train_mean_auc = 0.8452 | val_mean_auc = 0.8411\n",
      "  train AUC per head: h0: 0.8468 | h1: 0.8183 | h2: 0.8518 | h3: 0.8639\n",
      "  val   AUC per head: h0: 0.8411 | h1: 0.8148 | h2: 0.8482 | h3: 0.8603\n",
      "  no improvement this epoch. no_improve_heads = [1, 1, 1, 26]\n",
      "Epoch 554 | train_loss(step) = 0.3248 | train_loss(eval) = 0.3308 | train_mean_auc = 0.8451 | val_mean_auc = 0.8410\n",
      "  train AUC per head: h0: 0.8465 | h1: 0.8182 | h2: 0.8518 | h3: 0.8639\n",
      "  val   AUC per head: h0: 0.8409 | h1: 0.8147 | h2: 0.8481 | h3: 0.8603\n",
      "  no improvement this epoch. no_improve_heads = [2, 2, 2, 27]\n",
      "Epoch 555 | train_loss(step) = 0.3299 | train_loss(eval) = 0.3306 | train_mean_auc = 0.8453 | val_mean_auc = 0.8411\n",
      "  train AUC per head: h0: 0.8465 | h1: 0.8184 | h2: 0.8521 | h3: 0.8640\n",
      "  val   AUC per head: h0: 0.8408 | h1: 0.8148 | h2: 0.8485 | h3: 0.8604\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8412', '0.8152', '0.8485', '0.8604']\n",
      "  [EdgeMLP] best mean val AUC = 0.8413\n",
      "Epoch 556 | train_loss(step) = 0.3246 | train_loss(eval) = 0.3311 | train_mean_auc = 0.8454 | val_mean_auc = 0.8411\n",
      "  train AUC per head: h0: 0.8465 | h1: 0.8183 | h2: 0.8527 | h3: 0.8641\n",
      "  val   AUC per head: h0: 0.8406 | h1: 0.8145 | h2: 0.8489 | h3: 0.8604\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8412', '0.8152', '0.8489', '0.8604']\n",
      "  [EdgeMLP] best mean val AUC = 0.8413\n",
      "Epoch 557 | train_loss(step) = 0.3283 | train_loss(eval) = 0.3313 | train_mean_auc = 0.8453 | val_mean_auc = 0.8410\n",
      "  train AUC per head: h0: 0.8462 | h1: 0.8180 | h2: 0.8528 | h3: 0.8641\n",
      "  val   AUC per head: h0: 0.8402 | h1: 0.8142 | h2: 0.8490 | h3: 0.8604\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8412', '0.8152', '0.8490', '0.8604']\n",
      "  [EdgeMLP] best mean val AUC = 0.8413\n",
      "Epoch 558 | train_loss(step) = 0.3357 | train_loss(eval) = 0.3309 | train_mean_auc = 0.8453 | val_mean_auc = 0.8410\n",
      "  train AUC per head: h0: 0.8461 | h1: 0.8182 | h2: 0.8528 | h3: 0.8642\n",
      "  val   AUC per head: h0: 0.8400 | h1: 0.8145 | h2: 0.8490 | h3: 0.8604\n",
      "  no improvement this epoch. no_improve_heads = [6, 6, 1, 1]\n",
      "Epoch 559 | train_loss(step) = 0.3353 | train_loss(eval) = 0.3306 | train_mean_auc = 0.8453 | val_mean_auc = 0.8410\n",
      "  train AUC per head: h0: 0.8460 | h1: 0.8184 | h2: 0.8528 | h3: 0.8642\n",
      "  val   AUC per head: h0: 0.8399 | h1: 0.8148 | h2: 0.8489 | h3: 0.8604\n",
      "  no improvement this epoch. no_improve_heads = [7, 7, 2, 2]\n",
      "Epoch 560 | train_loss(step) = 0.3191 | train_loss(eval) = 0.3305 | train_mean_auc = 0.8454 | val_mean_auc = 0.8411\n",
      "  train AUC per head: h0: 0.8461 | h1: 0.8186 | h2: 0.8526 | h3: 0.8642\n",
      "  val   AUC per head: h0: 0.8400 | h1: 0.8150 | h2: 0.8488 | h3: 0.8604\n",
      "  no improvement this epoch. no_improve_heads = [8, 8, 3, 3]\n",
      "Epoch 561 | train_loss(step) = 0.3269 | train_loss(eval) = 0.3305 | train_mean_auc = 0.8455 | val_mean_auc = 0.8412\n",
      "  train AUC per head: h0: 0.8465 | h1: 0.8189 | h2: 0.8526 | h3: 0.8642\n",
      "  val   AUC per head: h0: 0.8406 | h1: 0.8153 | h2: 0.8487 | h3: 0.8603\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8412', '0.8153', '0.8490', '0.8604']\n",
      "  [EdgeMLP] best mean val AUC = 0.8413\n",
      "Epoch 562 | train_loss(step) = 0.3314 | train_loss(eval) = 0.3306 | train_mean_auc = 0.8456 | val_mean_auc = 0.8413\n",
      "  train AUC per head: h0: 0.8468 | h1: 0.8188 | h2: 0.8524 | h3: 0.8642\n",
      "  val   AUC per head: h0: 0.8410 | h1: 0.8153 | h2: 0.8484 | h3: 0.8604\n",
      "  no improvement this epoch. no_improve_heads = [10, 1, 5, 5]\n",
      "Epoch 563 | train_loss(step) = 0.3333 | train_loss(eval) = 0.3306 | train_mean_auc = 0.8455 | val_mean_auc = 0.8411\n",
      "  train AUC per head: h0: 0.8468 | h1: 0.8187 | h2: 0.8523 | h3: 0.8642\n",
      "  val   AUC per head: h0: 0.8410 | h1: 0.8150 | h2: 0.8482 | h3: 0.8604\n",
      "  no improvement this epoch. no_improve_heads = [11, 2, 6, 6]\n",
      "Epoch 564 | train_loss(step) = 0.3359 | train_loss(eval) = 0.3304 | train_mean_auc = 0.8455 | val_mean_auc = 0.8410\n",
      "  train AUC per head: h0: 0.8466 | h1: 0.8187 | h2: 0.8523 | h3: 0.8642\n",
      "  val   AUC per head: h0: 0.8407 | h1: 0.8149 | h2: 0.8481 | h3: 0.8604\n",
      "  no improvement this epoch. no_improve_heads = [12, 3, 7, 7]\n",
      "Epoch 565 | train_loss(step) = 0.3367 | train_loss(eval) = 0.3305 | train_mean_auc = 0.8455 | val_mean_auc = 0.8410\n",
      "  train AUC per head: h0: 0.8465 | h1: 0.8188 | h2: 0.8524 | h3: 0.8642\n",
      "  val   AUC per head: h0: 0.8406 | h1: 0.8149 | h2: 0.8482 | h3: 0.8604\n",
      "  no improvement this epoch. no_improve_heads = [13, 4, 8, 8]\n",
      "Epoch 566 | train_loss(step) = 0.3277 | train_loss(eval) = 0.3305 | train_mean_auc = 0.8455 | val_mean_auc = 0.8411\n",
      "  train AUC per head: h0: 0.8467 | h1: 0.8188 | h2: 0.8524 | h3: 0.8642\n",
      "  val   AUC per head: h0: 0.8408 | h1: 0.8149 | h2: 0.8481 | h3: 0.8604\n",
      "  no improvement this epoch. no_improve_heads = [14, 5, 9, 9]\n",
      "Epoch 567 | train_loss(step) = 0.3352 | train_loss(eval) = 0.3303 | train_mean_auc = 0.8455 | val_mean_auc = 0.8411\n",
      "  train AUC per head: h0: 0.8470 | h1: 0.8186 | h2: 0.8523 | h3: 0.8642\n",
      "  val   AUC per head: h0: 0.8411 | h1: 0.8148 | h2: 0.8480 | h3: 0.8604\n",
      "  no improvement this epoch. no_improve_heads = [15, 6, 10, 10]\n",
      "Epoch 568 | train_loss(step) = 0.3237 | train_loss(eval) = 0.3304 | train_mean_auc = 0.8454 | val_mean_auc = 0.8410\n",
      "  train AUC per head: h0: 0.8470 | h1: 0.8183 | h2: 0.8521 | h3: 0.8642\n",
      "  val   AUC per head: h0: 0.8412 | h1: 0.8146 | h2: 0.8479 | h3: 0.8604\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8412', '0.8153', '0.8490', '0.8604']\n",
      "  [EdgeMLP] best mean val AUC = 0.8413\n",
      "Epoch 569 | train_loss(step) = 0.3321 | train_loss(eval) = 0.3303 | train_mean_auc = 0.8455 | val_mean_auc = 0.8411\n",
      "  train AUC per head: h0: 0.8470 | h1: 0.8183 | h2: 0.8523 | h3: 0.8642\n",
      "  val   AUC per head: h0: 0.8412 | h1: 0.8146 | h2: 0.8482 | h3: 0.8604\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8412', '0.8153', '0.8490', '0.8604']\n",
      "  [EdgeMLP] best mean val AUC = 0.8413\n",
      "Epoch 570 | train_loss(step) = 0.3321 | train_loss(eval) = 0.3301 | train_mean_auc = 0.8458 | val_mean_auc = 0.8414\n",
      "  train AUC per head: h0: 0.8472 | h1: 0.8189 | h2: 0.8528 | h3: 0.8643\n",
      "  val   AUC per head: h0: 0.8413 | h1: 0.8151 | h2: 0.8488 | h3: 0.8605\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8413', '0.8153', '0.8490', '0.8605']\n",
      "  [EdgeMLP] best mean val AUC = 0.8414\n",
      "Epoch 571 | train_loss(step) = 0.3390 | train_loss(eval) = 0.3300 | train_mean_auc = 0.8459 | val_mean_auc = 0.8416\n",
      "  train AUC per head: h0: 0.8471 | h1: 0.8191 | h2: 0.8530 | h3: 0.8643\n",
      "  val   AUC per head: h0: 0.8411 | h1: 0.8154 | h2: 0.8492 | h3: 0.8605\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8413', '0.8154', '0.8492', '0.8605']\n",
      "  [EdgeMLP] best mean val AUC = 0.8416\n",
      "Epoch 572 | train_loss(step) = 0.3311 | train_loss(eval) = 0.3301 | train_mean_auc = 0.8459 | val_mean_auc = 0.8416\n",
      "  train AUC per head: h0: 0.8468 | h1: 0.8192 | h2: 0.8531 | h3: 0.8643\n",
      "  val   AUC per head: h0: 0.8408 | h1: 0.8155 | h2: 0.8495 | h3: 0.8605\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8413', '0.8155', '0.8495', '0.8605']\n",
      "  [EdgeMLP] best mean val AUC = 0.8416\n",
      "Epoch 573 | train_loss(step) = 0.3305 | train_loss(eval) = 0.3302 | train_mean_auc = 0.8458 | val_mean_auc = 0.8416\n",
      "  train AUC per head: h0: 0.8466 | h1: 0.8192 | h2: 0.8532 | h3: 0.8643\n",
      "  val   AUC per head: h0: 0.8406 | h1: 0.8156 | h2: 0.8497 | h3: 0.8605\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8413', '0.8156', '0.8497', '0.8605']\n",
      "  [EdgeMLP] best mean val AUC = 0.8416\n",
      "Epoch 574 | train_loss(step) = 0.3286 | train_loss(eval) = 0.3302 | train_mean_auc = 0.8458 | val_mean_auc = 0.8416\n",
      "  train AUC per head: h0: 0.8465 | h1: 0.8191 | h2: 0.8531 | h3: 0.8643\n",
      "  val   AUC per head: h0: 0.8405 | h1: 0.8156 | h2: 0.8498 | h3: 0.8605\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8413', '0.8156', '0.8498', '0.8605']\n",
      "  [EdgeMLP] best mean val AUC = 0.8416\n",
      "Epoch 575 | train_loss(step) = 0.3275 | train_loss(eval) = 0.3302 | train_mean_auc = 0.8457 | val_mean_auc = 0.8415\n",
      "  train AUC per head: h0: 0.8465 | h1: 0.8190 | h2: 0.8530 | h3: 0.8643\n",
      "  val   AUC per head: h0: 0.8406 | h1: 0.8155 | h2: 0.8497 | h3: 0.8604\n",
      "  no improvement this epoch. no_improve_heads = [5, 2, 1, 4]\n",
      "Epoch 576 | train_loss(step) = 0.3419 | train_loss(eval) = 0.3301 | train_mean_auc = 0.8457 | val_mean_auc = 0.8416\n",
      "  train AUC per head: h0: 0.8466 | h1: 0.8190 | h2: 0.8529 | h3: 0.8642\n",
      "  val   AUC per head: h0: 0.8408 | h1: 0.8155 | h2: 0.8496 | h3: 0.8604\n",
      "  no improvement this epoch. no_improve_heads = [6, 3, 2, 5]\n",
      "Epoch 577 | train_loss(step) = 0.3408 | train_loss(eval) = 0.3301 | train_mean_auc = 0.8457 | val_mean_auc = 0.8416\n",
      "  train AUC per head: h0: 0.8469 | h1: 0.8190 | h2: 0.8529 | h3: 0.8641\n",
      "  val   AUC per head: h0: 0.8411 | h1: 0.8155 | h2: 0.8495 | h3: 0.8602\n",
      "  no improvement this epoch. no_improve_heads = [7, 4, 3, 6]\n",
      "Epoch 578 | train_loss(step) = 0.3286 | train_loss(eval) = 0.3302 | train_mean_auc = 0.8457 | val_mean_auc = 0.8416\n",
      "  train AUC per head: h0: 0.8472 | h1: 0.8189 | h2: 0.8528 | h3: 0.8639\n",
      "  val   AUC per head: h0: 0.8414 | h1: 0.8154 | h2: 0.8495 | h3: 0.8601\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8414', '0.8156', '0.8498', '0.8605']\n",
      "  [EdgeMLP] best mean val AUC = 0.8416\n",
      "Epoch 579 | train_loss(step) = 0.3286 | train_loss(eval) = 0.3300 | train_mean_auc = 0.8458 | val_mean_auc = 0.8417\n",
      "  train AUC per head: h0: 0.8474 | h1: 0.8191 | h2: 0.8530 | h3: 0.8639\n",
      "  val   AUC per head: h0: 0.8417 | h1: 0.8155 | h2: 0.8497 | h3: 0.8600\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8417', '0.8156', '0.8498', '0.8605']\n",
      "  [EdgeMLP] best mean val AUC = 0.8417\n",
      "Epoch 580 | train_loss(step) = 0.3408 | train_loss(eval) = 0.3300 | train_mean_auc = 0.8459 | val_mean_auc = 0.8417\n",
      "  train AUC per head: h0: 0.8474 | h1: 0.8191 | h2: 0.8531 | h3: 0.8639\n",
      "  val   AUC per head: h0: 0.8417 | h1: 0.8155 | h2: 0.8496 | h3: 0.8600\n",
      "  [EdgeMLP] improvement! best val AUC per head now: ['0.8417', '0.8156', '0.8498', '0.8605']\n",
      "  [EdgeMLP] best mean val AUC = 0.8417\n",
      "Epoch 581 | train_loss(step) = 0.3337 | train_loss(eval) = 0.3301 | train_mean_auc = 0.8458 | val_mean_auc = 0.8416\n",
      "  train AUC per head: h0: 0.8473 | h1: 0.8189 | h2: 0.8531 | h3: 0.8640\n",
      "  val   AUC per head: h0: 0.8415 | h1: 0.8154 | h2: 0.8495 | h3: 0.8601\n",
      "  no improvement this epoch. no_improve_heads = [1, 8, 7, 10]\n",
      "Epoch 582 | train_loss(step) = 0.3398 | train_loss(eval) = 0.3302 | train_mean_auc = 0.8457 | val_mean_auc = 0.8414\n",
      "  train AUC per head: h0: 0.8471 | h1: 0.8187 | h2: 0.8528 | h3: 0.8642\n",
      "  val   AUC per head: h0: 0.8413 | h1: 0.8152 | h2: 0.8491 | h3: 0.8602\n",
      "  no improvement this epoch. no_improve_heads = [2, 9, 8, 11]\n",
      "Epoch 583 | train_loss(step) = 0.3263 | train_loss(eval) = 0.3303 | train_mean_auc = 0.8457 | val_mean_auc = 0.8413\n",
      "  train AUC per head: h0: 0.8471 | h1: 0.8186 | h2: 0.8527 | h3: 0.8643\n",
      "  val   AUC per head: h0: 0.8414 | h1: 0.8149 | h2: 0.8488 | h3: 0.8602\n",
      "  no improvement this epoch. no_improve_heads = [3, 10, 9, 12]\n",
      "Epoch 584 | train_loss(step) = 0.3248 | train_loss(eval) = 0.3302 | train_mean_auc = 0.8458 | val_mean_auc = 0.8414\n",
      "  train AUC per head: h0: 0.8474 | h1: 0.8187 | h2: 0.8528 | h3: 0.8643\n",
      "  val   AUC per head: h0: 0.8416 | h1: 0.8149 | h2: 0.8488 | h3: 0.8602\n",
      "  no improvement this epoch. no_improve_heads = [4, 11, 10, 13]\n",
      "Epoch 585 | train_loss(step) = 0.3286 | train_loss(eval) = 0.3301 | train_mean_auc = 0.8459 | val_mean_auc = 0.8414\n",
      "  train AUC per head: h0: 0.8475 | h1: 0.8187 | h2: 0.8531 | h3: 0.8642\n",
      "  val   AUC per head: h0: 0.8417 | h1: 0.8148 | h2: 0.8488 | h3: 0.8601\n",
      "  no improvement this epoch. no_improve_heads = [5, 12, 11, 14]\n",
      "Epoch 586 | train_loss(step) = 0.3287 | train_loss(eval) = 0.3304 | train_mean_auc = 0.8458 | val_mean_auc = 0.8412\n",
      "  train AUC per head: h0: 0.8474 | h1: 0.8185 | h2: 0.8531 | h3: 0.8642\n",
      "  val   AUC per head: h0: 0.8416 | h1: 0.8144 | h2: 0.8487 | h3: 0.8601\n",
      "  no improvement this epoch. no_improve_heads = [6, 13, 12, 15]\n",
      "Epoch 587 | train_loss(step) = 0.3357 | train_loss(eval) = 0.3306 | train_mean_auc = 0.8459 | val_mean_auc = 0.8412\n",
      "  train AUC per head: h0: 0.8475 | h1: 0.8186 | h2: 0.8532 | h3: 0.8643\n",
      "  val   AUC per head: h0: 0.8415 | h1: 0.8143 | h2: 0.8488 | h3: 0.8602\n",
      "  no improvement this epoch. no_improve_heads = [7, 14, 13, 16]\n",
      "Epoch 588 | train_loss(step) = 0.3340 | train_loss(eval) = 0.3303 | train_mean_auc = 0.8460 | val_mean_auc = 0.8413\n",
      "  train AUC per head: h0: 0.8475 | h1: 0.8189 | h2: 0.8535 | h3: 0.8643\n",
      "  val   AUC per head: h0: 0.8414 | h1: 0.8147 | h2: 0.8490 | h3: 0.8602\n",
      "  no improvement this epoch. no_improve_heads = [8, 15, 14, 17]\n",
      "Epoch 589 | train_loss(step) = 0.3339 | train_loss(eval) = 0.3298 | train_mean_auc = 0.8461 | val_mean_auc = 0.8414\n",
      "  train AUC per head: h0: 0.8474 | h1: 0.8192 | h2: 0.8536 | h3: 0.8643\n",
      "  val   AUC per head: h0: 0.8413 | h1: 0.8151 | h2: 0.8491 | h3: 0.8603\n",
      "  no improvement this epoch. no_improve_heads = [9, 16, 15, 18]\n",
      "Epoch 590 | train_loss(step) = 0.3419 | train_loss(eval) = 0.3300 | train_mean_auc = 0.8459 | val_mean_auc = 0.8412\n",
      "  train AUC per head: h0: 0.8472 | h1: 0.8188 | h2: 0.8534 | h3: 0.8643\n",
      "  val   AUC per head: h0: 0.8410 | h1: 0.8148 | h2: 0.8488 | h3: 0.8603\n",
      "  no improvement this epoch. no_improve_heads = [10, 17, 16, 19]\n",
      "Epoch 591 | train_loss(step) = 0.3344 | train_loss(eval) = 0.3305 | train_mean_auc = 0.8457 | val_mean_auc = 0.8409\n",
      "  train AUC per head: h0: 0.8469 | h1: 0.8185 | h2: 0.8530 | h3: 0.8642\n",
      "  val   AUC per head: h0: 0.8407 | h1: 0.8145 | h2: 0.8483 | h3: 0.8602\n",
      "  no improvement this epoch. no_improve_heads = [11, 18, 17, 20]\n",
      "Epoch 592 | train_loss(step) = 0.3282 | train_loss(eval) = 0.3305 | train_mean_auc = 0.8457 | val_mean_auc = 0.8410\n",
      "  train AUC per head: h0: 0.8472 | h1: 0.8188 | h2: 0.8529 | h3: 0.8641\n",
      "  val   AUC per head: h0: 0.8409 | h1: 0.8148 | h2: 0.8482 | h3: 0.8602\n",
      "  no improvement this epoch. no_improve_heads = [12, 19, 18, 21]\n",
      "Epoch 593 | train_loss(step) = 0.3247 | train_loss(eval) = 0.3299 | train_mean_auc = 0.8460 | val_mean_auc = 0.8413\n",
      "  train AUC per head: h0: 0.8474 | h1: 0.8194 | h2: 0.8533 | h3: 0.8640\n",
      "  val   AUC per head: h0: 0.8412 | h1: 0.8154 | h2: 0.8485 | h3: 0.8601\n",
      "  no improvement this epoch. no_improve_heads = [13, 20, 19, 22]\n",
      "Epoch 594 | train_loss(step) = 0.3333 | train_loss(eval) = 0.3296 | train_mean_auc = 0.8462 | val_mean_auc = 0.8415\n",
      "  train AUC per head: h0: 0.8475 | h1: 0.8197 | h2: 0.8537 | h3: 0.8640\n",
      "  val   AUC per head: h0: 0.8413 | h1: 0.8155 | h2: 0.8489 | h3: 0.8601\n",
      "  no improvement this epoch. no_improve_heads = [14, 21, 20, 23]\n",
      "Epoch 595 | train_loss(step) = 0.3299 | train_loss(eval) = 0.3298 | train_mean_auc = 0.8463 | val_mean_auc = 0.8415\n",
      "  train AUC per head: h0: 0.8475 | h1: 0.8195 | h2: 0.8540 | h3: 0.8641\n",
      "  val   AUC per head: h0: 0.8414 | h1: 0.8152 | h2: 0.8493 | h3: 0.8602\n",
      "  no improvement this epoch. no_improve_heads = [15, 22, 21, 24]\n",
      "Epoch 596 | train_loss(step) = 0.3315 | train_loss(eval) = 0.3303 | train_mean_auc = 0.8463 | val_mean_auc = 0.8414\n",
      "  train AUC per head: h0: 0.8474 | h1: 0.8191 | h2: 0.8542 | h3: 0.8644\n",
      "  val   AUC per head: h0: 0.8413 | h1: 0.8146 | h2: 0.8495 | h3: 0.8604\n",
      "  no improvement this epoch. no_improve_heads = [16, 23, 22, 25]\n",
      "Epoch 597 | train_loss(step) = 0.3460 | train_loss(eval) = 0.3300 | train_mean_auc = 0.8462 | val_mean_auc = 0.8415\n",
      "  train AUC per head: h0: 0.8475 | h1: 0.8191 | h2: 0.8539 | h3: 0.8645\n",
      "  val   AUC per head: h0: 0.8415 | h1: 0.8146 | h2: 0.8493 | h3: 0.8605\n",
      "  no improvement this epoch. no_improve_heads = [17, 24, 23, 26]\n",
      "Epoch 598 | train_loss(step) = 0.3300 | train_loss(eval) = 0.3299 | train_mean_auc = 0.8462 | val_mean_auc = 0.8414\n",
      "  train AUC per head: h0: 0.8474 | h1: 0.8191 | h2: 0.8536 | h3: 0.8644\n",
      "  val   AUC per head: h0: 0.8414 | h1: 0.8148 | h2: 0.8490 | h3: 0.8604\n",
      "  no improvement this epoch. no_improve_heads = [18, 25, 24, 27]\n",
      "Epoch 599 | train_loss(step) = 0.3318 | train_loss(eval) = 0.3298 | train_mean_auc = 0.8462 | val_mean_auc = 0.8415\n",
      "  train AUC per head: h0: 0.8475 | h1: 0.8194 | h2: 0.8535 | h3: 0.8644\n",
      "  val   AUC per head: h0: 0.8415 | h1: 0.8152 | h2: 0.8489 | h3: 0.8603\n",
      "  no improvement this epoch. no_improve_heads = [19, 26, 25, 28]\n",
      "Epoch 600 | train_loss(step) = 0.3251 | train_loss(eval) = 0.3298 | train_mean_auc = 0.8463 | val_mean_auc = 0.8416\n",
      "  train AUC per head: h0: 0.8476 | h1: 0.8196 | h2: 0.8538 | h3: 0.8643\n",
      "  val   AUC per head: h0: 0.8415 | h1: 0.8155 | h2: 0.8492 | h3: 0.8603\n",
      "  no improvement this epoch. no_improve_heads = [20, 27, 26, 29]\n",
      "Early stopping triggered: all heads have stalled.\n",
      "\n",
      "Loaded best model from epoch 580\n",
      "Best val AUC per head: [np.float64(0.8417262795209058), np.float64(0.8156089435511626), np.float64(0.8497589091981794), np.float64(0.8605081301810453)]\n",
      "Best mean val AUC: 0.8417\n",
      "\n",
      "Re-evaluating splits with best model:\n",
      "Final train loss: 0.3300 | train mean AUC: 0.8459\n",
      "  train AUC per head: [np.float64(0.8474068044559763), np.float64(0.8190622636441629), np.float64(0.8530685601006837), np.float64(0.8639286598489884)]\n",
      "Final val   loss: 0.3337 | val   mean AUC: 0.8417\n",
      "  val   AUC per head: [np.float64(0.8417262795209058), np.float64(0.8155094218666284), np.float64(0.8496141717026422), np.float64(0.8600175843249422)]\n",
      "Final test  loss: 0.3306 | test  mean AUC: 0.8446\n",
      "  test  AUC per head: [np.float64(0.8461365679985838), np.float64(0.816732777975772), np.float64(0.8509340781027793), np.float64(0.8645789821858838)]\n",
      "Best epoch used for final eval: 580\n"
     ]
    }
   ],
   "source": [
    "num_heads = 4\n",
    "patience = 20\n",
    "model_name = type(model).__name__\n",
    "\n",
    "best_val_auc_heads = [-float(\"inf\")] * num_heads\n",
    "best_val_auc_mean = -float(\"inf\")\n",
    "best_state = None\n",
    "best_epoch = None\n",
    "\n",
    "no_improve_heads = [0] * num_heads\n",
    "\n",
    "for epoch in range(1, 2001):\n",
    "    # 1) one training step\n",
    "    train_loss_step = train_step(batch_size=4096)\n",
    "\n",
    "    # 2) evaluate on train + val\n",
    "    train_loss_eval, train_auc_heads, train_auc_mean = eval_split(train_idx, \"train\")\n",
    "    val_loss, val_auc_heads, val_auc_mean = eval_split(val_idx, \"val\")\n",
    "\n",
    "    # pretty print\n",
    "    head_str_train = \" | \".join(\n",
    "        [f\"h{h}: {train_auc_heads[h]:.4f}\" for h in range(num_heads)]\n",
    "    )\n",
    "    head_str_val = \" | \".join(\n",
    "        [f\"h{h}: {val_auc_heads[h]:.4f}\" for h in range(num_heads)]\n",
    "    )\n",
    "    print(\n",
    "        f\"Epoch {epoch:03d} | \"\n",
    "        f\"train_loss(step) = {train_loss_step:.4f} | \"\n",
    "        f\"train_loss(eval) = {train_loss_eval:.4f} | \"\n",
    "        f\"train_mean_auc = {train_auc_mean:.4f} | \"\n",
    "        f\"val_mean_auc = {val_auc_mean:.4f}\"\n",
    "    )\n",
    "    print(f\"  train AUC per head: {head_str_train}\")\n",
    "    print(f\"  val   AUC per head: {head_str_val}\")\n",
    "\n",
    "    # 3) update bests and no_improve counters\n",
    "    any_head_improved = False\n",
    "    for h in range(num_heads):\n",
    "        auc_h = val_auc_heads[h]\n",
    "        if np.isnan(auc_h):\n",
    "            # skip heads with undefined AUC\n",
    "            continue\n",
    "\n",
    "        if auc_h > best_val_auc_heads[h]:\n",
    "            best_val_auc_heads[h] = auc_h\n",
    "            no_improve_heads[h] = 0\n",
    "            any_head_improved = True\n",
    "        else:\n",
    "            no_improve_heads[h] += 1\n",
    "\n",
    "    # we can still track best mean AUC for logging, but your stopping rule\n",
    "    # is based on all heads\n",
    "    if val_auc_mean > best_val_auc_mean:\n",
    "        best_val_auc_mean = val_auc_mean\n",
    "\n",
    "    # if any head improved, save model\n",
    "    if any_head_improved:\n",
    "        best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "        best_epoch = epoch\n",
    "        formatted_aucs = [f\"{a:.4f}\" for a in best_val_auc_heads]\n",
    "        print(f\"  [{model_name}] improvement! best val AUC per head now: {formatted_aucs}\")\n",
    "        print(f\"  [{model_name}] best mean val AUC = {best_val_auc_mean:.4f}\")\n",
    "    else:\n",
    "        print(f\"  no improvement this epoch. no_improve_heads = {no_improve_heads}\")\n",
    "\n",
    "    # 4) early stopping: all heads stopped improving for patience epochs\n",
    "    if all(n >= patience for n in no_improve_heads):\n",
    "        print(\"Early stopping triggered: all heads have stalled.\")\n",
    "        break\n",
    "\n",
    "# After training: reload best model and evaluate\n",
    "if best_state is not None:\n",
    "    model.load_state_dict(best_state)\n",
    "    print(f\"\\nLoaded best model from epoch {best_epoch}\")\n",
    "    print(f\"Best val AUC per head: {best_val_auc_heads}\")\n",
    "    print(f\"Best mean val AUC: {best_val_auc_mean:.4f}\")\n",
    "else:\n",
    "    print(\"\\nWarning: best_state is None\")\n",
    "\n",
    "print(\"\\nRe-evaluating splits with best model:\")\n",
    "\n",
    "train_loss_final, train_auc_heads_final, train_auc_mean_final = eval_split(train_idx, \"train\")\n",
    "val_loss_final, val_auc_heads_final, val_auc_mean_final = eval_split(val_idx, \"val\")\n",
    "test_loss_final, test_auc_heads_final, test_auc_mean_final = eval_split(test_idx, \"test\")\n",
    "\n",
    "print(f\"Final train loss: {train_loss_final:.4f} | train mean AUC: {train_auc_mean_final:.4f}\")\n",
    "print(f\"  train AUC per head: {train_auc_heads_final}\")\n",
    "print(f\"Final val   loss: {val_loss_final:.4f} | val   mean AUC: {val_auc_mean_final:.4f}\")\n",
    "print(f\"  val   AUC per head: {val_auc_heads_final}\")\n",
    "print(f\"Final test  loss: {test_loss_final:.4f} | test  mean AUC: {test_auc_mean_final:.4f}\")\n",
    "print(f\"  test  AUC per head: {test_auc_heads_final}\")\n",
    "print(f\"Best epoch used for final eval: {best_epoch}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30100ae-5e98-4522-9212-b73706c91bed",
   "metadata": {},
   "source": [
    "### 7. Saving output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c1d355a-035f-4e00-a1a5-4e7fafa2c15a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best EdgeMLP (multi-head) model to: /Users/haozhangao/Desktop/RecSys Research/KuaiRec 2.0/models/GNN/EdgeMLP_multihead_best_test.pt\n",
      "  best_epoch: 580\n",
      "  best val AUC per head: [0.8417 | 0.8156 | 0.8498 | 0.8605]\n",
      "  best val mean AUC: 0.8417\n",
      "  final train AUC per head: [0.8474 | 0.8191 | 0.8531 | 0.8639], mean = 0.8459\n",
      "  final val   AUC per head: [0.8417 | 0.8155 | 0.8496 | 0.8600],   mean = 0.8417\n",
      "  final test  AUC per head: [0.8461 | 0.8167 | 0.8509 | 0.8646],  mean = 0.8446\n"
     ]
    }
   ],
   "source": [
    "SAVE_DIR = Path(\"/Users/haozhangao/Desktop/RecSys Research/KuaiRec 2.0/models/GNN\")\n",
    "SAVE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "model_path = SAVE_DIR / f\"{model_name}_multihead_best_test.pt\"\n",
    "\n",
    "torch.save(\n",
    "    {\n",
    "        \"state_dict\": model.state_dict(),\n",
    "        \"best_epoch\": best_epoch,\n",
    "\n",
    "        # best (according to early stopping)\n",
    "        \"best_val_auc_heads\": best_val_auc_heads,        # list of 4 floats\n",
    "        \"best_val_auc_mean\": best_val_auc_mean,\n",
    "\n",
    "        # final metrics at best_epoch\n",
    "        \"train_loss_final\": float(train_loss_final),\n",
    "        \"val_loss_final\": float(val_loss_final),\n",
    "        \"test_loss_final\": float(test_loss_final),\n",
    "\n",
    "        \"train_auc_heads_final\": train_auc_heads_final,  # list of 4\n",
    "        \"val_auc_heads_final\": val_auc_heads_final,      # list of 4\n",
    "        \"test_auc_heads_final\": test_auc_heads_final,    # list of 4\n",
    "\n",
    "        \"train_auc_mean_final\": float(train_auc_mean_final),\n",
    "        \"val_auc_mean_final\": float(val_auc_mean_final),\n",
    "        \"test_auc_mean_final\": float(test_auc_mean_final),\n",
    "    },\n",
    "    model_path,\n",
    ")\n",
    "\n",
    "# pretty print with 4 digits\n",
    "fmt = lambda xs: \" | \".join(f\"{x:.4f}\" for x in xs)\n",
    "\n",
    "print(f\"Saved best {model_name} (multi-head) model to: {model_path}\")\n",
    "print(f\"  best_epoch: {best_epoch}\")\n",
    "print(f\"  best val AUC per head: [{fmt(best_val_auc_heads)}]\")\n",
    "print(f\"  best val mean AUC: {best_val_auc_mean:.4f}\")\n",
    "print(f\"  final train AUC per head: [{fmt(train_auc_heads_final)}], mean = {train_auc_mean_final:.4f}\")\n",
    "print(f\"  final val   AUC per head: [{fmt(val_auc_heads_final)}],   mean = {val_auc_mean_final:.4f}\")\n",
    "print(f\"  final test  AUC per head: [{fmt(test_auc_heads_final)}],  mean = {test_auc_mean_final:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
